{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PersonAttrubutes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankush2805/EIP/blob/master/Tests5/Epochs200.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "0ff1253d-1cff-4753-8f28-ac5c1b49c208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d3f3141-81bb-4f57-dedf-b989e3f8555f"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "outputId": "73ecf134-1ba1-47d3-90ba-0de32d9b7115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_path</th>\n",
              "      <td>resized/1.jpg</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_female</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_male</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Average</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Good</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_15-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_25-35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_35-45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_45-55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_55+</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_over-weight</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_underweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_None</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Normal</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Happy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Side</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  0  ...              4\n",
              "image_path                            resized/1.jpg  ...  resized/5.jpg\n",
              "gender_female                                     0  ...              1\n",
              "gender_male                                       1  ...              0\n",
              "imagequality_Average                              1  ...              0\n",
              "imagequality_Bad                                  0  ...              0\n",
              "imagequality_Good                                 0  ...              1\n",
              "age_15-25                                         0  ...              0\n",
              "age_25-35                                         0  ...              0\n",
              "age_35-45                                         1  ...              1\n",
              "age_45-55                                         0  ...              0\n",
              "age_55+                                           0  ...              0\n",
              "weight_normal-healthy                             1  ...              0\n",
              "weight_over-weight                                0  ...              0\n",
              "weight_slightly-overweight                        0  ...              1\n",
              "weight_underweight                                0  ...              0\n",
              "carryingbag_Daily/Office/Work Bag                 0  ...              0\n",
              "carryingbag_Grocery/Home/Plastic Bag              1  ...              0\n",
              "carryingbag_None                                  0  ...              1\n",
              "footwear_CantSee                                  0  ...              1\n",
              "footwear_Fancy                                    0  ...              0\n",
              "footwear_Normal                                   1  ...              0\n",
              "emotion_Angry/Serious                             0  ...              0\n",
              "emotion_Happy                                     0  ...              0\n",
              "emotion_Neutral                                   1  ...              1\n",
              "emotion_Sad                                       0  ...              0\n",
              "bodypose_Back                                     0  ...              0\n",
              "bodypose_Front-Frontish                           1  ...              1\n",
              "bodypose_Side                                     0  ...              0\n",
              "\n",
              "[28 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NblA5eWon8lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_eraser(input_img, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=1, pixel_level=False):\n",
        "  img_h, img_w, img_c = input_img.shape\n",
        "  p_1 = np.random.rand()\n",
        "  if p_1 > p:\n",
        "    return input_img\n",
        "\n",
        "  while True:\n",
        "    s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "    r = np.random.uniform(r_1, r_2)\n",
        "    w = int(np.sqrt(s / r))\n",
        "    h = int(np.sqrt(s * r))\n",
        "    left = np.random.randint(0, img_w)\n",
        "    top = np.random.randint(0, img_h)\n",
        "\n",
        "    if left + w <= img_w and top + h <= img_h:\n",
        "      break\n",
        "\n",
        "    if pixel_level:\n",
        "      c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "    else:\n",
        "      c = np.random.uniform(v_l, v_h)\n",
        "    input_img[top:top + h, left:left + w, :] = c\n",
        "  return input_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH5IpIVun_xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augmentor(images):\n",
        "\t\t'Apply data augmentation'\n",
        "\t\tsometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\t\tseq = iaa.Sequential(\n",
        "\t\t\t\t[\n",
        "\t\t\t\t# apply the following augmenters to most images\n",
        "\t\t\t\tiaa.Fliplr(0.3),  # horizontally flip 50% of all images\n",
        "\t\t\t\tsometimes(iaa.Affine(\n",
        "\t\t\t\t\tscale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
        "\t\t\t\t\t# scale images to 80-120% of their size, individually per axis\n",
        "\t\t\t\t\ttranslate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
        "\t\t\t\t\t# translate by -20 to +20 percent (per axis)\n",
        "\t\t\t\t\trotate=(-10, 10),  # rotate by -45 to +45 degrees\n",
        "\t\t\t\t\tshear=(-5, 5),  # shear by -16 to +16 degrees\n",
        "\t\t\t\t\torder=[0, 1],\n",
        "\t\t\t\t\t# use nearest neighbour or bilinear interpolation (fast)\n",
        "\t\t\t\t\tcval=(0, 255),  # if mode is constant, use a cval between 0 and 255\n",
        "\t\t\t\t\tmode=ia.ALL\n",
        "\t\t\t\t\t# use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "\t\t\t\t)),\n",
        "\t\t\t\t# execute 0 to 5 of the following (less important) augmenters per image\n",
        "\t\t\t\t# don't execute all of them, as that would often be way too strong\n",
        "\t\t\t\tiaa.SomeOf((0, 5),\n",
        "\t\t\t\t           [sometimes(iaa.Superpixels(p_replace=(0, 1.0),\n",
        "\t\t\t\t\t\t                                     n_segments=(20, 200))),\n",
        "\t\t\t\t\t           # convert images into their superpixel representation\n",
        "\t\t\t\t\t           iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.GaussianBlur((0, 1.0)),\n",
        "\t\t\t\t\t\t\t           # blur images with a sigma between 0 and 3.0\n",
        "\t\t\t\t\t\t\t           iaa.AverageBlur(k=(3, 5)),\n",
        "\t\t\t\t\t\t\t           # blur image using local means with kernel sizes between 2 and 7\n",
        "\t\t\t\t\t\t\t           iaa.MedianBlur(k=(3, 5)),\n",
        "\t\t\t\t\t\t\t           # blur image using local medians with kernel sizes between 2 and 7\n",
        "\t\t\t\t\t           ]),\n",
        "\t\t\t\t\t           iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)),\n",
        "\t\t\t\t\t           # sharpen images\n",
        "\t\t\t\t\t           iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),\n",
        "\t\t\t\t\t           # emboss images\n",
        "\t\t\t\t\t           # search either for all edges or for directed edges,\n",
        "\t\t\t\t\t           # blend the result with the original image using a blobby mask\n",
        "\t\t\t\t\t           iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "\t\t\t\t\t\t\t           iaa.DirectedEdgeDetect(alpha=(0.5, 1.0),\n",
        "\t\t\t\t\t\t\t                                  direction=(0.0, 1.0)),\n",
        "\t\t\t\t\t           ])),\n",
        "\t\t\t\t\t           iaa.AdditiveGaussianNoise(loc=0,\n",
        "\t\t\t\t\t                                     scale=(0.0, 0.01 * 255),\n",
        "\t\t\t\t\t                                     per_channel=0.5),\n",
        "\t\t\t\t\t           # add gaussian noise to images\n",
        "\t\t\t\t\t           \n",
        "\t\t\t\t\t           \n",
        "\t\t\t\t\t           iaa.Add((-2, 2), per_channel=0.5),\n",
        "\t\t\t\t\t           # change brightness of images (by -10 to 10 of original value)\n",
        "\t\t\t\t\t           iaa.AddToHueAndSaturation((-1, 1)),\n",
        "\t\t\t\t\t           # change hue and saturation\n",
        "\t\t\t\t\t           # either change the brightness of the whole image (sometimes\n",
        "\t\t\t\t\t           # per channel) or change the brightness of subareas\n",
        "\t\t\t\t\t           iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "\t\t\t\t\t\t\t           iaa.FrequencyNoiseAlpha(\n",
        "\t\t\t\t\t\t\t\t\t           exponent=(-1, 0),\n",
        "\t\t\t\t\t\t\t\t\t           first=iaa.Multiply((0.9, 1.1),\n",
        "\t\t\t\t\t\t\t\t\t                              per_channel=True),\n",
        "\t\t\t\t\t\t\t\t\t           second=iaa.ContrastNormalization(\n",
        "\t\t\t\t\t\t\t\t\t\t\t           (0.9, 1.1))\n",
        "\t\t\t\t\t\t\t           )\n",
        "\t\t\t\t\t           ]),\n",
        "\t\t\t\t\t           sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5),\n",
        "\t\t\t\t\t                                               sigma=0.25)),\n",
        "\t\t\t\t\t           # move pixels locally around (with random strengths)\n",
        "\t\t\t\t\t           sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n",
        "\t\t\t\t\t           # sometimes move parts of the image around\n",
        "\t\t\t\t\t           sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "\t\t\t\t           ],\n",
        "\t\t\t\t           random_order=True\n",
        "\t\t\t\t           )\n",
        "\t\t\t\t],\n",
        "\t\t\t\trandom_order=True\n",
        "\t\t)\n",
        "\t\treturn seq.augment_images(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "ia.seed(1)\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        if self.batch_size ==32:\n",
        "          image = np.stack([get_random_eraser(img) for img in image])\n",
        "          image = augmentor(image)\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "outputId": "1af374f5-10dc-40d2-8e7a-8bc203f05469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 28), (2036, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "outputId": "319b3e08-dd58-4821-a384-1bf75a1b57be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpStgLcg5NKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 0.001\n",
        "    if epoch > 95:\n",
        "        lr = 0.000001\n",
        "    if epoch > 80:\n",
        "        lr = 0.00005\n",
        "    elif epoch > 60:\n",
        "        lr = 0.0001\n",
        "    elif epoch > 40:\n",
        "        lr = 0.0005\n",
        "    elif epoch > 20:\n",
        "        lr = 0.001\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "outputId": "4c4a491f-0ea8-4d1d-cec7-3b63c174b88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "from keras.applications import InceptionV3, Xception, DenseNet121, DenseNet201, ResNet152V2\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "backbone = ResNet152V2(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "neck = GlobalAveragePooling2D()(neck)\n",
        "#neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "def build_dense_tower(in_layer):\n",
        "    neck = Dense(128, activation=\"relu\")(in_layer)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_dense_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_dense_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_dense_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_dense_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_dense_tower(neck))\n",
        "\n",
        "\n",
        "#model = Model(\n",
        "#    inputs=backbone.input, outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion])\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/person_attributes.hdf5')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snP65fRLqdhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "outputId": "bd02715a-1ad9-4499-9891-e49003704e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# losses = {\n",
        "# \t\"gender_output\": \"binary_crossentropy\",\n",
        "# \t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "# \t\"age_output\": \"categorical_crossentropy\",\n",
        "# \t\"weight_output\": \"categorical_crossentropy\",\n",
        "\n",
        "# }\n",
        "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=lr_schedule(0))\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2ZRIQ7BW-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "outputId": "0f783ebf-dcdf-49a2-d895-80bc8147e21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "#drive.mount('/content/gdrive')\n",
        "filepath = '/content/gdrive/My Drive/person_attributes.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             verbose=1,save_weights_only=False,\n",
        "                             period =10)\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=100,\n",
        "    verbose=1,callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "359/360 [============================>.] - ETA: 1s - loss: 6.0146 - gender_output_loss: 0.2442 - image_quality_output_loss: 0.9297 - age_output_loss: 1.2604 - weight_output_loss: 0.8772 - bag_output_loss: 0.7321 - footwear_output_loss: 0.7563 - pose_output_loss: 0.3656 - emotion_output_loss: 0.8490 - gender_output_acc: 0.8996 - image_quality_output_acc: 0.5649 - age_output_acc: 0.4489 - weight_output_acc: 0.6565 - bag_output_acc: 0.6915 - footwear_output_acc: 0.6672 - pose_output_acc: 0.8599 - emotion_output_acc: 0.7107Epoch 1/100\n",
            "360/360 [==============================] - 422s 1s/step - loss: 6.0177 - gender_output_loss: 0.2446 - image_quality_output_loss: 0.9298 - age_output_loss: 1.2604 - weight_output_loss: 0.8778 - bag_output_loss: 0.7326 - footwear_output_loss: 0.7573 - pose_output_loss: 0.3663 - emotion_output_loss: 0.8488 - gender_output_acc: 0.8995 - image_quality_output_acc: 0.5649 - age_output_acc: 0.4487 - weight_output_acc: 0.6562 - bag_output_acc: 0.6912 - footwear_output_acc: 0.6668 - pose_output_acc: 0.8597 - emotion_output_acc: 0.7108 - val_loss: 5.4112 - val_gender_output_loss: 0.1632 - val_image_quality_output_loss: 0.9237 - val_age_output_loss: 1.1435 - val_weight_output_loss: 0.7999 - val_bag_output_loss: 0.6791 - val_footwear_output_loss: 0.6728 - val_pose_output_loss: 0.2210 - val_emotion_output_loss: 0.8081 - val_gender_output_acc: 0.9415 - val_image_quality_output_acc: 0.5706 - val_age_output_acc: 0.4990 - val_weight_output_acc: 0.6759 - val_bag_output_acc: 0.7329 - val_footwear_output_acc: 0.7193 - val_pose_output_acc: 0.9254 - val_emotion_output_acc: 0.7218\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 6.0072 - gender_output_loss: 0.2499 - image_quality_output_loss: 0.9337 - age_output_loss: 1.2593 - weight_output_loss: 0.8797 - bag_output_loss: 0.7344 - footwear_output_loss: 0.7436 - pose_output_loss: 0.3588 - emotion_output_loss: 0.8478 - gender_output_acc: 0.8947 - image_quality_output_acc: 0.5577 - age_output_acc: 0.4432 - weight_output_acc: 0.6526 - bag_output_acc: 0.6953 - footwear_output_acc: 0.6774 - pose_output_acc: 0.8637 - emotion_output_acc: 0.7098 - val_loss: 5.7890 - val_gender_output_loss: 0.1694 - val_image_quality_output_loss: 0.9260 - val_age_output_loss: 1.2203 - val_weight_output_loss: 0.8753 - val_bag_output_loss: 0.7054 - val_footwear_output_loss: 0.7010 - val_pose_output_loss: 0.3748 - val_emotion_output_loss: 0.8167 - val_gender_output_acc: 0.9400 - val_image_quality_output_acc: 0.5801 - val_age_output_acc: 0.4506 - val_weight_output_acc: 0.6517 - val_bag_output_acc: 0.7157 - val_footwear_output_acc: 0.6991 - val_pose_output_acc: 0.8538 - val_emotion_output_acc: 0.7233\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.9728 - gender_output_loss: 0.2475 - image_quality_output_loss: 0.9244 - age_output_loss: 1.2640 - weight_output_loss: 0.8727 - bag_output_loss: 0.7243 - footwear_output_loss: 0.7422 - pose_output_loss: 0.3516 - emotion_output_loss: 0.8459 - gender_output_acc: 0.8967 - image_quality_output_acc: 0.5634 - age_output_acc: 0.4450 - weight_output_acc: 0.6568 - bag_output_acc: 0.7008 - footwear_output_acc: 0.6746 - pose_output_acc: 0.8691 - emotion_output_acc: 0.7105 - val_loss: 5.4765 - val_gender_output_loss: 0.1487 - val_image_quality_output_loss: 0.9081 - val_age_output_loss: 1.1728 - val_weight_output_loss: 0.8221 - val_bag_output_loss: 0.7023 - val_footwear_output_loss: 0.6781 - val_pose_output_loss: 0.2295 - val_emotion_output_loss: 0.8150 - val_gender_output_acc: 0.9491 - val_image_quality_output_acc: 0.5791 - val_age_output_acc: 0.4753 - val_weight_output_acc: 0.6759 - val_bag_output_acc: 0.7208 - val_footwear_output_acc: 0.7107 - val_pose_output_acc: 0.9239 - val_emotion_output_acc: 0.7218\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.9825 - gender_output_loss: 0.2433 - image_quality_output_loss: 0.9314 - age_output_loss: 1.2624 - weight_output_loss: 0.8711 - bag_output_loss: 0.7302 - footwear_output_loss: 0.7424 - pose_output_loss: 0.3560 - emotion_output_loss: 0.8458 - gender_output_acc: 0.8980 - image_quality_output_acc: 0.5610 - age_output_acc: 0.4457 - weight_output_acc: 0.6584 - bag_output_acc: 0.6984 - footwear_output_acc: 0.6753 - pose_output_acc: 0.8661 - emotion_output_acc: 0.7108 - val_loss: 5.4973 - val_gender_output_loss: 0.1555 - val_image_quality_output_loss: 0.9090 - val_age_output_loss: 1.1773 - val_weight_output_loss: 0.8227 - val_bag_output_loss: 0.6849 - val_footwear_output_loss: 0.6940 - val_pose_output_loss: 0.2343 - val_emotion_output_loss: 0.8195 - val_gender_output_acc: 0.9471 - val_image_quality_output_acc: 0.5711 - val_age_output_acc: 0.4743 - val_weight_output_acc: 0.6689 - val_bag_output_acc: 0.7233 - val_footwear_output_acc: 0.7067 - val_pose_output_acc: 0.9249 - val_emotion_output_acc: 0.7223\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.9331 - gender_output_loss: 0.2410 - image_quality_output_loss: 0.9216 - age_output_loss: 1.2499 - weight_output_loss: 0.8697 - bag_output_loss: 0.7209 - footwear_output_loss: 0.7430 - pose_output_loss: 0.3433 - emotion_output_loss: 0.8438 - gender_output_acc: 0.9016 - image_quality_output_acc: 0.5613 - age_output_acc: 0.4516 - weight_output_acc: 0.6571 - bag_output_acc: 0.7017 - footwear_output_acc: 0.6702 - pose_output_acc: 0.8711 - emotion_output_acc: 0.7113 - val_loss: 5.7111 - val_gender_output_loss: 0.1789 - val_image_quality_output_loss: 0.9246 - val_age_output_loss: 1.2079 - val_weight_output_loss: 0.8441 - val_bag_output_loss: 0.7123 - val_footwear_output_loss: 0.7345 - val_pose_output_loss: 0.2901 - val_emotion_output_loss: 0.8186 - val_gender_output_acc: 0.9315 - val_image_quality_output_acc: 0.5691 - val_age_output_acc: 0.4627 - val_weight_output_acc: 0.6618 - val_bag_output_acc: 0.7213 - val_footwear_output_acc: 0.6991 - val_pose_output_acc: 0.8876 - val_emotion_output_acc: 0.7203\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - 356s 988ms/step - loss: 5.9207 - gender_output_loss: 0.2389 - image_quality_output_loss: 0.9220 - age_output_loss: 1.2412 - weight_output_loss: 0.8646 - bag_output_loss: 0.7199 - footwear_output_loss: 0.7435 - pose_output_loss: 0.3438 - emotion_output_loss: 0.8469 - gender_output_acc: 0.8991 - image_quality_output_acc: 0.5605 - age_output_acc: 0.4473 - weight_output_acc: 0.6602 - bag_output_acc: 0.7043 - footwear_output_acc: 0.6713 - pose_output_acc: 0.8701 - emotion_output_acc: 0.7106 - val_loss: 5.5459 - val_gender_output_loss: 0.1470 - val_image_quality_output_loss: 0.9087 - val_age_output_loss: 1.1988 - val_weight_output_loss: 0.8524 - val_bag_output_loss: 0.6889 - val_footwear_output_loss: 0.6844 - val_pose_output_loss: 0.2501 - val_emotion_output_loss: 0.8156 - val_gender_output_acc: 0.9466 - val_image_quality_output_acc: 0.5801 - val_age_output_acc: 0.4602 - val_weight_output_acc: 0.6583 - val_bag_output_acc: 0.7349 - val_footwear_output_acc: 0.7177 - val_pose_output_acc: 0.9078 - val_emotion_output_acc: 0.7218\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - 356s 989ms/step - loss: 5.8928 - gender_output_loss: 0.2324 - image_quality_output_loss: 0.9204 - age_output_loss: 1.2452 - weight_output_loss: 0.8575 - bag_output_loss: 0.7137 - footwear_output_loss: 0.7431 - pose_output_loss: 0.3359 - emotion_output_loss: 0.8445 - gender_output_acc: 0.9065 - image_quality_output_acc: 0.5613 - age_output_acc: 0.4516 - weight_output_acc: 0.6595 - bag_output_acc: 0.7053 - footwear_output_acc: 0.6717 - pose_output_acc: 0.8792 - emotion_output_acc: 0.7102 - val_loss: 5.5393 - val_gender_output_loss: 0.1414 - val_image_quality_output_loss: 0.9324 - val_age_output_loss: 1.1558 - val_weight_output_loss: 0.8286 - val_bag_output_loss: 0.7068 - val_footwear_output_loss: 0.7108 - val_pose_output_loss: 0.2489 - val_emotion_output_loss: 0.8147 - val_gender_output_acc: 0.9536 - val_image_quality_output_acc: 0.5796 - val_age_output_acc: 0.4814 - val_weight_output_acc: 0.6633 - val_bag_output_acc: 0.7188 - val_footwear_output_acc: 0.6915 - val_pose_output_acc: 0.9173 - val_emotion_output_acc: 0.7218\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.8687 - gender_output_loss: 0.2281 - image_quality_output_loss: 0.9179 - age_output_loss: 1.2353 - weight_output_loss: 0.8613 - bag_output_loss: 0.7088 - footwear_output_loss: 0.7397 - pose_output_loss: 0.3346 - emotion_output_loss: 0.8430 - gender_output_acc: 0.9059 - image_quality_output_acc: 0.5659 - age_output_acc: 0.4559 - weight_output_acc: 0.6594 - bag_output_acc: 0.7068 - footwear_output_acc: 0.6762 - pose_output_acc: 0.8748 - emotion_output_acc: 0.7112 - val_loss: 5.6163 - val_gender_output_loss: 0.1437 - val_image_quality_output_loss: 0.9089 - val_age_output_loss: 1.1892 - val_weight_output_loss: 0.8662 - val_bag_output_loss: 0.7128 - val_footwear_output_loss: 0.7028 - val_pose_output_loss: 0.2775 - val_emotion_output_loss: 0.8151 - val_gender_output_acc: 0.9486 - val_image_quality_output_acc: 0.5781 - val_age_output_acc: 0.4738 - val_weight_output_acc: 0.6578 - val_bag_output_acc: 0.7293 - val_footwear_output_acc: 0.7147 - val_pose_output_acc: 0.8987 - val_emotion_output_acc: 0.7228\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - 355s 987ms/step - loss: 5.8555 - gender_output_loss: 0.2269 - image_quality_output_loss: 0.9178 - age_output_loss: 1.2337 - weight_output_loss: 0.8551 - bag_output_loss: 0.7137 - footwear_output_loss: 0.7316 - pose_output_loss: 0.3345 - emotion_output_loss: 0.8422 - gender_output_acc: 0.9061 - image_quality_output_acc: 0.5657 - age_output_acc: 0.4558 - weight_output_acc: 0.6623 - bag_output_acc: 0.7081 - footwear_output_acc: 0.6764 - pose_output_acc: 0.8736 - emotion_output_acc: 0.7112 - val_loss: 5.6069 - val_gender_output_loss: 0.1703 - val_image_quality_output_loss: 0.9242 - val_age_output_loss: 1.1703 - val_weight_output_loss: 0.8354 - val_bag_output_loss: 0.6960 - val_footwear_output_loss: 0.7164 - val_pose_output_loss: 0.2688 - val_emotion_output_loss: 0.8254 - val_gender_output_acc: 0.9395 - val_image_quality_output_acc: 0.5771 - val_age_output_acc: 0.4834 - val_weight_output_acc: 0.6719 - val_bag_output_acc: 0.7339 - val_footwear_output_acc: 0.6976 - val_pose_output_acc: 0.9123 - val_emotion_output_acc: 0.7198\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - 356s 988ms/step - loss: 5.8566 - gender_output_loss: 0.2257 - image_quality_output_loss: 0.9155 - age_output_loss: 1.2378 - weight_output_loss: 0.8555 - bag_output_loss: 0.7092 - footwear_output_loss: 0.7342 - pose_output_loss: 0.3347 - emotion_output_loss: 0.8440 - gender_output_acc: 0.9055 - image_quality_output_acc: 0.5679 - age_output_acc: 0.4498 - weight_output_acc: 0.6611 - bag_output_acc: 0.7106 - footwear_output_acc: 0.6757 - pose_output_acc: 0.8743 - emotion_output_acc: 0.7107 - val_loss: 5.7892 - val_gender_output_loss: 0.2402 - val_image_quality_output_loss: 0.9304 - val_age_output_loss: 1.1650 - val_weight_output_loss: 0.8374 - val_bag_output_loss: 0.7461 - val_footwear_output_loss: 0.7002 - val_pose_output_loss: 0.3438 - val_emotion_output_loss: 0.8261 - val_gender_output_acc: 0.9168 - val_image_quality_output_acc: 0.5862 - val_age_output_acc: 0.4854 - val_weight_output_acc: 0.6658 - val_bag_output_acc: 0.7031 - val_footwear_output_acc: 0.7006 - val_pose_output_acc: 0.8695 - val_emotion_output_acc: 0.7223\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - 357s 990ms/step - loss: 5.8447 - gender_output_loss: 0.2375 - image_quality_output_loss: 0.9148 - age_output_loss: 1.2371 - weight_output_loss: 0.8516 - bag_output_loss: 0.7045 - footwear_output_loss: 0.7308 - pose_output_loss: 0.3274 - emotion_output_loss: 0.8410 - gender_output_acc: 0.9002 - image_quality_output_acc: 0.5652 - age_output_acc: 0.4516 - weight_output_acc: 0.6668 - bag_output_acc: 0.7103 - footwear_output_acc: 0.6792 - pose_output_acc: 0.8774 - emotion_output_acc: 0.7115 - val_loss: 5.7393 - val_gender_output_loss: 0.1658 - val_image_quality_output_loss: 0.9130 - val_age_output_loss: 1.2328 - val_weight_output_loss: 0.8315 - val_bag_output_loss: 0.7700 - val_footwear_output_loss: 0.7182 - val_pose_output_loss: 0.2853 - val_emotion_output_loss: 0.8227 - val_gender_output_acc: 0.9415 - val_image_quality_output_acc: 0.5751 - val_age_output_acc: 0.4481 - val_weight_output_acc: 0.6759 - val_bag_output_acc: 0.6830 - val_footwear_output_acc: 0.6986 - val_pose_output_acc: 0.8972 - val_emotion_output_acc: 0.7208\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - 356s 988ms/step - loss: 5.8148 - gender_output_loss: 0.2269 - image_quality_output_loss: 0.9134 - age_output_loss: 1.2291 - weight_output_loss: 0.8513 - bag_output_loss: 0.7060 - footwear_output_loss: 0.7213 - pose_output_loss: 0.3263 - emotion_output_loss: 0.8406 - gender_output_acc: 0.9085 - image_quality_output_acc: 0.5649 - age_output_acc: 0.4567 - weight_output_acc: 0.6604 - bag_output_acc: 0.7090 - footwear_output_acc: 0.6793 - pose_output_acc: 0.8750 - emotion_output_acc: 0.7109 - val_loss: 5.7686 - val_gender_output_loss: 0.2312 - val_image_quality_output_loss: 0.9464 - val_age_output_loss: 1.1869 - val_weight_output_loss: 0.8463 - val_bag_output_loss: 0.7160 - val_footwear_output_loss: 0.7213 - val_pose_output_loss: 0.2964 - val_emotion_output_loss: 0.8240 - val_gender_output_acc: 0.9052 - val_image_quality_output_acc: 0.5534 - val_age_output_acc: 0.4652 - val_weight_output_acc: 0.6608 - val_bag_output_acc: 0.7268 - val_footwear_output_acc: 0.6830 - val_pose_output_acc: 0.8952 - val_emotion_output_acc: 0.7188\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.7787 - gender_output_loss: 0.2153 - image_quality_output_loss: 0.9097 - age_output_loss: 1.2203 - weight_output_loss: 0.8471 - bag_output_loss: 0.7009 - footwear_output_loss: 0.7227 - pose_output_loss: 0.3230 - emotion_output_loss: 0.8397 - gender_output_acc: 0.9101 - image_quality_output_acc: 0.5671 - age_output_acc: 0.4590 - weight_output_acc: 0.6662 - bag_output_acc: 0.7185 - footwear_output_acc: 0.6827 - pose_output_acc: 0.8807 - emotion_output_acc: 0.7114 - val_loss: 5.7610 - val_gender_output_loss: 0.2203 - val_image_quality_output_loss: 0.9463 - val_age_output_loss: 1.1940 - val_weight_output_loss: 0.8594 - val_bag_output_loss: 0.7026 - val_footwear_output_loss: 0.7214 - val_pose_output_loss: 0.2911 - val_emotion_output_loss: 0.8259 - val_gender_output_acc: 0.9178 - val_image_quality_output_acc: 0.5721 - val_age_output_acc: 0.4632 - val_weight_output_acc: 0.6542 - val_bag_output_acc: 0.7238 - val_footwear_output_acc: 0.6976 - val_pose_output_acc: 0.8967 - val_emotion_output_acc: 0.7203\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.7803 - gender_output_loss: 0.2175 - image_quality_output_loss: 0.9182 - age_output_loss: 1.2231 - weight_output_loss: 0.8469 - bag_output_loss: 0.6895 - footwear_output_loss: 0.7255 - pose_output_loss: 0.3199 - emotion_output_loss: 0.8399 - gender_output_acc: 0.9111 - image_quality_output_acc: 0.5631 - age_output_acc: 0.4591 - weight_output_acc: 0.6642 - bag_output_acc: 0.7227 - footwear_output_acc: 0.6813 - pose_output_acc: 0.8805 - emotion_output_acc: 0.7114 - val_loss: 5.6104 - val_gender_output_loss: 0.1680 - val_image_quality_output_loss: 0.9100 - val_age_output_loss: 1.1823 - val_weight_output_loss: 0.8416 - val_bag_output_loss: 0.7093 - val_footwear_output_loss: 0.7119 - val_pose_output_loss: 0.2712 - val_emotion_output_loss: 0.8161 - val_gender_output_acc: 0.9441 - val_image_quality_output_acc: 0.5736 - val_age_output_acc: 0.4798 - val_weight_output_acc: 0.6598 - val_bag_output_acc: 0.7203 - val_footwear_output_acc: 0.7031 - val_pose_output_acc: 0.9108 - val_emotion_output_acc: 0.7208\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.7682 - gender_output_loss: 0.2172 - image_quality_output_loss: 0.9102 - age_output_loss: 1.2138 - weight_output_loss: 0.8413 - bag_output_loss: 0.6962 - footwear_output_loss: 0.7255 - pose_output_loss: 0.3235 - emotion_output_loss: 0.8404 - gender_output_acc: 0.9128 - image_quality_output_acc: 0.5674 - age_output_acc: 0.4659 - weight_output_acc: 0.6676 - bag_output_acc: 0.7155 - footwear_output_acc: 0.6795 - pose_output_acc: 0.8781 - emotion_output_acc: 0.7102 - val_loss: 5.7636 - val_gender_output_loss: 0.1633 - val_image_quality_output_loss: 0.9525 - val_age_output_loss: 1.2054 - val_weight_output_loss: 0.8374 - val_bag_output_loss: 0.7646 - val_footwear_output_loss: 0.7522 - val_pose_output_loss: 0.2705 - val_emotion_output_loss: 0.8177 - val_gender_output_acc: 0.9456 - val_image_quality_output_acc: 0.5575 - val_age_output_acc: 0.4632 - val_weight_output_acc: 0.6658 - val_bag_output_acc: 0.6920 - val_footwear_output_acc: 0.6976 - val_pose_output_acc: 0.9068 - val_emotion_output_acc: 0.7213\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.7546 - gender_output_loss: 0.2133 - image_quality_output_loss: 0.9095 - age_output_loss: 1.2184 - weight_output_loss: 0.8403 - bag_output_loss: 0.6962 - footwear_output_loss: 0.7245 - pose_output_loss: 0.3161 - emotion_output_loss: 0.8363 - gender_output_acc: 0.9140 - image_quality_output_acc: 0.5687 - age_output_acc: 0.4640 - weight_output_acc: 0.6668 - bag_output_acc: 0.7154 - footwear_output_acc: 0.6816 - pose_output_acc: 0.8839 - emotion_output_acc: 0.7122 - val_loss: 5.6555 - val_gender_output_loss: 0.1759 - val_image_quality_output_loss: 0.9142 - val_age_output_loss: 1.1722 - val_weight_output_loss: 0.8328 - val_bag_output_loss: 0.7244 - val_footwear_output_loss: 0.7270 - val_pose_output_loss: 0.2855 - val_emotion_output_loss: 0.8235 - val_gender_output_acc: 0.9415 - val_image_quality_output_acc: 0.5842 - val_age_output_acc: 0.4748 - val_weight_output_acc: 0.6633 - val_bag_output_acc: 0.7188 - val_footwear_output_acc: 0.6925 - val_pose_output_acc: 0.8962 - val_emotion_output_acc: 0.7203\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.7551 - gender_output_loss: 0.2162 - image_quality_output_loss: 0.9084 - age_output_loss: 1.2171 - weight_output_loss: 0.8412 - bag_output_loss: 0.6949 - footwear_output_loss: 0.7271 - pose_output_loss: 0.3114 - emotion_output_loss: 0.8386 - gender_output_acc: 0.9147 - image_quality_output_acc: 0.5648 - age_output_acc: 0.4571 - weight_output_acc: 0.6643 - bag_output_acc: 0.7150 - footwear_output_acc: 0.6819 - pose_output_acc: 0.8863 - emotion_output_acc: 0.7110 - val_loss: 5.6871 - val_gender_output_loss: 0.1868 - val_image_quality_output_loss: 0.9245 - val_age_output_loss: 1.1970 - val_weight_output_loss: 0.8435 - val_bag_output_loss: 0.7144 - val_footwear_output_loss: 0.7175 - val_pose_output_loss: 0.2877 - val_emotion_output_loss: 0.8157 - val_gender_output_acc: 0.9340 - val_image_quality_output_acc: 0.5817 - val_age_output_acc: 0.4667 - val_weight_output_acc: 0.6714 - val_bag_output_acc: 0.7233 - val_footwear_output_acc: 0.6941 - val_pose_output_acc: 0.9073 - val_emotion_output_acc: 0.7208\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - 356s 988ms/step - loss: 5.7308 - gender_output_loss: 0.2083 - image_quality_output_loss: 0.9052 - age_output_loss: 1.2112 - weight_output_loss: 0.8378 - bag_output_loss: 0.6914 - footwear_output_loss: 0.7202 - pose_output_loss: 0.3152 - emotion_output_loss: 0.8415 - gender_output_acc: 0.9187 - image_quality_output_acc: 0.5699 - age_output_acc: 0.4664 - weight_output_acc: 0.6666 - bag_output_acc: 0.7214 - footwear_output_acc: 0.6819 - pose_output_acc: 0.8826 - emotion_output_acc: 0.7109 - val_loss: 5.6621 - val_gender_output_loss: 0.1707 - val_image_quality_output_loss: 0.9202 - val_age_output_loss: 1.1994 - val_weight_output_loss: 0.8338 - val_bag_output_loss: 0.7033 - val_footwear_output_loss: 0.7376 - val_pose_output_loss: 0.2807 - val_emotion_output_loss: 0.8165 - val_gender_output_acc: 0.9400 - val_image_quality_output_acc: 0.5781 - val_age_output_acc: 0.4773 - val_weight_output_acc: 0.6683 - val_bag_output_acc: 0.7182 - val_footwear_output_acc: 0.6961 - val_pose_output_acc: 0.9032 - val_emotion_output_acc: 0.7193\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.7147 - gender_output_loss: 0.2115 - image_quality_output_loss: 0.9061 - age_output_loss: 1.2113 - weight_output_loss: 0.8334 - bag_output_loss: 0.6806 - footwear_output_loss: 0.7193 - pose_output_loss: 0.3150 - emotion_output_loss: 0.8376 - gender_output_acc: 0.9130 - image_quality_output_acc: 0.5679 - age_output_acc: 0.4615 - weight_output_acc: 0.6672 - bag_output_acc: 0.7251 - footwear_output_acc: 0.6810 - pose_output_acc: 0.8834 - emotion_output_acc: 0.7116 - val_loss: 5.6700 - val_gender_output_loss: 0.1640 - val_image_quality_output_loss: 0.9255 - val_age_output_loss: 1.2113 - val_weight_output_loss: 0.8370 - val_bag_output_loss: 0.7247 - val_footwear_output_loss: 0.7113 - val_pose_output_loss: 0.2748 - val_emotion_output_loss: 0.8214 - val_gender_output_acc: 0.9375 - val_image_quality_output_acc: 0.5680 - val_age_output_acc: 0.4567 - val_weight_output_acc: 0.6658 - val_bag_output_acc: 0.7112 - val_footwear_output_acc: 0.6991 - val_pose_output_acc: 0.9037 - val_emotion_output_acc: 0.7208\n",
            "Epoch 20/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 5.6844 - gender_output_loss: 0.2047 - image_quality_output_loss: 0.9013 - age_output_loss: 1.2099 - weight_output_loss: 0.8281 - bag_output_loss: 0.6849 - footwear_output_loss: 0.7120 - pose_output_loss: 0.3066 - emotion_output_loss: 0.8369 - gender_output_acc: 0.9142 - image_quality_output_acc: 0.5716 - age_output_acc: 0.4665 - weight_output_acc: 0.6683 - bag_output_acc: 0.7202 - footwear_output_acc: 0.6876 - pose_output_acc: 0.8856 - emotion_output_acc: 0.7114Epoch 20/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.6842 - gender_output_loss: 0.2044 - image_quality_output_loss: 0.9018 - age_output_loss: 1.2103 - weight_output_loss: 0.8276 - bag_output_loss: 0.6849 - footwear_output_loss: 0.7120 - pose_output_loss: 0.3064 - emotion_output_loss: 0.8368 - gender_output_acc: 0.9143 - image_quality_output_acc: 0.5714 - age_output_acc: 0.4662 - weight_output_acc: 0.6686 - bag_output_acc: 0.7204 - footwear_output_acc: 0.6877 - pose_output_acc: 0.8858 - emotion_output_acc: 0.7115 - val_loss: 5.7302 - val_gender_output_loss: 0.2155 - val_image_quality_output_loss: 0.9154 - val_age_output_loss: 1.1773 - val_weight_output_loss: 0.8584 - val_bag_output_loss: 0.7397 - val_footwear_output_loss: 0.7174 - val_pose_output_loss: 0.2821 - val_emotion_output_loss: 0.8244 - val_gender_output_acc: 0.9244 - val_image_quality_output_acc: 0.5781 - val_age_output_acc: 0.4844 - val_weight_output_acc: 0.6562 - val_bag_output_acc: 0.7067 - val_footwear_output_acc: 0.7006 - val_pose_output_acc: 0.9032 - val_emotion_output_acc: 0.7198\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.6880 - gender_output_loss: 0.2094 - image_quality_output_loss: 0.9028 - age_output_loss: 1.2084 - weight_output_loss: 0.8256 - bag_output_loss: 0.6771 - footwear_output_loss: 0.7168 - pose_output_loss: 0.3111 - emotion_output_loss: 0.8368 - gender_output_acc: 0.9131 - image_quality_output_acc: 0.5715 - age_output_acc: 0.4648 - weight_output_acc: 0.6699 - bag_output_acc: 0.7253 - footwear_output_acc: 0.6885 - pose_output_acc: 0.8824 - emotion_output_acc: 0.7116 - val_loss: 5.7420 - val_gender_output_loss: 0.1759 - val_image_quality_output_loss: 0.9169 - val_age_output_loss: 1.1926 - val_weight_output_loss: 0.8862 - val_bag_output_loss: 0.7256 - val_footwear_output_loss: 0.7090 - val_pose_output_loss: 0.3162 - val_emotion_output_loss: 0.8198 - val_gender_output_acc: 0.9315 - val_image_quality_output_acc: 0.5781 - val_age_output_acc: 0.4682 - val_weight_output_acc: 0.6341 - val_bag_output_acc: 0.7157 - val_footwear_output_acc: 0.7036 - val_pose_output_acc: 0.8926 - val_emotion_output_acc: 0.7213\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.6408 - gender_output_loss: 0.2061 - image_quality_output_loss: 0.8945 - age_output_loss: 1.1984 - weight_output_loss: 0.8258 - bag_output_loss: 0.6751 - footwear_output_loss: 0.7132 - pose_output_loss: 0.2940 - emotion_output_loss: 0.8336 - gender_output_acc: 0.9164 - image_quality_output_acc: 0.5766 - age_output_acc: 0.4715 - weight_output_acc: 0.6688 - bag_output_acc: 0.7273 - footwear_output_acc: 0.6865 - pose_output_acc: 0.8915 - emotion_output_acc: 0.7109 - val_loss: 5.6922 - val_gender_output_loss: 0.1589 - val_image_quality_output_loss: 0.9149 - val_age_output_loss: 1.1853 - val_weight_output_loss: 0.8386 - val_bag_output_loss: 0.7473 - val_footwear_output_loss: 0.7218 - val_pose_output_loss: 0.3062 - val_emotion_output_loss: 0.8192 - val_gender_output_acc: 0.9415 - val_image_quality_output_acc: 0.5721 - val_age_output_acc: 0.4808 - val_weight_output_acc: 0.6643 - val_bag_output_acc: 0.6956 - val_footwear_output_acc: 0.6890 - val_pose_output_acc: 0.8926 - val_emotion_output_acc: 0.7213\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.6361 - gender_output_loss: 0.2012 - image_quality_output_loss: 0.8935 - age_output_loss: 1.1943 - weight_output_loss: 0.8225 - bag_output_loss: 0.6712 - footwear_output_loss: 0.7162 - pose_output_loss: 0.3018 - emotion_output_loss: 0.8355 - gender_output_acc: 0.9148 - image_quality_output_acc: 0.5760 - age_output_acc: 0.4734 - weight_output_acc: 0.6707 - bag_output_acc: 0.7317 - footwear_output_acc: 0.6871 - pose_output_acc: 0.8873 - emotion_output_acc: 0.7105 - val_loss: 5.7196 - val_gender_output_loss: 0.1740 - val_image_quality_output_loss: 0.9250 - val_age_output_loss: 1.1758 - val_weight_output_loss: 0.8418 - val_bag_output_loss: 0.7828 - val_footwear_output_loss: 0.7147 - val_pose_output_loss: 0.2821 - val_emotion_output_loss: 0.8234 - val_gender_output_acc: 0.9415 - val_image_quality_output_acc: 0.5691 - val_age_output_acc: 0.4698 - val_weight_output_acc: 0.6683 - val_bag_output_acc: 0.6860 - val_footwear_output_acc: 0.6976 - val_pose_output_acc: 0.9078 - val_emotion_output_acc: 0.7218\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.6138 - gender_output_loss: 0.1964 - image_quality_output_loss: 0.8928 - age_output_loss: 1.1915 - weight_output_loss: 0.8249 - bag_output_loss: 0.6661 - footwear_output_loss: 0.7061 - pose_output_loss: 0.3023 - emotion_output_loss: 0.8337 - gender_output_acc: 0.9184 - image_quality_output_acc: 0.5753 - age_output_acc: 0.4720 - weight_output_acc: 0.6756 - bag_output_acc: 0.7287 - footwear_output_acc: 0.6874 - pose_output_acc: 0.8859 - emotion_output_acc: 0.7110 - val_loss: 5.8330 - val_gender_output_loss: 0.1721 - val_image_quality_output_loss: 0.9577 - val_age_output_loss: 1.2105 - val_weight_output_loss: 0.8573 - val_bag_output_loss: 0.7548 - val_footwear_output_loss: 0.7409 - val_pose_output_loss: 0.3078 - val_emotion_output_loss: 0.8318 - val_gender_output_acc: 0.9410 - val_image_quality_output_acc: 0.5499 - val_age_output_acc: 0.4753 - val_weight_output_acc: 0.6628 - val_bag_output_acc: 0.7056 - val_footwear_output_acc: 0.6825 - val_pose_output_acc: 0.8886 - val_emotion_output_acc: 0.7193\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.6024 - gender_output_loss: 0.1910 - image_quality_output_loss: 0.8917 - age_output_loss: 1.1939 - weight_output_loss: 0.8179 - bag_output_loss: 0.6645 - footwear_output_loss: 0.7062 - pose_output_loss: 0.3029 - emotion_output_loss: 0.8342 - gender_output_acc: 0.9232 - image_quality_output_acc: 0.5721 - age_output_acc: 0.4729 - weight_output_acc: 0.6691 - bag_output_acc: 0.7306 - footwear_output_acc: 0.6903 - pose_output_acc: 0.8878 - emotion_output_acc: 0.7105 - val_loss: 5.7097 - val_gender_output_loss: 0.1801 - val_image_quality_output_loss: 0.9157 - val_age_output_loss: 1.1697 - val_weight_output_loss: 0.8525 - val_bag_output_loss: 0.7730 - val_footwear_output_loss: 0.7125 - val_pose_output_loss: 0.2784 - val_emotion_output_loss: 0.8278 - val_gender_output_acc: 0.9375 - val_image_quality_output_acc: 0.5877 - val_age_output_acc: 0.4793 - val_weight_output_acc: 0.6568 - val_bag_output_acc: 0.6991 - val_footwear_output_acc: 0.6925 - val_pose_output_acc: 0.9052 - val_emotion_output_acc: 0.7208\n",
            "Epoch 26/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 5.5901 - gender_output_loss: 0.1995 - image_quality_output_loss: 0.8873 - age_output_loss: 1.1850 - weight_output_loss: 0.8166 - bag_output_loss: 0.6617 - footwear_output_loss: 0.7105 - pose_output_loss: 0.2972 - emotion_output_loss: 0.8322 - gender_output_acc: 0.9173 - image_quality_output_acc: 0.5810 - age_output_acc: 0.4808 - weight_output_acc: 0.6719 - bag_output_acc: 0.7352 - footwear_output_acc: 0.6889 - pose_output_acc: 0.8893 - emotion_output_acc: 0.7114Epoch 26/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.5929 - gender_output_loss: 0.2001 - image_quality_output_loss: 0.8877 - age_output_loss: 1.1856 - weight_output_loss: 0.8169 - bag_output_loss: 0.6623 - footwear_output_loss: 0.7106 - pose_output_loss: 0.2972 - emotion_output_loss: 0.8326 - gender_output_acc: 0.9173 - image_quality_output_acc: 0.5808 - age_output_acc: 0.4805 - weight_output_acc: 0.6718 - bag_output_acc: 0.7347 - footwear_output_acc: 0.6886 - pose_output_acc: 0.8893 - emotion_output_acc: 0.7111 - val_loss: 5.8009 - val_gender_output_loss: 0.1880 - val_image_quality_output_loss: 0.9805 - val_age_output_loss: 1.1927 - val_weight_output_loss: 0.8388 - val_bag_output_loss: 0.7326 - val_footwear_output_loss: 0.7337 - val_pose_output_loss: 0.2991 - val_emotion_output_loss: 0.8354 - val_gender_output_acc: 0.9345 - val_image_quality_output_acc: 0.5449 - val_age_output_acc: 0.4773 - val_weight_output_acc: 0.6653 - val_bag_output_acc: 0.7167 - val_footwear_output_acc: 0.6709 - val_pose_output_acc: 0.9002 - val_emotion_output_acc: 0.7117\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.5618 - gender_output_loss: 0.1991 - image_quality_output_loss: 0.8900 - age_output_loss: 1.1801 - weight_output_loss: 0.8075 - bag_output_loss: 0.6620 - footwear_output_loss: 0.6965 - pose_output_loss: 0.2928 - emotion_output_loss: 0.8336 - gender_output_acc: 0.9173 - image_quality_output_acc: 0.5729 - age_output_acc: 0.4792 - weight_output_acc: 0.6753 - bag_output_acc: 0.7302 - footwear_output_acc: 0.6931 - pose_output_acc: 0.8921 - emotion_output_acc: 0.7131 - val_loss: 5.7892 - val_gender_output_loss: 0.1826 - val_image_quality_output_loss: 0.9289 - val_age_output_loss: 1.2046 - val_weight_output_loss: 0.8573 - val_bag_output_loss: 0.7728 - val_footwear_output_loss: 0.7234 - val_pose_output_loss: 0.2952 - val_emotion_output_loss: 0.8244 - val_gender_output_acc: 0.9395 - val_image_quality_output_acc: 0.5670 - val_age_output_acc: 0.4607 - val_weight_output_acc: 0.6562 - val_bag_output_acc: 0.7016 - val_footwear_output_acc: 0.6920 - val_pose_output_acc: 0.8942 - val_emotion_output_acc: 0.7198\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.5736 - gender_output_loss: 0.1920 - image_quality_output_loss: 0.8885 - age_output_loss: 1.1887 - weight_output_loss: 0.8154 - bag_output_loss: 0.6559 - footwear_output_loss: 0.7040 - pose_output_loss: 0.2985 - emotion_output_loss: 0.8305 - gender_output_acc: 0.9213 - image_quality_output_acc: 0.5753 - age_output_acc: 0.4760 - weight_output_acc: 0.6753 - bag_output_acc: 0.7362 - footwear_output_acc: 0.6895 - pose_output_acc: 0.8880 - emotion_output_acc: 0.7122 - val_loss: 5.7044 - val_gender_output_loss: 0.1803 - val_image_quality_output_loss: 0.9331 - val_age_output_loss: 1.1894 - val_weight_output_loss: 0.8355 - val_bag_output_loss: 0.7196 - val_footwear_output_loss: 0.7306 - val_pose_output_loss: 0.2814 - val_emotion_output_loss: 0.8344 - val_gender_output_acc: 0.9370 - val_image_quality_output_acc: 0.5711 - val_age_output_acc: 0.4738 - val_weight_output_acc: 0.6678 - val_bag_output_acc: 0.7082 - val_footwear_output_acc: 0.6870 - val_pose_output_acc: 0.8982 - val_emotion_output_acc: 0.7167\n",
            "Epoch 29/100\n",
            "360/360 [==============================] - 357s 993ms/step - loss: 5.5261 - gender_output_loss: 0.1912 - image_quality_output_loss: 0.8844 - age_output_loss: 1.1758 - weight_output_loss: 0.7987 - bag_output_loss: 0.6542 - footwear_output_loss: 0.7014 - pose_output_loss: 0.2888 - emotion_output_loss: 0.8316 - gender_output_acc: 0.9212 - image_quality_output_acc: 0.5778 - age_output_acc: 0.4800 - weight_output_acc: 0.6795 - bag_output_acc: 0.7347 - footwear_output_acc: 0.6941 - pose_output_acc: 0.8938 - emotion_output_acc: 0.7121 - val_loss: 5.9880 - val_gender_output_loss: 0.1949 - val_image_quality_output_loss: 0.9356 - val_age_output_loss: 1.2472 - val_weight_output_loss: 0.8779 - val_bag_output_loss: 0.8178 - val_footwear_output_loss: 0.7503 - val_pose_output_loss: 0.3234 - val_emotion_output_loss: 0.8409 - val_gender_output_acc: 0.9309 - val_image_quality_output_acc: 0.5877 - val_age_output_acc: 0.4405 - val_weight_output_acc: 0.6401 - val_bag_output_acc: 0.6951 - val_footwear_output_acc: 0.6855 - val_pose_output_acc: 0.8936 - val_emotion_output_acc: 0.7177\n",
            "Epoch 30/100\n",
            "360/360 [==============================] - 359s 997ms/step - loss: 5.5392 - gender_output_loss: 0.1979 - image_quality_output_loss: 0.8872 - age_output_loss: 1.1767 - weight_output_loss: 0.8061 - bag_output_loss: 0.6495 - footwear_output_loss: 0.6996 - pose_output_loss: 0.2912 - emotion_output_loss: 0.8310 - gender_output_acc: 0.9202 - image_quality_output_acc: 0.5772 - age_output_acc: 0.4807 - weight_output_acc: 0.6734 - bag_output_acc: 0.7410 - footwear_output_acc: 0.6950 - pose_output_acc: 0.8901 - emotion_output_acc: 0.7119 - val_loss: 5.8082 - val_gender_output_loss: 0.1990 - val_image_quality_output_loss: 0.9277 - val_age_output_loss: 1.2024 - val_weight_output_loss: 0.8657 - val_bag_output_loss: 0.7358 - val_footwear_output_loss: 0.7403 - val_pose_output_loss: 0.3059 - val_emotion_output_loss: 0.8314 - val_gender_output_acc: 0.9209 - val_image_quality_output_acc: 0.5630 - val_age_output_acc: 0.4738 - val_weight_output_acc: 0.6608 - val_bag_output_acc: 0.7097 - val_footwear_output_acc: 0.6860 - val_pose_output_acc: 0.8851 - val_emotion_output_acc: 0.7177\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 31/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 5.5057 - gender_output_loss: 0.1888 - image_quality_output_loss: 0.8837 - age_output_loss: 1.1702 - weight_output_loss: 0.8047 - bag_output_loss: 0.6482 - footwear_output_loss: 0.6985 - pose_output_loss: 0.2808 - emotion_output_loss: 0.8308 - gender_output_acc: 0.9247 - image_quality_output_acc: 0.5769 - age_output_acc: 0.4878 - weight_output_acc: 0.6812 - bag_output_acc: 0.7407 - footwear_output_acc: 0.6942 - pose_output_acc: 0.8970 - emotion_output_acc: 0.7121 - val_loss: 5.7924 - val_gender_output_loss: 0.1960 - val_image_quality_output_loss: 0.9227 - val_age_output_loss: 1.2129 - val_weight_output_loss: 0.8593 - val_bag_output_loss: 0.7252 - val_footwear_output_loss: 0.7211 - val_pose_output_loss: 0.3289 - val_emotion_output_loss: 0.8262 - val_gender_output_acc: 0.9304 - val_image_quality_output_acc: 0.5696 - val_age_output_acc: 0.4567 - val_weight_output_acc: 0.6583 - val_bag_output_acc: 0.7228 - val_footwear_output_acc: 0.6966 - val_pose_output_acc: 0.8921 - val_emotion_output_acc: 0.7193\n",
            "Epoch 32/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.4830 - gender_output_loss: 0.1836 - image_quality_output_loss: 0.8819 - age_output_loss: 1.1714 - weight_output_loss: 0.7945 - bag_output_loss: 0.6474 - footwear_output_loss: 0.6919 - pose_output_loss: 0.2837 - emotion_output_loss: 0.8288 - gender_output_acc: 0.9240 - image_quality_output_acc: 0.5781 - age_output_acc: 0.4837 - weight_output_acc: 0.6787 - bag_output_acc: 0.7395 - footwear_output_acc: 0.7013 - pose_output_acc: 0.8922 - emotion_output_acc: 0.7109 - val_loss: 5.9812 - val_gender_output_loss: 0.1854 - val_image_quality_output_loss: 0.9426 - val_age_output_loss: 1.2648 - val_weight_output_loss: 0.8743 - val_bag_output_loss: 0.7486 - val_footwear_output_loss: 0.7437 - val_pose_output_loss: 0.3878 - val_emotion_output_loss: 0.8340 - val_gender_output_acc: 0.9345 - val_image_quality_output_acc: 0.5806 - val_age_output_acc: 0.4572 - val_weight_output_acc: 0.6653 - val_bag_output_acc: 0.7182 - val_footwear_output_acc: 0.6910 - val_pose_output_acc: 0.8715 - val_emotion_output_acc: 0.7142\n",
            "Epoch 33/100\n",
            "360/360 [==============================] - 359s 998ms/step - loss: 5.4355 - gender_output_loss: 0.1797 - image_quality_output_loss: 0.8764 - age_output_loss: 1.1606 - weight_output_loss: 0.7867 - bag_output_loss: 0.6363 - footwear_output_loss: 0.6961 - pose_output_loss: 0.2733 - emotion_output_loss: 0.8265 - gender_output_acc: 0.9260 - image_quality_output_acc: 0.5818 - age_output_acc: 0.4857 - weight_output_acc: 0.6798 - bag_output_acc: 0.7454 - footwear_output_acc: 0.6984 - pose_output_acc: 0.8959 - emotion_output_acc: 0.7135 - val_loss: 5.8722 - val_gender_output_loss: 0.2038 - val_image_quality_output_loss: 0.9450 - val_age_output_loss: 1.2123 - val_weight_output_loss: 0.8915 - val_bag_output_loss: 0.7278 - val_footwear_output_loss: 0.7472 - val_pose_output_loss: 0.3141 - val_emotion_output_loss: 0.8305 - val_gender_output_acc: 0.9274 - val_image_quality_output_acc: 0.5645 - val_age_output_acc: 0.4753 - val_weight_output_acc: 0.6608 - val_bag_output_acc: 0.7213 - val_footwear_output_acc: 0.6804 - val_pose_output_acc: 0.8962 - val_emotion_output_acc: 0.7218\n",
            "Epoch 34/100\n",
            "360/360 [==============================] - 358s 994ms/step - loss: 5.4475 - gender_output_loss: 0.1845 - image_quality_output_loss: 0.8722 - age_output_loss: 1.1609 - weight_output_loss: 0.7931 - bag_output_loss: 0.6396 - footwear_output_loss: 0.6899 - pose_output_loss: 0.2769 - emotion_output_loss: 0.8305 - gender_output_acc: 0.9256 - image_quality_output_acc: 0.5872 - age_output_acc: 0.4894 - weight_output_acc: 0.6813 - bag_output_acc: 0.7405 - footwear_output_acc: 0.6961 - pose_output_acc: 0.8961 - emotion_output_acc: 0.7115 - val_loss: 5.9004 - val_gender_output_loss: 0.1705 - val_image_quality_output_loss: 0.9429 - val_age_output_loss: 1.1803 - val_weight_output_loss: 0.8674 - val_bag_output_loss: 0.7597 - val_footwear_output_loss: 0.7467 - val_pose_output_loss: 0.4065 - val_emotion_output_loss: 0.8263 - val_gender_output_acc: 0.9405 - val_image_quality_output_acc: 0.5675 - val_age_output_acc: 0.4657 - val_weight_output_acc: 0.6648 - val_bag_output_acc: 0.7172 - val_footwear_output_acc: 0.6754 - val_pose_output_acc: 0.8594 - val_emotion_output_acc: 0.7162\n",
            "Epoch 35/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.4287 - gender_output_loss: 0.1813 - image_quality_output_loss: 0.8734 - age_output_loss: 1.1593 - weight_output_loss: 0.7942 - bag_output_loss: 0.6334 - footwear_output_loss: 0.6904 - pose_output_loss: 0.2707 - emotion_output_loss: 0.8260 - gender_output_acc: 0.9240 - image_quality_output_acc: 0.5806 - age_output_acc: 0.4891 - weight_output_acc: 0.6832 - bag_output_acc: 0.7445 - footwear_output_acc: 0.6995 - pose_output_acc: 0.8972 - emotion_output_acc: 0.7128 - val_loss: 6.0624 - val_gender_output_loss: 0.2091 - val_image_quality_output_loss: 0.9544 - val_age_output_loss: 1.2777 - val_weight_output_loss: 0.9280 - val_bag_output_loss: 0.7607 - val_footwear_output_loss: 0.7612 - val_pose_output_loss: 0.3343 - val_emotion_output_loss: 0.8369 - val_gender_output_acc: 0.9249 - val_image_quality_output_acc: 0.5650 - val_age_output_acc: 0.4435 - val_weight_output_acc: 0.6613 - val_bag_output_acc: 0.7167 - val_footwear_output_acc: 0.6759 - val_pose_output_acc: 0.8952 - val_emotion_output_acc: 0.7203\n",
            "Epoch 36/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.4338 - gender_output_loss: 0.1860 - image_quality_output_loss: 0.8754 - age_output_loss: 1.1545 - weight_output_loss: 0.7939 - bag_output_loss: 0.6327 - footwear_output_loss: 0.6908 - pose_output_loss: 0.2748 - emotion_output_loss: 0.8257 - gender_output_acc: 0.9235 - image_quality_output_acc: 0.5839 - age_output_acc: 0.4877 - weight_output_acc: 0.6830 - bag_output_acc: 0.7457 - footwear_output_acc: 0.7036 - pose_output_acc: 0.8962 - emotion_output_acc: 0.7127 - val_loss: 5.8878 - val_gender_output_loss: 0.1988 - val_image_quality_output_loss: 1.0040 - val_age_output_loss: 1.2053 - val_weight_output_loss: 0.8673 - val_bag_output_loss: 0.7378 - val_footwear_output_loss: 0.7356 - val_pose_output_loss: 0.3023 - val_emotion_output_loss: 0.8366 - val_gender_output_acc: 0.9345 - val_image_quality_output_acc: 0.5575 - val_age_output_acc: 0.4511 - val_weight_output_acc: 0.6517 - val_bag_output_acc: 0.7167 - val_footwear_output_acc: 0.6855 - val_pose_output_acc: 0.8947 - val_emotion_output_acc: 0.7142\n",
            "Epoch 37/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.3685 - gender_output_loss: 0.1756 - image_quality_output_loss: 0.8662 - age_output_loss: 1.1527 - weight_output_loss: 0.7803 - bag_output_loss: 0.6221 - footwear_output_loss: 0.6836 - pose_output_loss: 0.2665 - emotion_output_loss: 0.8216 - gender_output_acc: 0.9285 - image_quality_output_acc: 0.5878 - age_output_acc: 0.4964 - weight_output_acc: 0.6904 - bag_output_acc: 0.7517 - footwear_output_acc: 0.6987 - pose_output_acc: 0.9016 - emotion_output_acc: 0.7136 - val_loss: 6.1035 - val_gender_output_loss: 0.2479 - val_image_quality_output_loss: 0.9692 - val_age_output_loss: 1.1976 - val_weight_output_loss: 0.8841 - val_bag_output_loss: 0.9037 - val_footwear_output_loss: 0.7445 - val_pose_output_loss: 0.3181 - val_emotion_output_loss: 0.8384 - val_gender_output_acc: 0.9103 - val_image_quality_output_acc: 0.5504 - val_age_output_acc: 0.4778 - val_weight_output_acc: 0.6608 - val_bag_output_acc: 0.6779 - val_footwear_output_acc: 0.6930 - val_pose_output_acc: 0.8942 - val_emotion_output_acc: 0.7203\n",
            "Epoch 38/100\n",
            "360/360 [==============================] - 357s 993ms/step - loss: 5.3747 - gender_output_loss: 0.1869 - image_quality_output_loss: 0.8687 - age_output_loss: 1.1513 - weight_output_loss: 0.7816 - bag_output_loss: 0.6221 - footwear_output_loss: 0.6734 - pose_output_loss: 0.2658 - emotion_output_loss: 0.8249 - gender_output_acc: 0.9224 - image_quality_output_acc: 0.5889 - age_output_acc: 0.4895 - weight_output_acc: 0.6833 - bag_output_acc: 0.7502 - footwear_output_acc: 0.7036 - pose_output_acc: 0.9004 - emotion_output_acc: 0.7132 - val_loss: 5.8819 - val_gender_output_loss: 0.2035 - val_image_quality_output_loss: 0.9459 - val_age_output_loss: 1.1912 - val_weight_output_loss: 0.8760 - val_bag_output_loss: 0.7554 - val_footwear_output_loss: 0.7597 - val_pose_output_loss: 0.3150 - val_emotion_output_loss: 0.8352 - val_gender_output_acc: 0.9274 - val_image_quality_output_acc: 0.5605 - val_age_output_acc: 0.4884 - val_weight_output_acc: 0.6583 - val_bag_output_acc: 0.7072 - val_footwear_output_acc: 0.6845 - val_pose_output_acc: 0.8861 - val_emotion_output_acc: 0.7137\n",
            "Epoch 39/100\n",
            "360/360 [==============================] - 356s 989ms/step - loss: 5.3324 - gender_output_loss: 0.1660 - image_quality_output_loss: 0.8657 - age_output_loss: 1.1478 - weight_output_loss: 0.7767 - bag_output_loss: 0.6159 - footwear_output_loss: 0.6723 - pose_output_loss: 0.2626 - emotion_output_loss: 0.8254 - gender_output_acc: 0.9316 - image_quality_output_acc: 0.5850 - age_output_acc: 0.4976 - weight_output_acc: 0.6852 - bag_output_acc: 0.7573 - footwear_output_acc: 0.7062 - pose_output_acc: 0.9021 - emotion_output_acc: 0.7120 - val_loss: 5.8969 - val_gender_output_loss: 0.1955 - val_image_quality_output_loss: 0.9584 - val_age_output_loss: 1.2281 - val_weight_output_loss: 0.8694 - val_bag_output_loss: 0.7255 - val_footwear_output_loss: 0.7466 - val_pose_output_loss: 0.3371 - val_emotion_output_loss: 0.8364 - val_gender_output_acc: 0.9340 - val_image_quality_output_acc: 0.5549 - val_age_output_acc: 0.4748 - val_weight_output_acc: 0.6547 - val_bag_output_acc: 0.7213 - val_footwear_output_acc: 0.6794 - val_pose_output_acc: 0.8896 - val_emotion_output_acc: 0.7162\n",
            "Epoch 40/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.3444 - gender_output_loss: 0.1758 - image_quality_output_loss: 0.8609 - age_output_loss: 1.1447 - weight_output_loss: 0.7858 - bag_output_loss: 0.6142 - footwear_output_loss: 0.6710 - pose_output_loss: 0.2660 - emotion_output_loss: 0.8260 - gender_output_acc: 0.9257 - image_quality_output_acc: 0.5956 - age_output_acc: 0.4990 - weight_output_acc: 0.6858 - bag_output_acc: 0.7549 - footwear_output_acc: 0.7106 - pose_output_acc: 0.9003 - emotion_output_acc: 0.7131 - val_loss: 5.8855 - val_gender_output_loss: 0.1793 - val_image_quality_output_loss: 0.9700 - val_age_output_loss: 1.2076 - val_weight_output_loss: 0.8987 - val_bag_output_loss: 0.7570 - val_footwear_output_loss: 0.7369 - val_pose_output_loss: 0.3037 - val_emotion_output_loss: 0.8323 - val_gender_output_acc: 0.9375 - val_image_quality_output_acc: 0.5585 - val_age_output_acc: 0.4592 - val_weight_output_acc: 0.6285 - val_bag_output_acc: 0.7092 - val_footwear_output_acc: 0.6925 - val_pose_output_acc: 0.8906 - val_emotion_output_acc: 0.7152\n",
            "\n",
            "Epoch 00040: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 41/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.3465 - gender_output_loss: 0.1781 - image_quality_output_loss: 0.8605 - age_output_loss: 1.1478 - weight_output_loss: 0.7773 - bag_output_loss: 0.6199 - footwear_output_loss: 0.6774 - pose_output_loss: 0.2630 - emotion_output_loss: 0.8224 - gender_output_acc: 0.9285 - image_quality_output_acc: 0.5870 - age_output_acc: 0.4944 - weight_output_acc: 0.6872 - bag_output_acc: 0.7524 - footwear_output_acc: 0.7043 - pose_output_acc: 0.9040 - emotion_output_acc: 0.7120 - val_loss: 5.9079 - val_gender_output_loss: 0.1831 - val_image_quality_output_loss: 0.9770 - val_age_output_loss: 1.1998 - val_weight_output_loss: 0.8692 - val_bag_output_loss: 0.7715 - val_footwear_output_loss: 0.7478 - val_pose_output_loss: 0.3216 - val_emotion_output_loss: 0.8380 - val_gender_output_acc: 0.9345 - val_image_quality_output_acc: 0.5474 - val_age_output_acc: 0.4713 - val_weight_output_acc: 0.6527 - val_bag_output_acc: 0.7036 - val_footwear_output_acc: 0.6815 - val_pose_output_acc: 0.8957 - val_emotion_output_acc: 0.7107\n",
            "Epoch 42/100\n",
            "360/360 [==============================] - 357s 993ms/step - loss: 5.3122 - gender_output_loss: 0.1836 - image_quality_output_loss: 0.8626 - age_output_loss: 1.1381 - weight_output_loss: 0.7743 - bag_output_loss: 0.6098 - footwear_output_loss: 0.6708 - pose_output_loss: 0.2540 - emotion_output_loss: 0.8190 - gender_output_acc: 0.9201 - image_quality_output_acc: 0.5912 - age_output_acc: 0.5003 - weight_output_acc: 0.6841 - bag_output_acc: 0.7617 - footwear_output_acc: 0.7101 - pose_output_acc: 0.9065 - emotion_output_acc: 0.7140 - val_loss: 5.8611 - val_gender_output_loss: 0.1946 - val_image_quality_output_loss: 0.9494 - val_age_output_loss: 1.2053 - val_weight_output_loss: 0.8699 - val_bag_output_loss: 0.7508 - val_footwear_output_loss: 0.7419 - val_pose_output_loss: 0.3186 - val_emotion_output_loss: 0.8305 - val_gender_output_acc: 0.9335 - val_image_quality_output_acc: 0.5615 - val_age_output_acc: 0.4768 - val_weight_output_acc: 0.6648 - val_bag_output_acc: 0.7152 - val_footwear_output_acc: 0.6930 - val_pose_output_acc: 0.8936 - val_emotion_output_acc: 0.7198\n",
            "Epoch 43/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.2763 - gender_output_loss: 0.1699 - image_quality_output_loss: 0.8533 - age_output_loss: 1.1341 - weight_output_loss: 0.7680 - bag_output_loss: 0.6076 - footwear_output_loss: 0.6622 - pose_output_loss: 0.2612 - emotion_output_loss: 0.8199 - gender_output_acc: 0.9312 - image_quality_output_acc: 0.5954 - age_output_acc: 0.5027 - weight_output_acc: 0.6911 - bag_output_acc: 0.7587 - footwear_output_acc: 0.7094 - pose_output_acc: 0.9055 - emotion_output_acc: 0.7138 - val_loss: 6.0433 - val_gender_output_loss: 0.2000 - val_image_quality_output_loss: 0.9848 - val_age_output_loss: 1.2177 - val_weight_output_loss: 0.8994 - val_bag_output_loss: 0.7686 - val_footwear_output_loss: 0.7886 - val_pose_output_loss: 0.3449 - val_emotion_output_loss: 0.8393 - val_gender_output_acc: 0.9330 - val_image_quality_output_acc: 0.5534 - val_age_output_acc: 0.4693 - val_weight_output_acc: 0.6507 - val_bag_output_acc: 0.7092 - val_footwear_output_acc: 0.6769 - val_pose_output_acc: 0.8957 - val_emotion_output_acc: 0.7182\n",
            "Epoch 44/100\n",
            "360/360 [==============================] - 359s 996ms/step - loss: 5.2467 - gender_output_loss: 0.1690 - image_quality_output_loss: 0.8528 - age_output_loss: 1.1259 - weight_output_loss: 0.7602 - bag_output_loss: 0.6047 - footwear_output_loss: 0.6662 - pose_output_loss: 0.2511 - emotion_output_loss: 0.8168 - gender_output_acc: 0.9319 - image_quality_output_acc: 0.5948 - age_output_acc: 0.5031 - weight_output_acc: 0.6962 - bag_output_acc: 0.7582 - footwear_output_acc: 0.7089 - pose_output_acc: 0.9084 - emotion_output_acc: 0.7157 - val_loss: 6.0788 - val_gender_output_loss: 0.2067 - val_image_quality_output_loss: 0.9812 - val_age_output_loss: 1.2300 - val_weight_output_loss: 0.8897 - val_bag_output_loss: 0.8073 - val_footwear_output_loss: 0.7678 - val_pose_output_loss: 0.3625 - val_emotion_output_loss: 0.8336 - val_gender_output_acc: 0.9350 - val_image_quality_output_acc: 0.5600 - val_age_output_acc: 0.4758 - val_weight_output_acc: 0.6401 - val_bag_output_acc: 0.7011 - val_footwear_output_acc: 0.6840 - val_pose_output_acc: 0.8891 - val_emotion_output_acc: 0.7182\n",
            "Epoch 45/100\n",
            "360/360 [==============================] - 358s 994ms/step - loss: 5.2343 - gender_output_loss: 0.1669 - image_quality_output_loss: 0.8512 - age_output_loss: 1.1281 - weight_output_loss: 0.7598 - bag_output_loss: 0.5982 - footwear_output_loss: 0.6613 - pose_output_loss: 0.2555 - emotion_output_loss: 0.8133 - gender_output_acc: 0.9332 - image_quality_output_acc: 0.5980 - age_output_acc: 0.5063 - weight_output_acc: 0.6951 - bag_output_acc: 0.7641 - footwear_output_acc: 0.7168 - pose_output_acc: 0.9056 - emotion_output_acc: 0.7132 - val_loss: 6.0181 - val_gender_output_loss: 0.1884 - val_image_quality_output_loss: 0.9626 - val_age_output_loss: 1.2035 - val_weight_output_loss: 0.8758 - val_bag_output_loss: 0.8156 - val_footwear_output_loss: 0.8179 - val_pose_output_loss: 0.3125 - val_emotion_output_loss: 0.8418 - val_gender_output_acc: 0.9400 - val_image_quality_output_acc: 0.5494 - val_age_output_acc: 0.4708 - val_weight_output_acc: 0.6658 - val_bag_output_acc: 0.6986 - val_footwear_output_acc: 0.6421 - val_pose_output_acc: 0.8992 - val_emotion_output_acc: 0.7102\n",
            "Epoch 46/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.2316 - gender_output_loss: 0.1685 - image_quality_output_loss: 0.8438 - age_output_loss: 1.1304 - weight_output_loss: 0.7577 - bag_output_loss: 0.5962 - footwear_output_loss: 0.6588 - pose_output_loss: 0.2566 - emotion_output_loss: 0.8197 - gender_output_acc: 0.9320 - image_quality_output_acc: 0.5996 - age_output_acc: 0.5105 - weight_output_acc: 0.6931 - bag_output_acc: 0.7615 - footwear_output_acc: 0.7120 - pose_output_acc: 0.9029 - emotion_output_acc: 0.7135 - val_loss: 6.1589 - val_gender_output_loss: 0.2053 - val_image_quality_output_loss: 1.0116 - val_age_output_loss: 1.2169 - val_weight_output_loss: 0.8781 - val_bag_output_loss: 0.8007 - val_footwear_output_loss: 0.7744 - val_pose_output_loss: 0.4257 - val_emotion_output_loss: 0.8464 - val_gender_output_acc: 0.9299 - val_image_quality_output_acc: 0.5469 - val_age_output_acc: 0.4758 - val_weight_output_acc: 0.6497 - val_bag_output_acc: 0.7097 - val_footwear_output_acc: 0.6704 - val_pose_output_acc: 0.8553 - val_emotion_output_acc: 0.7077\n",
            "Epoch 47/100\n",
            "360/360 [==============================] - 358s 995ms/step - loss: 5.1874 - gender_output_loss: 0.1683 - image_quality_output_loss: 0.8363 - age_output_loss: 1.1164 - weight_output_loss: 0.7538 - bag_output_loss: 0.5901 - footwear_output_loss: 0.6546 - pose_output_loss: 0.2485 - emotion_output_loss: 0.8194 - gender_output_acc: 0.9294 - image_quality_output_acc: 0.6016 - age_output_acc: 0.5083 - weight_output_acc: 0.6939 - bag_output_acc: 0.7650 - footwear_output_acc: 0.7156 - pose_output_acc: 0.9061 - emotion_output_acc: 0.7141 - val_loss: 6.0703 - val_gender_output_loss: 0.2050 - val_image_quality_output_loss: 1.0405 - val_age_output_loss: 1.2172 - val_weight_output_loss: 0.9141 - val_bag_output_loss: 0.7536 - val_footwear_output_loss: 0.7612 - val_pose_output_loss: 0.3420 - val_emotion_output_loss: 0.8368 - val_gender_output_acc: 0.9304 - val_image_quality_output_acc: 0.5091 - val_age_output_acc: 0.4814 - val_weight_output_acc: 0.6280 - val_bag_output_acc: 0.7051 - val_footwear_output_acc: 0.6779 - val_pose_output_acc: 0.8957 - val_emotion_output_acc: 0.7177\n",
            "Epoch 48/100\n",
            "360/360 [==============================] - 358s 996ms/step - loss: 5.2026 - gender_output_loss: 0.1681 - image_quality_output_loss: 0.8438 - age_output_loss: 1.1179 - weight_output_loss: 0.7557 - bag_output_loss: 0.5872 - footwear_output_loss: 0.6579 - pose_output_loss: 0.2539 - emotion_output_loss: 0.8182 - gender_output_acc: 0.9317 - image_quality_output_acc: 0.5984 - age_output_acc: 0.5040 - weight_output_acc: 0.6993 - bag_output_acc: 0.7696 - footwear_output_acc: 0.7140 - pose_output_acc: 0.9047 - emotion_output_acc: 0.7140 - val_loss: 6.2519 - val_gender_output_loss: 0.2064 - val_image_quality_output_loss: 1.0259 - val_age_output_loss: 1.2093 - val_weight_output_loss: 0.9157 - val_bag_output_loss: 0.9496 - val_footwear_output_loss: 0.7708 - val_pose_output_loss: 0.3422 - val_emotion_output_loss: 0.8319 - val_gender_output_acc: 0.9345 - val_image_quality_output_acc: 0.5423 - val_age_output_acc: 0.4713 - val_weight_output_acc: 0.6391 - val_bag_output_acc: 0.6512 - val_footwear_output_acc: 0.6764 - val_pose_output_acc: 0.8977 - val_emotion_output_acc: 0.7193\n",
            "Epoch 49/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.1866 - gender_output_loss: 0.1667 - image_quality_output_loss: 0.8330 - age_output_loss: 1.1225 - weight_output_loss: 0.7480 - bag_output_loss: 0.5876 - footwear_output_loss: 0.6607 - pose_output_loss: 0.2535 - emotion_output_loss: 0.8146 - gender_output_acc: 0.9307 - image_quality_output_acc: 0.6077 - age_output_acc: 0.5084 - weight_output_acc: 0.6989 - bag_output_acc: 0.7655 - footwear_output_acc: 0.7129 - pose_output_acc: 0.9062 - emotion_output_acc: 0.7150 - val_loss: 6.0594 - val_gender_output_loss: 0.2186 - val_image_quality_output_loss: 0.9658 - val_age_output_loss: 1.2158 - val_weight_output_loss: 0.8852 - val_bag_output_loss: 0.8600 - val_footwear_output_loss: 0.7560 - val_pose_output_loss: 0.3178 - val_emotion_output_loss: 0.8401 - val_gender_output_acc: 0.9315 - val_image_quality_output_acc: 0.5590 - val_age_output_acc: 0.4672 - val_weight_output_acc: 0.6573 - val_bag_output_acc: 0.6925 - val_footwear_output_acc: 0.6850 - val_pose_output_acc: 0.8911 - val_emotion_output_acc: 0.7193\n",
            "Epoch 50/100\n",
            "360/360 [==============================] - 357s 993ms/step - loss: 5.1492 - gender_output_loss: 0.1678 - image_quality_output_loss: 0.8289 - age_output_loss: 1.1121 - weight_output_loss: 0.7516 - bag_output_loss: 0.5786 - footwear_output_loss: 0.6516 - pose_output_loss: 0.2453 - emotion_output_loss: 0.8133 - gender_output_acc: 0.9309 - image_quality_output_acc: 0.6089 - age_output_acc: 0.5078 - weight_output_acc: 0.6974 - bag_output_acc: 0.7705 - footwear_output_acc: 0.7183 - pose_output_acc: 0.9071 - emotion_output_acc: 0.7149 - val_loss: 6.2751 - val_gender_output_loss: 0.2414 - val_image_quality_output_loss: 1.0773 - val_age_output_loss: 1.2246 - val_weight_output_loss: 0.9181 - val_bag_output_loss: 0.8582 - val_footwear_output_loss: 0.7795 - val_pose_output_loss: 0.3379 - val_emotion_output_loss: 0.8381 - val_gender_output_acc: 0.9259 - val_image_quality_output_acc: 0.5030 - val_age_output_acc: 0.4733 - val_weight_output_acc: 0.6628 - val_bag_output_acc: 0.7072 - val_footwear_output_acc: 0.6628 - val_pose_output_acc: 0.8942 - val_emotion_output_acc: 0.7132\n",
            "\n",
            "Epoch 00050: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 51/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.1573 - gender_output_loss: 0.1716 - image_quality_output_loss: 0.8317 - age_output_loss: 1.1076 - weight_output_loss: 0.7511 - bag_output_loss: 0.5744 - footwear_output_loss: 0.6532 - pose_output_loss: 0.2542 - emotion_output_loss: 0.8135 - gender_output_acc: 0.9279 - image_quality_output_acc: 0.6102 - age_output_acc: 0.5114 - weight_output_acc: 0.7023 - bag_output_acc: 0.7765 - footwear_output_acc: 0.7186 - pose_output_acc: 0.9067 - emotion_output_acc: 0.7135 - val_loss: 6.2030 - val_gender_output_loss: 0.2053 - val_image_quality_output_loss: 1.0139 - val_age_output_loss: 1.2721 - val_weight_output_loss: 0.8892 - val_bag_output_loss: 0.8204 - val_footwear_output_loss: 0.8134 - val_pose_output_loss: 0.3520 - val_emotion_output_loss: 0.8366 - val_gender_output_acc: 0.9289 - val_image_quality_output_acc: 0.5428 - val_age_output_acc: 0.4350 - val_weight_output_acc: 0.6447 - val_bag_output_acc: 0.6895 - val_footwear_output_acc: 0.6825 - val_pose_output_acc: 0.8916 - val_emotion_output_acc: 0.7157\n",
            "Epoch 52/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.1573 - gender_output_loss: 0.1716 - image_quality_output_loss: 0.8317 - age_output_loss: 1.1076 - weight_output_loss: 0.7511 - bag_output_loss: 0.5744 - footwear_output_loss: 0.6532 - pose_output_loss: 0.2542 - emotion_output_loss: 0.8135 - gender_output_acc: 0.9279 - image_quality_output_acc: 0.6102 - age_output_acc: 0.5114 - weight_output_acc: 0.7023 - bag_output_acc: 0.7765 - footwear_output_acc: 0.7186 - pose_output_acc: 0.9067 - emotion_output_acc: 0.7135 - val_loss: 6.2030 - val_gender_output_loss: 0.2053 - val_image_quality_output_loss: 1.0139 - val_age_output_loss: 1.2721 - val_weight_output_loss: 0.8892 - val_bag_output_loss: 0.8204 - val_footwear_output_loss: 0.8134 - val_pose_output_loss: 0.3520 - val_emotion_output_loss: 0.8366 - val_gender_output_acc: 0.9289 - val_image_quality_output_acc: 0.5428 - val_age_output_acc: 0.4350 - val_weight_output_acc: 0.6447 - val_bag_output_acc: 0.6895 - val_footwear_output_acc: 0.6825 - val_pose_output_acc: 0.8916 - val_emotion_output_acc: 0.7157\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 5.0972 - gender_output_loss: 0.1582 - image_quality_output_loss: 0.8325 - age_output_loss: 1.1093 - weight_output_loss: 0.7392 - bag_output_loss: 0.5718 - footwear_output_loss: 0.6385 - pose_output_loss: 0.2350 - emotion_output_loss: 0.8128 - gender_output_acc: 0.9365 - image_quality_output_acc: 0.6080 - age_output_acc: 0.5150 - weight_output_acc: 0.7035 - bag_output_acc: 0.7720 - footwear_output_acc: 0.7201 - pose_output_acc: 0.9122 - emotion_output_acc: 0.7138 - val_loss: 6.1381 - val_gender_output_loss: 0.2140 - val_image_quality_output_loss: 0.9895 - val_age_output_loss: 1.2167 - val_weight_output_loss: 0.9138 - val_bag_output_loss: 0.8291 - val_footwear_output_loss: 0.7950 - val_pose_output_loss: 0.3510 - val_emotion_output_loss: 0.8290 - val_gender_output_acc: 0.9315 - val_image_quality_output_acc: 0.5514 - val_age_output_acc: 0.4662 - val_weight_output_acc: 0.6300 - val_bag_output_acc: 0.6956 - val_footwear_output_acc: 0.6880 - val_pose_output_acc: 0.8911 - val_emotion_output_acc: 0.7218\n",
            "Epoch 53/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 5.0648 - gender_output_loss: 0.1610 - image_quality_output_loss: 0.8230 - age_output_loss: 1.0977 - weight_output_loss: 0.7351 - bag_output_loss: 0.5585 - footwear_output_loss: 0.6365 - pose_output_loss: 0.2396 - emotion_output_loss: 0.8134 - gender_output_acc: 0.9324 - image_quality_output_acc: 0.6122 - age_output_acc: 0.5203 - weight_output_acc: 0.7062 - bag_output_acc: 0.7796 - footwear_output_acc: 0.7254 - pose_output_acc: 0.9117 - emotion_output_acc: 0.7134\n",
            "360/360 [==============================] - 357s 993ms/step - loss: 5.0646 - gender_output_loss: 0.1611 - image_quality_output_loss: 0.8233 - age_output_loss: 1.0980 - weight_output_loss: 0.7348 - bag_output_loss: 0.5581 - footwear_output_loss: 0.6364 - pose_output_loss: 0.2394 - emotion_output_loss: 0.8134 - gender_output_acc: 0.9322 - image_quality_output_acc: 0.6118 - age_output_acc: 0.5201 - weight_output_acc: 0.7064 - bag_output_acc: 0.7798 - footwear_output_acc: 0.7253 - pose_output_acc: 0.9118 - emotion_output_acc: 0.7134 - val_loss: 6.1715 - val_gender_output_loss: 0.2273 - val_image_quality_output_loss: 1.0135 - val_age_output_loss: 1.2273 - val_weight_output_loss: 0.9043 - val_bag_output_loss: 0.8110 - val_footwear_output_loss: 0.8106 - val_pose_output_loss: 0.3395 - val_emotion_output_loss: 0.8380 - val_gender_output_acc: 0.9309 - val_image_quality_output_acc: 0.5474 - val_age_output_acc: 0.4788 - val_weight_output_acc: 0.6537 - val_bag_output_acc: 0.6855 - val_footwear_output_acc: 0.6527 - val_pose_output_acc: 0.8871 - val_emotion_output_acc: 0.7132\n",
            "Epoch 54/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 5.0402 - gender_output_loss: 0.1539 - image_quality_output_loss: 0.8157 - age_output_loss: 1.0903 - weight_output_loss: 0.7315 - bag_output_loss: 0.5642 - footwear_output_loss: 0.6327 - pose_output_loss: 0.2394 - emotion_output_loss: 0.8125 - gender_output_acc: 0.9391 - image_quality_output_acc: 0.6213 - age_output_acc: 0.5162 - weight_output_acc: 0.7069 - bag_output_acc: 0.7793 - footwear_output_acc: 0.7283 - pose_output_acc: 0.9107 - emotion_output_acc: 0.7157 - val_loss: 6.1628 - val_gender_output_loss: 0.1956 - val_image_quality_output_loss: 0.9746 - val_age_output_loss: 1.2463 - val_weight_output_loss: 0.9103 - val_bag_output_loss: 0.8392 - val_footwear_output_loss: 0.8183 - val_pose_output_loss: 0.3362 - val_emotion_output_loss: 0.8424 - val_gender_output_acc: 0.9315 - val_image_quality_output_acc: 0.5565 - val_age_output_acc: 0.4471 - val_weight_output_acc: 0.6532 - val_bag_output_acc: 0.7011 - val_footwear_output_acc: 0.6774 - val_pose_output_acc: 0.8901 - val_emotion_output_acc: 0.7177\n",
            "Epoch 55/100\n",
            "360/360 [==============================] - 358s 994ms/step - loss: 5.0289 - gender_output_loss: 0.1584 - image_quality_output_loss: 0.8165 - age_output_loss: 1.0908 - weight_output_loss: 0.7288 - bag_output_loss: 0.5625 - footwear_output_loss: 0.6266 - pose_output_loss: 0.2304 - emotion_output_loss: 0.8150 - gender_output_acc: 0.9357 - image_quality_output_acc: 0.6155 - age_output_acc: 0.5156 - weight_output_acc: 0.7078 - bag_output_acc: 0.7756 - footwear_output_acc: 0.7286 - pose_output_acc: 0.9144 - emotion_output_acc: 0.7129 - val_loss: 6.2795 - val_gender_output_loss: 0.2144 - val_image_quality_output_loss: 0.9996 - val_age_output_loss: 1.2540 - val_weight_output_loss: 0.9633 - val_bag_output_loss: 0.8101 - val_footwear_output_loss: 0.8133 - val_pose_output_loss: 0.3846 - val_emotion_output_loss: 0.8402 - val_gender_output_acc: 0.9355 - val_image_quality_output_acc: 0.5565 - val_age_output_acc: 0.4607 - val_weight_output_acc: 0.6179 - val_bag_output_acc: 0.7036 - val_footwear_output_acc: 0.6568 - val_pose_output_acc: 0.8780 - val_emotion_output_acc: 0.7167\n",
            "Epoch 56/100\n",
            "360/360 [==============================] - 357s 993ms/step - loss: 5.0213 - gender_output_loss: 0.1556 - image_quality_output_loss: 0.8118 - age_output_loss: 1.0898 - weight_output_loss: 0.7312 - bag_output_loss: 0.5610 - footwear_output_loss: 0.6285 - pose_output_loss: 0.2300 - emotion_output_loss: 0.8133 - gender_output_acc: 0.9356 - image_quality_output_acc: 0.6226 - age_output_acc: 0.5211 - weight_output_acc: 0.7034 - bag_output_acc: 0.7776 - footwear_output_acc: 0.7260 - pose_output_acc: 0.9134 - emotion_output_acc: 0.7151 - val_loss: 6.2089 - val_gender_output_loss: 0.2104 - val_image_quality_output_loss: 0.9981 - val_age_output_loss: 1.2362 - val_weight_output_loss: 0.9165 - val_bag_output_loss: 0.8886 - val_footwear_output_loss: 0.7745 - val_pose_output_loss: 0.3428 - val_emotion_output_loss: 0.8418 - val_gender_output_acc: 0.9264 - val_image_quality_output_acc: 0.5388 - val_age_output_acc: 0.4551 - val_weight_output_acc: 0.6552 - val_bag_output_acc: 0.6860 - val_footwear_output_acc: 0.6754 - val_pose_output_acc: 0.8896 - val_emotion_output_acc: 0.7132\n",
            "Epoch 57/100\n",
            "360/360 [==============================] - 359s 998ms/step - loss: 5.0344 - gender_output_loss: 0.1612 - image_quality_output_loss: 0.8078 - age_output_loss: 1.0946 - weight_output_loss: 0.7314 - bag_output_loss: 0.5583 - footwear_output_loss: 0.6337 - pose_output_loss: 0.2400 - emotion_output_loss: 0.8074 - gender_output_acc: 0.9337 - image_quality_output_acc: 0.6185 - age_output_acc: 0.5240 - weight_output_acc: 0.7031 - bag_output_acc: 0.7838 - footwear_output_acc: 0.7237 - pose_output_acc: 0.9107 - emotion_output_acc: 0.7163 - val_loss: 6.2077 - val_gender_output_loss: 0.2041 - val_image_quality_output_loss: 1.0017 - val_age_output_loss: 1.2743 - val_weight_output_loss: 0.9612 - val_bag_output_loss: 0.8119 - val_footwear_output_loss: 0.7762 - val_pose_output_loss: 0.3349 - val_emotion_output_loss: 0.8434 - val_gender_output_acc: 0.9294 - val_image_quality_output_acc: 0.5519 - val_age_output_acc: 0.4572 - val_weight_output_acc: 0.6487 - val_bag_output_acc: 0.6961 - val_footwear_output_acc: 0.6749 - val_pose_output_acc: 0.9022 - val_emotion_output_acc: 0.7142\n",
            "Epoch 58/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 5.0150 - gender_output_loss: 0.1614 - image_quality_output_loss: 0.8068 - age_output_loss: 1.0905 - weight_output_loss: 0.7288 - bag_output_loss: 0.5593 - footwear_output_loss: 0.6237 - pose_output_loss: 0.2372 - emotion_output_loss: 0.8073 - gender_output_acc: 0.9342 - image_quality_output_acc: 0.6192 - age_output_acc: 0.5247 - weight_output_acc: 0.7052 - bag_output_acc: 0.7772 - footwear_output_acc: 0.7261 - pose_output_acc: 0.9099 - emotion_output_acc: 0.7148Epoch 58/100\n",
            "360/360 [==============================] - 358s 995ms/step - loss: 5.0161 - gender_output_loss: 0.1618 - image_quality_output_loss: 0.8071 - age_output_loss: 1.0911 - weight_output_loss: 0.7292 - bag_output_loss: 0.5591 - footwear_output_loss: 0.6232 - pose_output_loss: 0.2378 - emotion_output_loss: 0.8069 - gender_output_acc: 0.9340 - image_quality_output_acc: 0.6191 - age_output_acc: 0.5245 - weight_output_acc: 0.7051 - bag_output_acc: 0.7774 - footwear_output_acc: 0.7265 - pose_output_acc: 0.9097 - emotion_output_acc: 0.7150 - val_loss: 6.2242 - val_gender_output_loss: 0.2036 - val_image_quality_output_loss: 1.0095 - val_age_output_loss: 1.2799 - val_weight_output_loss: 0.9211 - val_bag_output_loss: 0.7942 - val_footwear_output_loss: 0.8281 - val_pose_output_loss: 0.3430 - val_emotion_output_loss: 0.8448 - val_gender_output_acc: 0.9355 - val_image_quality_output_acc: 0.5449 - val_age_output_acc: 0.4451 - val_weight_output_acc: 0.6411 - val_bag_output_acc: 0.7077 - val_footwear_output_acc: 0.6754 - val_pose_output_acc: 0.8926 - val_emotion_output_acc: 0.7177\n",
            "Epoch 59/100\n",
            "360/360 [==============================] - 358s 994ms/step - loss: 4.9638 - gender_output_loss: 0.1545 - image_quality_output_loss: 0.7967 - age_output_loss: 1.0853 - weight_output_loss: 0.7185 - bag_output_loss: 0.5510 - footwear_output_loss: 0.6186 - pose_output_loss: 0.2325 - emotion_output_loss: 0.8067 - gender_output_acc: 0.9339 - image_quality_output_acc: 0.6274 - age_output_acc: 0.5276 - weight_output_acc: 0.7107 - bag_output_acc: 0.7812 - footwear_output_acc: 0.7339 - pose_output_acc: 0.9143 - emotion_output_acc: 0.7168 - val_loss: 6.2641 - val_gender_output_loss: 0.2126 - val_image_quality_output_loss: 0.9987 - val_age_output_loss: 1.2479 - val_weight_output_loss: 0.9143 - val_bag_output_loss: 0.8316 - val_footwear_output_loss: 0.8737 - val_pose_output_loss: 0.3354 - val_emotion_output_loss: 0.8498 - val_gender_output_acc: 0.9325 - val_image_quality_output_acc: 0.5549 - val_age_output_acc: 0.4587 - val_weight_output_acc: 0.6401 - val_bag_output_acc: 0.6966 - val_footwear_output_acc: 0.6714 - val_pose_output_acc: 0.8921 - val_emotion_output_acc: 0.7172\n",
            "Epoch 60/100\n",
            "360/360 [==============================] - 358s 993ms/step - loss: 4.9414 - gender_output_loss: 0.1536 - image_quality_output_loss: 0.7995 - age_output_loss: 1.0698 - weight_output_loss: 0.7048 - bag_output_loss: 0.5520 - footwear_output_loss: 0.6288 - pose_output_loss: 0.2270 - emotion_output_loss: 0.8059 - gender_output_acc: 0.9339 - image_quality_output_acc: 0.6223 - age_output_acc: 0.5305 - weight_output_acc: 0.7175 - bag_output_acc: 0.7796 - footwear_output_acc: 0.7273 - pose_output_acc: 0.9161 - emotion_output_acc: 0.7154 - val_loss: 6.3080 - val_gender_output_loss: 0.2101 - val_image_quality_output_loss: 1.0112 - val_age_output_loss: 1.2609 - val_weight_output_loss: 0.9926 - val_bag_output_loss: 0.8079 - val_footwear_output_loss: 0.7957 - val_pose_output_loss: 0.3768 - val_emotion_output_loss: 0.8528 - val_gender_output_acc: 0.9340 - val_image_quality_output_acc: 0.5559 - val_age_output_acc: 0.4718 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.7006 - val_footwear_output_acc: 0.6815 - val_pose_output_acc: 0.8826 - val_emotion_output_acc: 0.7132\n",
            "\n",
            "Epoch 00060: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 61/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 4.9656 - gender_output_loss: 0.1584 - image_quality_output_loss: 0.7981 - age_output_loss: 1.0848 - weight_output_loss: 0.7214 - bag_output_loss: 0.5465 - footwear_output_loss: 0.6159 - pose_output_loss: 0.2309 - emotion_output_loss: 0.8096 - gender_output_acc: 0.9332 - image_quality_output_acc: 0.6262 - age_output_acc: 0.5260 - weight_output_acc: 0.7105 - bag_output_acc: 0.7831 - footwear_output_acc: 0.7372 - pose_output_acc: 0.9141 - emotion_output_acc: 0.7154 - val_loss: 6.3141 - val_gender_output_loss: 0.2134 - val_image_quality_output_loss: 1.0545 - val_age_output_loss: 1.2303 - val_weight_output_loss: 0.9325 - val_bag_output_loss: 0.8446 - val_footwear_output_loss: 0.8180 - val_pose_output_loss: 0.3757 - val_emotion_output_loss: 0.8450 - val_gender_output_acc: 0.9309 - val_image_quality_output_acc: 0.5292 - val_age_output_acc: 0.4602 - val_weight_output_acc: 0.6568 - val_bag_output_acc: 0.7036 - val_footwear_output_acc: 0.6613 - val_pose_output_acc: 0.8906 - val_emotion_output_acc: 0.7152\n",
            "Epoch 62/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 5.2008 - gender_output_loss: 0.1917 - image_quality_output_loss: 0.8279 - age_output_loss: 1.1265 - weight_output_loss: 0.7470 - bag_output_loss: 0.5834 - footwear_output_loss: 0.6390 - pose_output_loss: 0.2713 - emotion_output_loss: 0.8141 - gender_output_acc: 0.9205 - image_quality_output_acc: 0.6102 - age_output_acc: 0.5022 - weight_output_acc: 0.6949 - bag_output_acc: 0.7659 - footwear_output_acc: 0.7161 - pose_output_acc: 0.8956 - emotion_output_acc: 0.7149Epoch 62/100\n",
            "360/360 [==============================] - 358s 994ms/step - loss: 5.1998 - gender_output_loss: 0.1916 - image_quality_output_loss: 0.8280 - age_output_loss: 1.1262 - weight_output_loss: 0.7472 - bag_output_loss: 0.5828 - footwear_output_loss: 0.6390 - pose_output_loss: 0.2715 - emotion_output_loss: 0.8136 - gender_output_acc: 0.9207 - image_quality_output_acc: 0.6104 - age_output_acc: 0.5023 - weight_output_acc: 0.6949 - bag_output_acc: 0.7662 - footwear_output_acc: 0.7161 - pose_output_acc: 0.8956 - emotion_output_acc: 0.7152 - val_loss: 6.6923 - val_gender_output_loss: 0.2645 - val_image_quality_output_loss: 1.1491 - val_age_output_loss: 1.2800 - val_weight_output_loss: 0.9521 - val_bag_output_loss: 0.9093 - val_footwear_output_loss: 0.9011 - val_pose_output_loss: 0.3630 - val_emotion_output_loss: 0.8734 - val_gender_output_acc: 0.9173 - val_image_quality_output_acc: 0.4859 - val_age_output_acc: 0.4541 - val_weight_output_acc: 0.6673 - val_bag_output_acc: 0.6935 - val_footwear_output_acc: 0.6557 - val_pose_output_acc: 0.8810 - val_emotion_output_acc: 0.7228\n",
            "Epoch 63/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 4.9444 - gender_output_loss: 0.1626 - image_quality_output_loss: 0.8014 - age_output_loss: 1.0774 - weight_output_loss: 0.7175 - bag_output_loss: 0.5399 - footwear_output_loss: 0.6172 - pose_output_loss: 0.2252 - emotion_output_loss: 0.8031 - gender_output_acc: 0.9309 - image_quality_output_acc: 0.6251 - age_output_acc: 0.5307 - weight_output_acc: 0.7100 - bag_output_acc: 0.7924 - footwear_output_acc: 0.7360 - pose_output_acc: 0.9158 - emotion_output_acc: 0.7188 - val_loss: 6.2807 - val_gender_output_loss: 0.2176 - val_image_quality_output_loss: 1.0435 - val_age_output_loss: 1.2435 - val_weight_output_loss: 0.9159 - val_bag_output_loss: 0.8321 - val_footwear_output_loss: 0.8164 - val_pose_output_loss: 0.3606 - val_emotion_output_loss: 0.8509 - val_gender_output_acc: 0.9229 - val_image_quality_output_acc: 0.5358 - val_age_output_acc: 0.4677 - val_weight_output_acc: 0.6467 - val_bag_output_acc: 0.7102 - val_footwear_output_acc: 0.6678 - val_pose_output_acc: 0.8800 - val_emotion_output_acc: 0.7127\n",
            "Epoch 64/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 4.8651 - gender_output_loss: 0.1512 - image_quality_output_loss: 0.7795 - age_output_loss: 1.0645 - weight_output_loss: 0.7045 - bag_output_loss: 0.5275 - footwear_output_loss: 0.6101 - pose_output_loss: 0.2237 - emotion_output_loss: 0.8040 - gender_output_acc: 0.9387 - image_quality_output_acc: 0.6415 - age_output_acc: 0.5339 - weight_output_acc: 0.7147 - bag_output_acc: 0.7902 - footwear_output_acc: 0.7359 - pose_output_acc: 0.9160 - emotion_output_acc: 0.7168 - val_loss: 6.5389 - val_gender_output_loss: 0.2259 - val_image_quality_output_loss: 1.1276 - val_age_output_loss: 1.2585 - val_weight_output_loss: 0.9446 - val_bag_output_loss: 0.9434 - val_footwear_output_loss: 0.8134 - val_pose_output_loss: 0.3668 - val_emotion_output_loss: 0.8588 - val_gender_output_acc: 0.9294 - val_image_quality_output_acc: 0.4970 - val_age_output_acc: 0.4748 - val_weight_output_acc: 0.6305 - val_bag_output_acc: 0.6613 - val_footwear_output_acc: 0.6623 - val_pose_output_acc: 0.8936 - val_emotion_output_acc: 0.7031\n",
            "Epoch 65/100\n",
            "360/360 [==============================] - 358s 993ms/step - loss: 4.8591 - gender_output_loss: 0.1468 - image_quality_output_loss: 0.7777 - age_output_loss: 1.0597 - weight_output_loss: 0.7026 - bag_output_loss: 0.5279 - footwear_output_loss: 0.6147 - pose_output_loss: 0.2263 - emotion_output_loss: 0.8033 - gender_output_acc: 0.9392 - image_quality_output_acc: 0.6377 - age_output_acc: 0.5396 - weight_output_acc: 0.7165 - bag_output_acc: 0.7911 - footwear_output_acc: 0.7364 - pose_output_acc: 0.9150 - emotion_output_acc: 0.7150 - val_loss: 6.2653 - val_gender_output_loss: 0.2042 - val_image_quality_output_loss: 1.0235 - val_age_output_loss: 1.2495 - val_weight_output_loss: 0.9247 - val_bag_output_loss: 0.8358 - val_footwear_output_loss: 0.8223 - val_pose_output_loss: 0.3590 - val_emotion_output_loss: 0.8464 - val_gender_output_acc: 0.9380 - val_image_quality_output_acc: 0.5444 - val_age_output_acc: 0.4672 - val_weight_output_acc: 0.6487 - val_bag_output_acc: 0.6804 - val_footwear_output_acc: 0.6704 - val_pose_output_acc: 0.8826 - val_emotion_output_acc: 0.7167\n",
            "Epoch 66/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 4.8162 - gender_output_loss: 0.1482 - image_quality_output_loss: 0.7759 - age_output_loss: 1.0578 - weight_output_loss: 0.6923 - bag_output_loss: 0.5257 - footwear_output_loss: 0.6016 - pose_output_loss: 0.2177 - emotion_output_loss: 0.7969 - gender_output_acc: 0.9406 - image_quality_output_acc: 0.6371 - age_output_acc: 0.5382 - weight_output_acc: 0.7253 - bag_output_acc: 0.7946 - footwear_output_acc: 0.7391 - pose_output_acc: 0.9179 - emotion_output_acc: 0.7158 - val_loss: 6.3502 - val_gender_output_loss: 0.2107 - val_image_quality_output_loss: 1.0539 - val_age_output_loss: 1.2403 - val_weight_output_loss: 0.9991 - val_bag_output_loss: 0.8223 - val_footwear_output_loss: 0.8236 - val_pose_output_loss: 0.3507 - val_emotion_output_loss: 0.8496 - val_gender_output_acc: 0.9345 - val_image_quality_output_acc: 0.5161 - val_age_output_acc: 0.4884 - val_weight_output_acc: 0.6593 - val_bag_output_acc: 0.6976 - val_footwear_output_acc: 0.6628 - val_pose_output_acc: 0.8856 - val_emotion_output_acc: 0.7162\n",
            "Epoch 67/100\n",
            "360/360 [==============================] - 357s 993ms/step - loss: 4.7921 - gender_output_loss: 0.1446 - image_quality_output_loss: 0.7685 - age_output_loss: 1.0529 - weight_output_loss: 0.6922 - bag_output_loss: 0.5228 - footwear_output_loss: 0.5967 - pose_output_loss: 0.2153 - emotion_output_loss: 0.7991 - gender_output_acc: 0.9416 - image_quality_output_acc: 0.6433 - age_output_acc: 0.5411 - weight_output_acc: 0.7211 - bag_output_acc: 0.7946 - footwear_output_acc: 0.7443 - pose_output_acc: 0.9182 - emotion_output_acc: 0.7155 - val_loss: 6.5395 - val_gender_output_loss: 0.2051 - val_image_quality_output_loss: 1.2048 - val_age_output_loss: 1.2503 - val_weight_output_loss: 0.9271 - val_bag_output_loss: 0.8442 - val_footwear_output_loss: 0.8761 - val_pose_output_loss: 0.3828 - val_emotion_output_loss: 0.8491 - val_gender_output_acc: 0.9375 - val_image_quality_output_acc: 0.4869 - val_age_output_acc: 0.4556 - val_weight_output_acc: 0.6462 - val_bag_output_acc: 0.6885 - val_footwear_output_acc: 0.6678 - val_pose_output_acc: 0.8987 - val_emotion_output_acc: 0.7218\n",
            "Epoch 68/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 4.7552 - gender_output_loss: 0.1393 - image_quality_output_loss: 0.7703 - age_output_loss: 1.0499 - weight_output_loss: 0.6897 - bag_output_loss: 0.4998 - footwear_output_loss: 0.5985 - pose_output_loss: 0.2121 - emotion_output_loss: 0.7956 - gender_output_acc: 0.9433 - image_quality_output_acc: 0.6408 - age_output_acc: 0.5391 - weight_output_acc: 0.7220 - bag_output_acc: 0.8005 - footwear_output_acc: 0.7446 - pose_output_acc: 0.9179 - emotion_output_acc: 0.7162 - val_loss: 6.5695 - val_gender_output_loss: 0.2437 - val_image_quality_output_loss: 1.0592 - val_age_output_loss: 1.2530 - val_weight_output_loss: 0.9592 - val_bag_output_loss: 0.9554 - val_footwear_output_loss: 0.8434 - val_pose_output_loss: 0.4027 - val_emotion_output_loss: 0.8529 - val_gender_output_acc: 0.9189 - val_image_quality_output_acc: 0.5333 - val_age_output_acc: 0.4733 - val_weight_output_acc: 0.6426 - val_bag_output_acc: 0.6668 - val_footwear_output_acc: 0.6578 - val_pose_output_acc: 0.8800 - val_emotion_output_acc: 0.7162\n",
            "Epoch 69/100\n",
            "360/360 [==============================] - 357s 993ms/step - loss: 4.7563 - gender_output_loss: 0.1404 - image_quality_output_loss: 0.7596 - age_output_loss: 1.0442 - weight_output_loss: 0.6954 - bag_output_loss: 0.5099 - footwear_output_loss: 0.5908 - pose_output_loss: 0.2138 - emotion_output_loss: 0.8024 - gender_output_acc: 0.9434 - image_quality_output_acc: 0.6516 - age_output_acc: 0.5481 - weight_output_acc: 0.7165 - bag_output_acc: 0.7972 - footwear_output_acc: 0.7471 - pose_output_acc: 0.9187 - emotion_output_acc: 0.7169 - val_loss: 6.5371 - val_gender_output_loss: 0.2458 - val_image_quality_output_loss: 1.1022 - val_age_output_loss: 1.3172 - val_weight_output_loss: 0.9526 - val_bag_output_loss: 0.8520 - val_footwear_output_loss: 0.8330 - val_pose_output_loss: 0.3800 - val_emotion_output_loss: 0.8544 - val_gender_output_acc: 0.9194 - val_image_quality_output_acc: 0.5146 - val_age_output_acc: 0.4582 - val_weight_output_acc: 0.6457 - val_bag_output_acc: 0.6971 - val_footwear_output_acc: 0.6623 - val_pose_output_acc: 0.8831 - val_emotion_output_acc: 0.7102\n",
            "Epoch 70/100\n",
            "360/360 [==============================] - 358s 993ms/step - loss: 4.7498 - gender_output_loss: 0.1416 - image_quality_output_loss: 0.7638 - age_output_loss: 1.0498 - weight_output_loss: 0.6869 - bag_output_loss: 0.5081 - footwear_output_loss: 0.5889 - pose_output_loss: 0.2104 - emotion_output_loss: 0.8003 - gender_output_acc: 0.9447 - image_quality_output_acc: 0.6453 - age_output_acc: 0.5378 - weight_output_acc: 0.7227 - bag_output_acc: 0.7980 - footwear_output_acc: 0.7431 - pose_output_acc: 0.9223 - emotion_output_acc: 0.7158 - val_loss: 6.6804 - val_gender_output_loss: 0.2170 - val_image_quality_output_loss: 1.1020 - val_age_output_loss: 1.2720 - val_weight_output_loss: 1.0108 - val_bag_output_loss: 0.9528 - val_footwear_output_loss: 0.8674 - val_pose_output_loss: 0.3979 - val_emotion_output_loss: 0.8606 - val_gender_output_acc: 0.9345 - val_image_quality_output_acc: 0.5181 - val_age_output_acc: 0.4506 - val_weight_output_acc: 0.6512 - val_bag_output_acc: 0.6709 - val_footwear_output_acc: 0.6729 - val_pose_output_acc: 0.8861 - val_emotion_output_acc: 0.7137\n",
            "\n",
            "Epoch 00070: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 71/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 4.7156 - gender_output_loss: 0.1448 - image_quality_output_loss: 0.7552 - age_output_loss: 1.0473 - weight_output_loss: 0.6896 - bag_output_loss: 0.4963 - footwear_output_loss: 0.5806 - pose_output_loss: 0.2100 - emotion_output_loss: 0.7920 - gender_output_acc: 0.9386 - image_quality_output_acc: 0.6523 - age_output_acc: 0.5442 - weight_output_acc: 0.7236 - bag_output_acc: 0.8068 - footwear_output_acc: 0.7510 - pose_output_acc: 0.9223 - emotion_output_acc: 0.7181 - val_loss: 6.4557 - val_gender_output_loss: 0.2474 - val_image_quality_output_loss: 1.0453 - val_age_output_loss: 1.2441 - val_weight_output_loss: 0.9290 - val_bag_output_loss: 0.8922 - val_footwear_output_loss: 0.8613 - val_pose_output_loss: 0.3848 - val_emotion_output_loss: 0.8515 - val_gender_output_acc: 0.9133 - val_image_quality_output_acc: 0.5378 - val_age_output_acc: 0.4693 - val_weight_output_acc: 0.6522 - val_bag_output_acc: 0.6809 - val_footwear_output_acc: 0.6648 - val_pose_output_acc: 0.8891 - val_emotion_output_acc: 0.7142\n",
            "Epoch 72/100\n",
            "360/360 [==============================] - 356s 989ms/step - loss: 4.6898 - gender_output_loss: 0.1429 - image_quality_output_loss: 0.7492 - age_output_loss: 1.0413 - weight_output_loss: 0.6786 - bag_output_loss: 0.4926 - footwear_output_loss: 0.5796 - pose_output_loss: 0.2108 - emotion_output_loss: 0.7948 - gender_output_acc: 0.9411 - image_quality_output_acc: 0.6596 - age_output_acc: 0.5517 - weight_output_acc: 0.7280 - bag_output_acc: 0.8068 - footwear_output_acc: 0.7533 - pose_output_acc: 0.9220 - emotion_output_acc: 0.7166 - val_loss: 6.7510 - val_gender_output_loss: 0.2913 - val_image_quality_output_loss: 1.2081 - val_age_output_loss: 1.2552 - val_weight_output_loss: 0.9742 - val_bag_output_loss: 0.9128 - val_footwear_output_loss: 0.8498 - val_pose_output_loss: 0.3975 - val_emotion_output_loss: 0.8622 - val_gender_output_acc: 0.9178 - val_image_quality_output_acc: 0.4859 - val_age_output_acc: 0.4748 - val_weight_output_acc: 0.6452 - val_bag_output_acc: 0.6986 - val_footwear_output_acc: 0.6593 - val_pose_output_acc: 0.8790 - val_emotion_output_acc: 0.7021\n",
            "Epoch 73/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 4.6991 - gender_output_loss: 0.1432 - image_quality_output_loss: 0.7500 - age_output_loss: 1.0390 - weight_output_loss: 0.6838 - bag_output_loss: 0.4922 - footwear_output_loss: 0.5850 - pose_output_loss: 0.2090 - emotion_output_loss: 0.7968 - gender_output_acc: 0.9406 - image_quality_output_acc: 0.6542 - age_output_acc: 0.5440 - weight_output_acc: 0.7254 - bag_output_acc: 0.8072 - footwear_output_acc: 0.7522 - pose_output_acc: 0.9215 - emotion_output_acc: 0.7162 - val_loss: 6.6259 - val_gender_output_loss: 0.2422 - val_image_quality_output_loss: 1.0847 - val_age_output_loss: 1.2929 - val_weight_output_loss: 0.9622 - val_bag_output_loss: 0.8742 - val_footwear_output_loss: 0.8937 - val_pose_output_loss: 0.4185 - val_emotion_output_loss: 0.8576 - val_gender_output_acc: 0.9304 - val_image_quality_output_acc: 0.5393 - val_age_output_acc: 0.4677 - val_weight_output_acc: 0.6527 - val_bag_output_acc: 0.7036 - val_footwear_output_acc: 0.6663 - val_pose_output_acc: 0.8851 - val_emotion_output_acc: 0.7157\n",
            "Epoch 74/100\n",
            "360/360 [==============================] - 359s 997ms/step - loss: 4.6711 - gender_output_loss: 0.1420 - image_quality_output_loss: 0.7469 - age_output_loss: 1.0275 - weight_output_loss: 0.6766 - bag_output_loss: 0.4890 - footwear_output_loss: 0.5767 - pose_output_loss: 0.2152 - emotion_output_loss: 0.7970 - gender_output_acc: 0.9405 - image_quality_output_acc: 0.6579 - age_output_acc: 0.5582 - weight_output_acc: 0.7266 - bag_output_acc: 0.8037 - footwear_output_acc: 0.7482 - pose_output_acc: 0.9182 - emotion_output_acc: 0.7162 - val_loss: 6.5682 - val_gender_output_loss: 0.2260 - val_image_quality_output_loss: 1.0858 - val_age_output_loss: 1.2620 - val_weight_output_loss: 0.9387 - val_bag_output_loss: 0.9313 - val_footwear_output_loss: 0.8895 - val_pose_output_loss: 0.3860 - val_emotion_output_loss: 0.8489 - val_gender_output_acc: 0.9289 - val_image_quality_output_acc: 0.5474 - val_age_output_acc: 0.4748 - val_weight_output_acc: 0.6507 - val_bag_output_acc: 0.6895 - val_footwear_output_acc: 0.6709 - val_pose_output_acc: 0.8831 - val_emotion_output_acc: 0.7122\n",
            "Epoch 75/100\n",
            "360/360 [==============================] - 358s 993ms/step - loss: 4.6509 - gender_output_loss: 0.1421 - image_quality_output_loss: 0.7411 - age_output_loss: 1.0222 - weight_output_loss: 0.6819 - bag_output_loss: 0.4841 - footwear_output_loss: 0.5790 - pose_output_loss: 0.2077 - emotion_output_loss: 0.7928 - gender_output_acc: 0.9411 - image_quality_output_acc: 0.6582 - age_output_acc: 0.5515 - weight_output_acc: 0.7300 - bag_output_acc: 0.8077 - footwear_output_acc: 0.7523 - pose_output_acc: 0.9184 - emotion_output_acc: 0.7190 - val_loss: 6.8697 - val_gender_output_loss: 0.2411 - val_image_quality_output_loss: 1.1105 - val_age_output_loss: 1.3332 - val_weight_output_loss: 1.0392 - val_bag_output_loss: 0.9310 - val_footwear_output_loss: 0.8958 - val_pose_output_loss: 0.4549 - val_emotion_output_loss: 0.8640 - val_gender_output_acc: 0.9274 - val_image_quality_output_acc: 0.5368 - val_age_output_acc: 0.4572 - val_weight_output_acc: 0.6447 - val_bag_output_acc: 0.6769 - val_footwear_output_acc: 0.6643 - val_pose_output_acc: 0.8816 - val_emotion_output_acc: 0.7117\n",
            "Epoch 76/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.6208 - gender_output_loss: 0.1382 - image_quality_output_loss: 0.7361 - age_output_loss: 1.0327 - weight_output_loss: 0.6720 - bag_output_loss: 0.4767 - footwear_output_loss: 0.5737 - pose_output_loss: 0.2044 - emotion_output_loss: 0.7869 - gender_output_acc: 0.9432 - image_quality_output_acc: 0.6652 - age_output_acc: 0.5519 - weight_output_acc: 0.7329 - bag_output_acc: 0.8133 - footwear_output_acc: 0.7538 - pose_output_acc: 0.9252 - emotion_output_acc: 0.7174Epoch 76/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 4.6210 - gender_output_loss: 0.1380 - image_quality_output_loss: 0.7356 - age_output_loss: 1.0329 - weight_output_loss: 0.6717 - bag_output_loss: 0.4768 - footwear_output_loss: 0.5742 - pose_output_loss: 0.2048 - emotion_output_loss: 0.7869 - gender_output_acc: 0.9432 - image_quality_output_acc: 0.6655 - age_output_acc: 0.5517 - weight_output_acc: 0.7332 - bag_output_acc: 0.8134 - footwear_output_acc: 0.7534 - pose_output_acc: 0.9250 - emotion_output_acc: 0.7173 - val_loss: 6.8182 - val_gender_output_loss: 0.2377 - val_image_quality_output_loss: 1.1383 - val_age_output_loss: 1.2538 - val_weight_output_loss: 0.9713 - val_bag_output_loss: 0.9677 - val_footwear_output_loss: 0.9879 - val_pose_output_loss: 0.3946 - val_emotion_output_loss: 0.8669 - val_gender_output_acc: 0.9274 - val_image_quality_output_acc: 0.5222 - val_age_output_acc: 0.4758 - val_weight_output_acc: 0.6391 - val_bag_output_acc: 0.6744 - val_footwear_output_acc: 0.6643 - val_pose_output_acc: 0.8836 - val_emotion_output_acc: 0.7122\n",
            "Epoch 77/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 4.6380 - gender_output_loss: 0.1428 - image_quality_output_loss: 0.7405 - age_output_loss: 1.0264 - weight_output_loss: 0.6716 - bag_output_loss: 0.4873 - footwear_output_loss: 0.5647 - pose_output_loss: 0.2141 - emotion_output_loss: 0.7905 - gender_output_acc: 0.9415 - image_quality_output_acc: 0.6623 - age_output_acc: 0.5512 - weight_output_acc: 0.7305 - bag_output_acc: 0.8089 - footwear_output_acc: 0.7608 - pose_output_acc: 0.9183 - emotion_output_acc: 0.7170 - val_loss: 6.7342 - val_gender_output_loss: 0.2256 - val_image_quality_output_loss: 1.0925 - val_age_output_loss: 1.2945 - val_weight_output_loss: 1.0066 - val_bag_output_loss: 1.0064 - val_footwear_output_loss: 0.8737 - val_pose_output_loss: 0.3812 - val_emotion_output_loss: 0.8536 - val_gender_output_acc: 0.9249 - val_image_quality_output_acc: 0.5267 - val_age_output_acc: 0.4688 - val_weight_output_acc: 0.6562 - val_bag_output_acc: 0.6628 - val_footwear_output_acc: 0.6442 - val_pose_output_acc: 0.8921 - val_emotion_output_acc: 0.7117\n",
            "Epoch 78/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 4.5690 - gender_output_loss: 0.1368 - image_quality_output_loss: 0.7326 - age_output_loss: 1.0113 - weight_output_loss: 0.6673 - bag_output_loss: 0.4694 - footwear_output_loss: 0.5586 - pose_output_loss: 0.2028 - emotion_output_loss: 0.7902 - gender_output_acc: 0.9442 - image_quality_output_acc: 0.6659 - age_output_acc: 0.5630 - weight_output_acc: 0.7332 - bag_output_acc: 0.8155 - footwear_output_acc: 0.7640 - pose_output_acc: 0.9266 - emotion_output_acc: 0.7187 - val_loss: 6.7539 - val_gender_output_loss: 0.2297 - val_image_quality_output_loss: 1.2458 - val_age_output_loss: 1.2654 - val_weight_output_loss: 0.9649 - val_bag_output_loss: 0.8837 - val_footwear_output_loss: 0.9291 - val_pose_output_loss: 0.3846 - val_emotion_output_loss: 0.8507 - val_gender_output_acc: 0.9304 - val_image_quality_output_acc: 0.4803 - val_age_output_acc: 0.4632 - val_weight_output_acc: 0.6331 - val_bag_output_acc: 0.6976 - val_footwear_output_acc: 0.6633 - val_pose_output_acc: 0.8810 - val_emotion_output_acc: 0.7172\n",
            "Epoch 79/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 4.5056 - gender_output_loss: 0.1281 - image_quality_output_loss: 0.7313 - age_output_loss: 1.0038 - weight_output_loss: 0.6488 - bag_output_loss: 0.4638 - footwear_output_loss: 0.5533 - pose_output_loss: 0.1962 - emotion_output_loss: 0.7804 - gender_output_acc: 0.9478 - image_quality_output_acc: 0.6609 - age_output_acc: 0.5684 - weight_output_acc: 0.7365 - bag_output_acc: 0.8199 - footwear_output_acc: 0.7649 - pose_output_acc: 0.9280 - emotion_output_acc: 0.7207 - val_loss: 7.0057 - val_gender_output_loss: 0.2566 - val_image_quality_output_loss: 1.1673 - val_age_output_loss: 1.3401 - val_weight_output_loss: 1.0320 - val_bag_output_loss: 0.9844 - val_footwear_output_loss: 0.9342 - val_pose_output_loss: 0.4206 - val_emotion_output_loss: 0.8704 - val_gender_output_acc: 0.9214 - val_image_quality_output_acc: 0.5186 - val_age_output_acc: 0.4597 - val_weight_output_acc: 0.6583 - val_bag_output_acc: 0.6749 - val_footwear_output_acc: 0.6341 - val_pose_output_acc: 0.8690 - val_emotion_output_acc: 0.6976\n",
            "Epoch 80/100\n",
            "360/360 [==============================] - 356s 990ms/step - loss: 4.5212 - gender_output_loss: 0.1370 - image_quality_output_loss: 0.7245 - age_output_loss: 1.0085 - weight_output_loss: 0.6547 - bag_output_loss: 0.4567 - footwear_output_loss: 0.5465 - pose_output_loss: 0.1996 - emotion_output_loss: 0.7938 - gender_output_acc: 0.9414 - image_quality_output_acc: 0.6714 - age_output_acc: 0.5622 - weight_output_acc: 0.7365 - bag_output_acc: 0.8195 - footwear_output_acc: 0.7668 - pose_output_acc: 0.9269 - emotion_output_acc: 0.7158 - val_loss: 6.9423 - val_gender_output_loss: 0.2981 - val_image_quality_output_loss: 1.1470 - val_age_output_loss: 1.3159 - val_weight_output_loss: 1.0217 - val_bag_output_loss: 0.9525 - val_footwear_output_loss: 0.9088 - val_pose_output_loss: 0.4362 - val_emotion_output_loss: 0.8621 - val_gender_output_acc: 0.9073 - val_image_quality_output_acc: 0.5222 - val_age_output_acc: 0.4743 - val_weight_output_acc: 0.6517 - val_bag_output_acc: 0.6835 - val_footwear_output_acc: 0.6366 - val_pose_output_acc: 0.8800 - val_emotion_output_acc: 0.7046\n",
            "\n",
            "Epoch 00080: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 81/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 4.5012 - gender_output_loss: 0.1398 - image_quality_output_loss: 0.7159 - age_output_loss: 1.0065 - weight_output_loss: 0.6468 - bag_output_loss: 0.4624 - footwear_output_loss: 0.5529 - pose_output_loss: 0.1935 - emotion_output_loss: 0.7834 - gender_output_acc: 0.9424 - image_quality_output_acc: 0.6726 - age_output_acc: 0.5662 - weight_output_acc: 0.7421 - bag_output_acc: 0.8142 - footwear_output_acc: 0.7648 - pose_output_acc: 0.9257 - emotion_output_acc: 0.7208 - val_loss: 7.0357 - val_gender_output_loss: 0.2524 - val_image_quality_output_loss: 1.1774 - val_age_output_loss: 1.3260 - val_weight_output_loss: 1.0221 - val_bag_output_loss: 1.0491 - val_footwear_output_loss: 0.9135 - val_pose_output_loss: 0.4132 - val_emotion_output_loss: 0.8818 - val_gender_output_acc: 0.9279 - val_image_quality_output_acc: 0.5186 - val_age_output_acc: 0.4642 - val_weight_output_acc: 0.6396 - val_bag_output_acc: 0.6825 - val_footwear_output_acc: 0.6507 - val_pose_output_acc: 0.8826 - val_emotion_output_acc: 0.6951\n",
            "Epoch 82/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 4.4649 - gender_output_loss: 0.1327 - image_quality_output_loss: 0.7125 - age_output_loss: 0.9957 - weight_output_loss: 0.6463 - bag_output_loss: 0.4528 - footwear_output_loss: 0.5420 - pose_output_loss: 0.1986 - emotion_output_loss: 0.7844 - gender_output_acc: 0.9452 - image_quality_output_acc: 0.6765 - age_output_acc: 0.5694 - weight_output_acc: 0.7418 - bag_output_acc: 0.8201 - footwear_output_acc: 0.7692 - pose_output_acc: 0.9263 - emotion_output_acc: 0.7201 - val_loss: 6.9632 - val_gender_output_loss: 0.2277 - val_image_quality_output_loss: 1.2116 - val_age_output_loss: 1.3205 - val_weight_output_loss: 1.0215 - val_bag_output_loss: 0.9716 - val_footwear_output_loss: 0.9463 - val_pose_output_loss: 0.3949 - val_emotion_output_loss: 0.8690 - val_gender_output_acc: 0.9289 - val_image_quality_output_acc: 0.5040 - val_age_output_acc: 0.4481 - val_weight_output_acc: 0.6381 - val_bag_output_acc: 0.6845 - val_footwear_output_acc: 0.6593 - val_pose_output_acc: 0.8795 - val_emotion_output_acc: 0.7061\n",
            "Epoch 83/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.4343 - gender_output_loss: 0.1349 - image_quality_output_loss: 0.7097 - age_output_loss: 0.9943 - weight_output_loss: 0.6434 - bag_output_loss: 0.4427 - footwear_output_loss: 0.5361 - pose_output_loss: 0.1918 - emotion_output_loss: 0.7813 - gender_output_acc: 0.9449 - image_quality_output_acc: 0.6790 - age_output_acc: 0.5655 - weight_output_acc: 0.7405 - bag_output_acc: 0.8254 - footwear_output_acc: 0.7681 - pose_output_acc: 0.9277 - emotion_output_acc: 0.7194Epoch 83/100\n",
            "360/360 [==============================] - 357s 992ms/step - loss: 4.4341 - gender_output_loss: 0.1350 - image_quality_output_loss: 0.7096 - age_output_loss: 0.9950 - weight_output_loss: 0.6433 - bag_output_loss: 0.4428 - footwear_output_loss: 0.5359 - pose_output_loss: 0.1916 - emotion_output_loss: 0.7809 - gender_output_acc: 0.9450 - image_quality_output_acc: 0.6791 - age_output_acc: 0.5654 - weight_output_acc: 0.7407 - bag_output_acc: 0.8253 - footwear_output_acc: 0.7681 - pose_output_acc: 0.9278 - emotion_output_acc: 0.7196 - val_loss: 6.9052 - val_gender_output_loss: 0.2470 - val_image_quality_output_loss: 1.1208 - val_age_output_loss: 1.3857 - val_weight_output_loss: 1.0568 - val_bag_output_loss: 0.8961 - val_footwear_output_loss: 0.9013 - val_pose_output_loss: 0.4250 - val_emotion_output_loss: 0.8726 - val_gender_output_acc: 0.9204 - val_image_quality_output_acc: 0.5358 - val_age_output_acc: 0.4380 - val_weight_output_acc: 0.6447 - val_bag_output_acc: 0.6915 - val_footwear_output_acc: 0.6421 - val_pose_output_acc: 0.8816 - val_emotion_output_acc: 0.7132\n",
            "Epoch 84/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.4201 - gender_output_loss: 0.1369 - image_quality_output_loss: 0.6961 - age_output_loss: 0.9932 - weight_output_loss: 0.6416 - bag_output_loss: 0.4430 - footwear_output_loss: 0.5394 - pose_output_loss: 0.1923 - emotion_output_loss: 0.7777 - gender_output_acc: 0.9423 - image_quality_output_acc: 0.6791 - age_output_acc: 0.5720 - weight_output_acc: 0.7440 - bag_output_acc: 0.8267 - footwear_output_acc: 0.7684 - pose_output_acc: 0.9295 - emotion_output_acc: 0.7210\n",
            "360/360 [==============================] - 358s 994ms/step - loss: 4.4200 - gender_output_loss: 0.1368 - image_quality_output_loss: 0.6960 - age_output_loss: 0.9931 - weight_output_loss: 0.6412 - bag_output_loss: 0.4436 - footwear_output_loss: 0.5392 - pose_output_loss: 0.1930 - emotion_output_loss: 0.7771 - gender_output_acc: 0.9424 - image_quality_output_acc: 0.6794 - age_output_acc: 0.5720 - weight_output_acc: 0.7442 - bag_output_acc: 0.8265 - footwear_output_acc: 0.7681 - pose_output_acc: 0.9292 - emotion_output_acc: 0.7214 - val_loss: 7.3381 - val_gender_output_loss: 0.2611 - val_image_quality_output_loss: 1.4780 - val_age_output_loss: 1.3209 - val_weight_output_loss: 0.9912 - val_bag_output_loss: 0.9984 - val_footwear_output_loss: 0.9705 - val_pose_output_loss: 0.4475 - val_emotion_output_loss: 0.8704 - val_gender_output_acc: 0.9199 - val_image_quality_output_acc: 0.4778 - val_age_output_acc: 0.4632 - val_weight_output_acc: 0.6326 - val_bag_output_acc: 0.6915 - val_footwear_output_acc: 0.6689 - val_pose_output_acc: 0.8821 - val_emotion_output_acc: 0.7182\n",
            "Epoch 85/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 4.3619 - gender_output_loss: 0.1271 - image_quality_output_loss: 0.6914 - age_output_loss: 0.9776 - weight_output_loss: 0.6352 - bag_output_loss: 0.4299 - footwear_output_loss: 0.5324 - pose_output_loss: 0.1925 - emotion_output_loss: 0.7757 - gender_output_acc: 0.9481 - image_quality_output_acc: 0.6839 - age_output_acc: 0.5796 - weight_output_acc: 0.7437 - bag_output_acc: 0.8334 - footwear_output_acc: 0.7739 - pose_output_acc: 0.9293 - emotion_output_acc: 0.7217 - val_loss: 6.9736 - val_gender_output_loss: 0.2649 - val_image_quality_output_loss: 1.1492 - val_age_output_loss: 1.3032 - val_weight_output_loss: 1.0080 - val_bag_output_loss: 0.9930 - val_footwear_output_loss: 0.9571 - val_pose_output_loss: 0.4236 - val_emotion_output_loss: 0.8745 - val_gender_output_acc: 0.9289 - val_image_quality_output_acc: 0.5227 - val_age_output_acc: 0.4647 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.6699 - val_footwear_output_acc: 0.6447 - val_pose_output_acc: 0.8810 - val_emotion_output_acc: 0.7102\n",
            "Epoch 86/100\n",
            "360/360 [==============================] - 357s 991ms/step - loss: 4.3619 - gender_output_loss: 0.1271 - image_quality_output_loss: 0.6914 - age_output_loss: 0.9776 - weight_output_loss: 0.6352 - bag_output_loss: 0.4299 - footwear_output_loss: 0.5324 - pose_output_loss: 0.1925 - emotion_output_loss: 0.7757 - gender_output_acc: 0.9481 - image_quality_output_acc: 0.6839 - age_output_acc: 0.5796 - weight_output_acc: 0.7437 - bag_output_acc: 0.8334 - footwear_output_acc: 0.7739 - pose_output_acc: 0.9293 - emotion_output_acc: 0.7217 - val_loss: 6.9736 - val_gender_output_loss: 0.2649 - val_image_quality_output_loss: 1.1492 - val_age_output_loss: 1.3032 - val_weight_output_loss: 1.0080 - val_bag_output_loss: 0.9930 - val_footwear_output_loss: 0.9571 - val_pose_output_loss: 0.4236 - val_emotion_output_loss: 0.8745 - val_gender_output_acc: 0.9289 - val_image_quality_output_acc: 0.5227 - val_age_output_acc: 0.4647 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.6699 - val_footwear_output_acc: 0.6447 - val_pose_output_acc: 0.8810 - val_emotion_output_acc: 0.7102\n",
            "360/360 [==============================] - 356s 988ms/step - loss: 4.3550 - gender_output_loss: 0.1273 - image_quality_output_loss: 0.6879 - age_output_loss: 0.9732 - weight_output_loss: 0.6371 - bag_output_loss: 0.4382 - footwear_output_loss: 0.5206 - pose_output_loss: 0.1924 - emotion_output_loss: 0.7784 - gender_output_acc: 0.9487 - image_quality_output_acc: 0.6902 - age_output_acc: 0.5787 - weight_output_acc: 0.7476 - bag_output_acc: 0.8263 - footwear_output_acc: 0.7776 - pose_output_acc: 0.9280 - emotion_output_acc: 0.7218 - val_loss: 7.3314 - val_gender_output_loss: 0.2608 - val_image_quality_output_loss: 1.3305 - val_age_output_loss: 1.3515 - val_weight_output_loss: 1.0268 - val_bag_output_loss: 1.0687 - val_footwear_output_loss: 0.9872 - val_pose_output_loss: 0.4114 - val_emotion_output_loss: 0.8945 - val_gender_output_acc: 0.9254 - val_image_quality_output_acc: 0.4703 - val_age_output_acc: 0.4577 - val_weight_output_acc: 0.6361 - val_bag_output_acc: 0.6724 - val_footwear_output_acc: 0.6290 - val_pose_output_acc: 0.8826 - val_emotion_output_acc: 0.6935\n",
            "Epoch 87/100\n",
            "360/360 [==============================] - 356s 988ms/step - loss: 4.3559 - gender_output_loss: 0.1360 - image_quality_output_loss: 0.6908 - age_output_loss: 0.9752 - weight_output_loss: 0.6273 - bag_output_loss: 0.4357 - footwear_output_loss: 0.5213 - pose_output_loss: 0.1932 - emotion_output_loss: 0.7765 - gender_output_acc: 0.9446 - image_quality_output_acc: 0.6897 - age_output_acc: 0.5794 - weight_output_acc: 0.7515 - bag_output_acc: 0.8294 - footwear_output_acc: 0.7822 - pose_output_acc: 0.9293 - emotion_output_acc: 0.7216 - val_loss: 7.2954 - val_gender_output_loss: 0.2536 - val_image_quality_output_loss: 1.2193 - val_age_output_loss: 1.3601 - val_weight_output_loss: 1.0702 - val_bag_output_loss: 1.0274 - val_footwear_output_loss: 0.9819 - val_pose_output_loss: 0.4782 - val_emotion_output_loss: 0.9046 - val_gender_output_acc: 0.9269 - val_image_quality_output_acc: 0.5146 - val_age_output_acc: 0.4607 - val_weight_output_acc: 0.6467 - val_bag_output_acc: 0.6683 - val_footwear_output_acc: 0.6517 - val_pose_output_acc: 0.8715 - val_emotion_output_acc: 0.7188\n",
            "Epoch 88/100\n",
            "360/360 [==============================] - 355s 985ms/step - loss: 4.3495 - gender_output_loss: 0.1274 - image_quality_output_loss: 0.6860 - age_output_loss: 0.9749 - weight_output_loss: 0.6362 - bag_output_loss: 0.4433 - footwear_output_loss: 0.5225 - pose_output_loss: 0.1828 - emotion_output_loss: 0.7763 - gender_output_acc: 0.9480 - image_quality_output_acc: 0.6915 - age_output_acc: 0.5715 - weight_output_acc: 0.7453 - bag_output_acc: 0.8250 - footwear_output_acc: 0.7779 - pose_output_acc: 0.9321 - emotion_output_acc: 0.7209 - val_loss: 7.5503 - val_gender_output_loss: 0.2876 - val_image_quality_output_loss: 1.3329 - val_age_output_loss: 1.4356 - val_weight_output_loss: 1.0537 - val_bag_output_loss: 1.0631 - val_footwear_output_loss: 0.9938 - val_pose_output_loss: 0.5106 - val_emotion_output_loss: 0.8730 - val_gender_output_acc: 0.9204 - val_image_quality_output_acc: 0.4934 - val_age_output_acc: 0.4486 - val_weight_output_acc: 0.6376 - val_bag_output_acc: 0.6905 - val_footwear_output_acc: 0.6502 - val_pose_output_acc: 0.8710 - val_emotion_output_acc: 0.7132\n",
            "Epoch 89/100\n",
            "360/360 [==============================] - 354s 983ms/step - loss: 4.3178 - gender_output_loss: 0.1337 - image_quality_output_loss: 0.6737 - age_output_loss: 0.9714 - weight_output_loss: 0.6358 - bag_output_loss: 0.4248 - footwear_output_loss: 0.5173 - pose_output_loss: 0.1871 - emotion_output_loss: 0.7742 - gender_output_acc: 0.9457 - image_quality_output_acc: 0.6958 - age_output_acc: 0.5852 - weight_output_acc: 0.7453 - bag_output_acc: 0.8334 - footwear_output_acc: 0.7814 - pose_output_acc: 0.9293 - emotion_output_acc: 0.7222 - val_loss: 7.3619 - val_gender_output_loss: 0.2975 - val_image_quality_output_loss: 1.2062 - val_age_output_loss: 1.3605 - val_weight_output_loss: 1.0010 - val_bag_output_loss: 1.0657 - val_footwear_output_loss: 1.0317 - val_pose_output_loss: 0.5078 - val_emotion_output_loss: 0.8916 - val_gender_output_acc: 0.8997 - val_image_quality_output_acc: 0.5091 - val_age_output_acc: 0.4340 - val_weight_output_acc: 0.6356 - val_bag_output_acc: 0.6139 - val_footwear_output_acc: 0.6416 - val_pose_output_acc: 0.8558 - val_emotion_output_acc: 0.7132\n",
            "Epoch 90/100\n",
            "360/360 [==============================] - 354s 983ms/step - loss: 4.4073 - gender_output_loss: 0.1379 - image_quality_output_loss: 0.6913 - age_output_loss: 0.9931 - weight_output_loss: 0.6417 - bag_output_loss: 0.4427 - footwear_output_loss: 0.5277 - pose_output_loss: 0.1935 - emotion_output_loss: 0.7795 - gender_output_acc: 0.9425 - image_quality_output_acc: 0.6855 - age_output_acc: 0.5662 - weight_output_acc: 0.7459 - bag_output_acc: 0.8266 - footwear_output_acc: 0.7750 - pose_output_acc: 0.9266 - emotion_output_acc: 0.7219 - val_loss: 7.0097 - val_gender_output_loss: 0.2993 - val_image_quality_output_loss: 1.1982 - val_age_output_loss: 1.3231 - val_weight_output_loss: 1.0090 - val_bag_output_loss: 0.9819 - val_footwear_output_loss: 0.9377 - val_pose_output_loss: 0.3805 - val_emotion_output_loss: 0.8799 - val_gender_output_acc: 0.9163 - val_image_quality_output_acc: 0.5393 - val_age_output_acc: 0.4688 - val_weight_output_acc: 0.6285 - val_bag_output_acc: 0.6774 - val_footwear_output_acc: 0.6386 - val_pose_output_acc: 0.8911 - val_emotion_output_acc: 0.6986\n",
            "\n",
            "Epoch 00090: saving model to /content/gdrive/My Drive/person_attributes.hdf5\n",
            "Epoch 91/100\n",
            "360/360 [==============================] - 355s 986ms/step - loss: 4.2513 - gender_output_loss: 0.1197 - image_quality_output_loss: 0.6641 - age_output_loss: 0.9702 - weight_output_loss: 0.6244 - bag_output_loss: 0.4122 - footwear_output_loss: 0.5149 - pose_output_loss: 0.1740 - emotion_output_loss: 0.7718 - gender_output_acc: 0.9512 - image_quality_output_acc: 0.7003 - age_output_acc: 0.5821 - weight_output_acc: 0.7541 - bag_output_acc: 0.8398 - footwear_output_acc: 0.7840 - pose_output_acc: 0.9345 - emotion_output_acc: 0.7227 - val_loss: 7.2122 - val_gender_output_loss: 0.2484 - val_image_quality_output_loss: 1.2339 - val_age_output_loss: 1.3356 - val_weight_output_loss: 1.0512 - val_bag_output_loss: 1.0573 - val_footwear_output_loss: 0.9805 - val_pose_output_loss: 0.4309 - val_emotion_output_loss: 0.8743 - val_gender_output_acc: 0.9274 - val_image_quality_output_acc: 0.5045 - val_age_output_acc: 0.4456 - val_weight_output_acc: 0.6069 - val_bag_output_acc: 0.6820 - val_footwear_output_acc: 0.6426 - val_pose_output_acc: 0.8841 - val_emotion_output_acc: 0.7021\n",
            "Epoch 92/100\n",
            "360/360 [==============================] - 354s 983ms/step - loss: 4.2093 - gender_output_loss: 0.1224 - image_quality_output_loss: 0.6585 - age_output_loss: 0.9591 - weight_output_loss: 0.6178 - bag_output_loss: 0.4033 - footwear_output_loss: 0.5008 - pose_output_loss: 0.1817 - emotion_output_loss: 0.7657 - gender_output_acc: 0.9505 - image_quality_output_acc: 0.7030 - age_output_acc: 0.5902 - weight_output_acc: 0.7541 - bag_output_acc: 0.8434 - footwear_output_acc: 0.7896 - pose_output_acc: 0.9319 - emotion_output_acc: 0.7278 - val_loss: 7.7708 - val_gender_output_loss: 0.2931 - val_image_quality_output_loss: 1.2479 - val_age_output_loss: 1.4660 - val_weight_output_loss: 1.0966 - val_bag_output_loss: 1.2462 - val_footwear_output_loss: 1.0706 - val_pose_output_loss: 0.4707 - val_emotion_output_loss: 0.8798 - val_gender_output_acc: 0.9259 - val_image_quality_output_acc: 0.5151 - val_age_output_acc: 0.4451 - val_weight_output_acc: 0.6487 - val_bag_output_acc: 0.6779 - val_footwear_output_acc: 0.6517 - val_pose_output_acc: 0.8810 - val_emotion_output_acc: 0.7082\n",
            "Epoch 93/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.2209 - gender_output_loss: 0.1212 - image_quality_output_loss: 0.6634 - age_output_loss: 0.9575 - weight_output_loss: 0.6067 - bag_output_loss: 0.4101 - footwear_output_loss: 0.5066 - pose_output_loss: 0.1844 - emotion_output_loss: 0.7710 - gender_output_acc: 0.9506 - image_quality_output_acc: 0.7018 - age_output_acc: 0.5938 - weight_output_acc: 0.7591 - bag_output_acc: 0.8400 - footwear_output_acc: 0.7900 - pose_output_acc: 0.9325 - emotion_output_acc: 0.7210Epoch 93/100\n",
            "360/360 [==============================] - 354s 984ms/step - loss: 4.2224 - gender_output_loss: 0.1211 - image_quality_output_loss: 0.6633 - age_output_loss: 0.9583 - weight_output_loss: 0.6071 - bag_output_loss: 0.4102 - footwear_output_loss: 0.5068 - pose_output_loss: 0.1846 - emotion_output_loss: 0.7709 - gender_output_acc: 0.9506 - image_quality_output_acc: 0.7017 - age_output_acc: 0.5937 - weight_output_acc: 0.7590 - bag_output_acc: 0.8401 - footwear_output_acc: 0.7900 - pose_output_acc: 0.9324 - emotion_output_acc: 0.7213 - val_loss: 7.2937 - val_gender_output_loss: 0.2748 - val_image_quality_output_loss: 1.2706 - val_age_output_loss: 1.3820 - val_weight_output_loss: 1.0330 - val_bag_output_loss: 1.0413 - val_footwear_output_loss: 0.9769 - val_pose_output_loss: 0.4308 - val_emotion_output_loss: 0.8841 - val_gender_output_acc: 0.9234 - val_image_quality_output_acc: 0.4960 - val_age_output_acc: 0.4491 - val_weight_output_acc: 0.6235 - val_bag_output_acc: 0.6804 - val_footwear_output_acc: 0.6497 - val_pose_output_acc: 0.8876 - val_emotion_output_acc: 0.7082\n",
            "Epoch 94/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.2407 - gender_output_loss: 0.1297 - image_quality_output_loss: 0.6626 - age_output_loss: 0.9644 - weight_output_loss: 0.6116 - bag_output_loss: 0.4094 - footwear_output_loss: 0.5051 - pose_output_loss: 0.1926 - emotion_output_loss: 0.7653 - gender_output_acc: 0.9471 - image_quality_output_acc: 0.7058 - age_output_acc: 0.5812 - weight_output_acc: 0.7588 - bag_output_acc: 0.8390 - footwear_output_acc: 0.7891 - pose_output_acc: 0.9308 - emotion_output_acc: 0.7271Epoch 94/100\n",
            "360/360 [==============================] - 355s 985ms/step - loss: 4.2411 - gender_output_loss: 0.1298 - image_quality_output_loss: 0.6629 - age_output_loss: 0.9643 - weight_output_loss: 0.6115 - bag_output_loss: 0.4092 - footwear_output_loss: 0.5057 - pose_output_loss: 0.1930 - emotion_output_loss: 0.7649 - gender_output_acc: 0.9470 - image_quality_output_acc: 0.7057 - age_output_acc: 0.5815 - weight_output_acc: 0.7586 - bag_output_acc: 0.8391 - footwear_output_acc: 0.7890 - pose_output_acc: 0.9306 - emotion_output_acc: 0.7273 - val_loss: 7.5315 - val_gender_output_loss: 0.2700 - val_image_quality_output_loss: 1.3071 - val_age_output_loss: 1.3732 - val_weight_output_loss: 1.0369 - val_bag_output_loss: 1.1199 - val_footwear_output_loss: 1.0657 - val_pose_output_loss: 0.4747 - val_emotion_output_loss: 0.8841 - val_gender_output_acc: 0.9294 - val_image_quality_output_acc: 0.5071 - val_age_output_acc: 0.4390 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.6769 - val_footwear_output_acc: 0.6421 - val_pose_output_acc: 0.8851 - val_emotion_output_acc: 0.7077\n",
            "Epoch 95/100\n",
            "360/360 [==============================] - 354s 984ms/step - loss: 4.1876 - gender_output_loss: 0.1276 - image_quality_output_loss: 0.6414 - age_output_loss: 0.9499 - weight_output_loss: 0.6144 - bag_output_loss: 0.4055 - footwear_output_loss: 0.5027 - pose_output_loss: 0.1802 - emotion_output_loss: 0.7659 - gender_output_acc: 0.9480 - image_quality_output_acc: 0.7154 - age_output_acc: 0.5863 - weight_output_acc: 0.7501 - bag_output_acc: 0.8360 - footwear_output_acc: 0.7882 - pose_output_acc: 0.9311 - emotion_output_acc: 0.7243 - val_loss: 7.3463 - val_gender_output_loss: 0.3268 - val_image_quality_output_loss: 1.2118 - val_age_output_loss: 1.3405 - val_weight_output_loss: 1.0257 - val_bag_output_loss: 1.0767 - val_footwear_output_loss: 1.0387 - val_pose_output_loss: 0.4518 - val_emotion_output_loss: 0.8744 - val_gender_output_acc: 0.9002 - val_image_quality_output_acc: 0.5071 - val_age_output_acc: 0.4627 - val_weight_output_acc: 0.6356 - val_bag_output_acc: 0.6598 - val_footwear_output_acc: 0.6376 - val_pose_output_acc: 0.8775 - val_emotion_output_acc: 0.7117\n",
            "Epoch 96/100\n",
            "360/360 [==============================] - 355s 986ms/step - loss: 4.1350 - gender_output_loss: 0.1300 - image_quality_output_loss: 0.6378 - age_output_loss: 0.9355 - weight_output_loss: 0.6043 - bag_output_loss: 0.4023 - footwear_output_loss: 0.4777 - pose_output_loss: 0.1796 - emotion_output_loss: 0.7678 - gender_output_acc: 0.9450 - image_quality_output_acc: 0.7072 - age_output_acc: 0.5982 - weight_output_acc: 0.7600 - bag_output_acc: 0.8419 - footwear_output_acc: 0.8016 - pose_output_acc: 0.9332 - emotion_output_acc: 0.7248 - val_loss: 7.6884 - val_gender_output_loss: 0.2809 - val_image_quality_output_loss: 1.4760 - val_age_output_loss: 1.3716 - val_weight_output_loss: 1.0434 - val_bag_output_loss: 1.0308 - val_footwear_output_loss: 1.1456 - val_pose_output_loss: 0.4521 - val_emotion_output_loss: 0.8880 - val_gender_output_acc: 0.9153 - val_image_quality_output_acc: 0.4743 - val_age_output_acc: 0.4612 - val_weight_output_acc: 0.6280 - val_bag_output_acc: 0.6774 - val_footwear_output_acc: 0.6522 - val_pose_output_acc: 0.8861 - val_emotion_output_acc: 0.7127\n",
            "Epoch 97/100\n",
            "360/360 [==============================] - 355s 986ms/step - loss: 4.1350 - gender_output_loss: 0.1300 - image_quality_output_loss: 0.6378 - age_output_loss: 0.9355 - weight_output_loss: 0.6043 - bag_output_loss: 0.4023 - footwear_output_loss: 0.4777 - pose_output_loss: 0.1796 - emotion_output_loss: 0.7678 - gender_output_acc: 0.9450 - image_quality_output_acc: 0.7072 - age_output_acc: 0.5982 - weight_output_acc: 0.7600 - bag_output_acc: 0.8419 - footwear_output_acc: 0.8016 - pose_output_acc: 0.9332 - emotion_output_acc: 0.7248 - val_loss: 7.6884 - val_gender_output_loss: 0.2809 - val_image_quality_output_loss: 1.4760 - val_age_output_loss: 1.3716 - val_weight_output_loss: 1.0434 - val_bag_output_loss: 1.0308 - val_footwear_output_loss: 1.1456 - val_pose_output_loss: 0.4521 - val_emotion_output_loss: 0.8880 - val_gender_output_acc: 0.9153 - val_image_quality_output_acc: 0.4743 - val_age_output_acc: 0.4612 - val_weight_output_acc: 0.6280 - val_bag_output_acc: 0.6774 - val_footwear_output_acc: 0.6522 - val_pose_output_acc: 0.8861 - val_emotion_output_acc: 0.7127\n",
            "360/360 [==============================] - 356s 988ms/step - loss: 4.1303 - gender_output_loss: 0.1242 - image_quality_output_loss: 0.6428 - age_output_loss: 0.9408 - weight_output_loss: 0.6014 - bag_output_loss: 0.3962 - footwear_output_loss: 0.4866 - pose_output_loss: 0.1777 - emotion_output_loss: 0.7606 - gender_output_acc: 0.9493 - image_quality_output_acc: 0.7101 - age_output_acc: 0.5953 - weight_output_acc: 0.7641 - bag_output_acc: 0.8424 - footwear_output_acc: 0.7908 - pose_output_acc: 0.9343 - emotion_output_acc: 0.7247 - val_loss: 7.6029 - val_gender_output_loss: 0.3040 - val_image_quality_output_loss: 1.3685 - val_age_output_loss: 1.3945 - val_weight_output_loss: 1.0456 - val_bag_output_loss: 1.1346 - val_footwear_output_loss: 1.0009 - val_pose_output_loss: 0.4752 - val_emotion_output_loss: 0.8797 - val_gender_output_acc: 0.9178 - val_image_quality_output_acc: 0.5015 - val_age_output_acc: 0.4657 - val_weight_output_acc: 0.6467 - val_bag_output_acc: 0.6603 - val_footwear_output_acc: 0.6472 - val_pose_output_acc: 0.8836 - val_emotion_output_acc: 0.7112\n",
            "Epoch 98/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.1436 - gender_output_loss: 0.1215 - image_quality_output_loss: 0.6373 - age_output_loss: 0.9418 - weight_output_loss: 0.6055 - bag_output_loss: 0.4022 - footwear_output_loss: 0.4910 - pose_output_loss: 0.1810 - emotion_output_loss: 0.7634 - gender_output_acc: 0.9530 - image_quality_output_acc: 0.7153 - age_output_acc: 0.5884 - weight_output_acc: 0.7603 - bag_output_acc: 0.8386 - footwear_output_acc: 0.7960 - pose_output_acc: 0.9334 - emotion_output_acc: 0.7279Epoch 98/100\n",
            "360/360 [==============================] - 354s 984ms/step - loss: 4.1432 - gender_output_loss: 0.1215 - image_quality_output_loss: 0.6383 - age_output_loss: 0.9412 - weight_output_loss: 0.6050 - bag_output_loss: 0.4026 - footwear_output_loss: 0.4907 - pose_output_loss: 0.1807 - emotion_output_loss: 0.7632 - gender_output_acc: 0.9530 - image_quality_output_acc: 0.7148 - age_output_acc: 0.5888 - weight_output_acc: 0.7603 - bag_output_acc: 0.8384 - footwear_output_acc: 0.7960 - pose_output_acc: 0.9335 - emotion_output_acc: 0.7280 - val_loss: 7.4775 - val_gender_output_loss: 0.2729 - val_image_quality_output_loss: 1.2812 - val_age_output_loss: 1.3679 - val_weight_output_loss: 1.0986 - val_bag_output_loss: 1.0880 - val_footwear_output_loss: 1.0543 - val_pose_output_loss: 0.4323 - val_emotion_output_loss: 0.8823 - val_gender_output_acc: 0.9098 - val_image_quality_output_acc: 0.5101 - val_age_output_acc: 0.4461 - val_weight_output_acc: 0.6452 - val_bag_output_acc: 0.6583 - val_footwear_output_acc: 0.6618 - val_pose_output_acc: 0.8861 - val_emotion_output_acc: 0.7122\n",
            "Epoch 99/100\n",
            "279/360 [======================>.......] - ETA: 1:16 - loss: 4.0949 - gender_output_loss: 0.1256 - image_quality_output_loss: 0.6323 - age_output_loss: 0.9217 - weight_output_loss: 0.5998 - bag_output_loss: 0.3998 - footwear_output_loss: 0.4757 - pose_output_loss: 0.1716 - emotion_output_loss: 0.7683 - gender_output_acc: 0.9493 - image_quality_output_acc: 0.7186 - age_output_acc: 0.6002 - weight_output_acc: 0.7605 - bag_output_acc: 0.8422 - footwear_output_acc: 0.8007 - pose_output_acc: 0.9371 - emotion_output_acc: 0.7244"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP5OIiduotdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3OCW3iag5k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}