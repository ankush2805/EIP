{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PersonAttrubutes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankush2805/EIP/blob/master/Tests5/PersonAttrubites.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NblA5eWon8lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_eraser(input_img, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=1, pixel_level=False):\n",
        "  img_h, img_w, img_c = input_img.shape\n",
        "  p_1 = np.random.rand()\n",
        "  if p_1 > p:\n",
        "    return input_img\n",
        "\n",
        "  while True:\n",
        "    s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "    r = np.random.uniform(r_1, r_2)\n",
        "    w = int(np.sqrt(s / r))\n",
        "    h = int(np.sqrt(s * r))\n",
        "    left = np.random.randint(0, img_w)\n",
        "    top = np.random.randint(0, img_h)\n",
        "\n",
        "    if left + w <= img_w and top + h <= img_h:\n",
        "      break\n",
        "\n",
        "    if pixel_level:\n",
        "      c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "    else:\n",
        "      c = np.random.uniform(v_l, v_h)\n",
        "    input_img[top:top + h, left:left + w, :] = c\n",
        "  return input_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH5IpIVun_xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augmentor(images):\n",
        "\t\t'Apply data augmentation'\n",
        "\t\tsometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\t\tseq = iaa.Sequential(\n",
        "\t\t\t\t[\n",
        "\t\t\t\t# apply the following augmenters to most images\n",
        "\t\t\t\tiaa.Fliplr(0.3),  # horizontally flip 50% of all images\n",
        "\t\t\t\tsometimes(iaa.Affine(\n",
        "\t\t\t\t\tscale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
        "\t\t\t\t\t# scale images to 80-120% of their size, individually per axis\n",
        "\t\t\t\t\ttranslate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
        "\t\t\t\t\t# translate by -20 to +20 percent (per axis)\n",
        "\t\t\t\t\trotate=(-10, 10),  # rotate by -45 to +45 degrees\n",
        "\t\t\t\t\tshear=(-5, 5),  # shear by -16 to +16 degrees\n",
        "\t\t\t\t\torder=[0, 1],\n",
        "\t\t\t\t\t# use nearest neighbour or bilinear interpolation (fast)\n",
        "\t\t\t\t\tcval=(0, 255),  # if mode is constant, use a cval between 0 and 255\n",
        "\t\t\t\t\tmode=ia.ALL\n",
        "\t\t\t\t\t# use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "\t\t\t\t)),\n",
        "\t\t\t\t# execute 0 to 5 of the following (less important) augmenters per image\n",
        "\t\t\t\t# don't execute all of them, as that would often be way too strong\n",
        "\t\t\t\tiaa.SomeOf((0, 5),\n",
        "\t\t\t\t           [sometimes(iaa.Superpixels(p_replace=(0, 1.0),\n",
        "\t\t\t\t\t\t                                     n_segments=(20, 200))),\n",
        "\t\t\t\t\t           # convert images into their superpixel representation\n",
        "\t\t\t\t\t           iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.GaussianBlur((0, 1.0)),\n",
        "\t\t\t\t\t\t\t           # blur images with a sigma between 0 and 3.0\n",
        "\t\t\t\t\t\t\t           iaa.AverageBlur(k=(3, 5)),\n",
        "\t\t\t\t\t\t\t           # blur image using local means with kernel sizes between 2 and 7\n",
        "\t\t\t\t\t\t\t           iaa.MedianBlur(k=(3, 5)),\n",
        "\t\t\t\t\t\t\t           # blur image using local medians with kernel sizes between 2 and 7\n",
        "\t\t\t\t\t           ]),\n",
        "\t\t\t\t\t           iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)),\n",
        "\t\t\t\t\t           # sharpen images\n",
        "\t\t\t\t\t           iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),\n",
        "\t\t\t\t\t           # emboss images\n",
        "\t\t\t\t\t           # search either for all edges or for directed edges,\n",
        "\t\t\t\t\t           # blend the result with the original image using a blobby mask\n",
        "\t\t\t\t\t           iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "\t\t\t\t\t\t\t           iaa.DirectedEdgeDetect(alpha=(0.5, 1.0),\n",
        "\t\t\t\t\t\t\t                                  direction=(0.0, 1.0)),\n",
        "\t\t\t\t\t           ])),\n",
        "\t\t\t\t\t           iaa.AdditiveGaussianNoise(loc=0,\n",
        "\t\t\t\t\t                                     scale=(0.0, 0.01 * 255),\n",
        "\t\t\t\t\t                                     per_channel=0.5),\n",
        "\t\t\t\t\t           # add gaussian noise to images\n",
        "\t\t\t\t\t           \n",
        "\t\t\t\t\t           \n",
        "\t\t\t\t\t           iaa.Add((-2, 2), per_channel=0.5),\n",
        "\t\t\t\t\t           # change brightness of images (by -10 to 10 of original value)\n",
        "\t\t\t\t\t           iaa.AddToHueAndSaturation((-1, 1)),\n",
        "\t\t\t\t\t           # change hue and saturation\n",
        "\t\t\t\t\t           # either change the brightness of the whole image (sometimes\n",
        "\t\t\t\t\t           # per channel) or change the brightness of subareas\n",
        "\t\t\t\t\t           iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "\t\t\t\t\t\t\t           iaa.FrequencyNoiseAlpha(\n",
        "\t\t\t\t\t\t\t\t\t           exponent=(-1, 0),\n",
        "\t\t\t\t\t\t\t\t\t           first=iaa.Multiply((0.9, 1.1),\n",
        "\t\t\t\t\t\t\t\t\t                              per_channel=True),\n",
        "\t\t\t\t\t\t\t\t\t           second=iaa.ContrastNormalization(\n",
        "\t\t\t\t\t\t\t\t\t\t\t           (0.9, 1.1))\n",
        "\t\t\t\t\t\t\t           )\n",
        "\t\t\t\t\t           ]),\n",
        "\t\t\t\t\t           sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5),\n",
        "\t\t\t\t\t                                               sigma=0.25)),\n",
        "\t\t\t\t\t           # move pixels locally around (with random strengths)\n",
        "\t\t\t\t\t           sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n",
        "\t\t\t\t\t           # sometimes move parts of the image around\n",
        "\t\t\t\t\t           sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "\t\t\t\t           ],\n",
        "\t\t\t\t           random_order=True\n",
        "\t\t\t\t           )\n",
        "\t\t\t\t],\n",
        "\t\t\t\trandom_order=True\n",
        "\t\t)\n",
        "\t\treturn seq.augment_images(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "ia.seed(1)\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        if self.batch_size ==32:\n",
        "          image = np.stack([get_random_eraser(img) for img in image])\n",
        "          image = augmentor(image)\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpStgLcg5NKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 0.001\n",
        "    if epoch > 95:\n",
        "        lr = 0.000001\n",
        "    if epoch > 80:\n",
        "        lr = 0.00005\n",
        "    elif epoch > 60:\n",
        "        lr = 0.0001\n",
        "    elif epoch > 40:\n",
        "        lr = 0.0005\n",
        "    elif epoch > 20:\n",
        "        lr = 0.001\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import InceptionV3, Xception, DenseNet121, DenseNet201, ResNet152V2\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "backbone = ResNet152V2(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "neck = GlobalAveragePooling2D()(neck)\n",
        "#neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "def build_dense_tower(in_layer):\n",
        "    neck = Dense(128, activation=\"relu\")(in_layer)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_dense_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_dense_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_dense_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_dense_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_dense_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = {\n",
        "# \t\"gender_output\": \"binary_crossentropy\",\n",
        "# \t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "# \t\"age_output\": \"categorical_crossentropy\",\n",
        "# \t\"weight_output\": \"categorical_crossentropy\",\n",
        "\n",
        "# }\n",
        "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=lr_schedule(0))\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2ZRIQ7BW-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "#drive.mount('/content/gdrive')\n",
        "filepath = '/content/gdrive/My Drive/person_attributes.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             verbose=1,save_weights_only=False,\n",
        "                             period =10)\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=100,\n",
        "    verbose=1,callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3OCW3iag5k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}