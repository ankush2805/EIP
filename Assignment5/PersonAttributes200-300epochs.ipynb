{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PersonAttrubutes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankush2805/EIP/blob/master/Assignment5/PersonAttributes200-300epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "aafd6932-2ac6-4e97-ba4b-c953e21642b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7431dde5-dde1-4f5f-c23c-1f0e7d94b3e3"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a03c9aa6-b772-458e-8b66-cb0e947734b8"
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NblA5eWon8lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_eraser(input_img, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=1, pixel_level=False):\n",
        "  img_h, img_w, img_c = input_img.shape\n",
        "  p_1 = np.random.rand()\n",
        "  if p_1 > p:\n",
        "    return input_img\n",
        "\n",
        "  while True:\n",
        "    s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "    r = np.random.uniform(r_1, r_2)\n",
        "    w = int(np.sqrt(s / r))\n",
        "    h = int(np.sqrt(s * r))\n",
        "    left = np.random.randint(0, img_w)\n",
        "    top = np.random.randint(0, img_h)\n",
        "\n",
        "    if left + w <= img_w and top + h <= img_h:\n",
        "      break\n",
        "\n",
        "    if pixel_level:\n",
        "      c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "    else:\n",
        "      c = np.random.uniform(v_l, v_h)\n",
        "    input_img[top:top + h, left:left + w, :] = c\n",
        "  return input_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH5IpIVun_xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augmentor(images):\n",
        "\t\t'Apply data augmentation'\n",
        "\t\tsometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\t\tseq = iaa.Sequential(\n",
        "\t\t\t\t[\n",
        "\t\t\t\t# apply the following augmenters to most images\n",
        "\t\t\t\tiaa.Fliplr(0.3),  # horizontally flip 50% of all images\n",
        "\t\t\t\tsometimes(iaa.Affine(\n",
        "\t\t\t\t\tscale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
        "\t\t\t\t\t# scale images to 80-120% of their size, individually per axis\n",
        "\t\t\t\t\ttranslate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
        "\t\t\t\t\t# translate by -20 to +20 percent (per axis)\n",
        "\t\t\t\t\trotate=(-10, 10),  # rotate by -45 to +45 degrees\n",
        "\t\t\t\t\tshear=(-5, 5),  # shear by -16 to +16 degrees\n",
        "\t\t\t\t\torder=[0, 1],\n",
        "\t\t\t\t\t# use nearest neighbour or bilinear interpolation (fast)\n",
        "\t\t\t\t\tcval=(0, 255),  # if mode is constant, use a cval between 0 and 255\n",
        "\t\t\t\t\tmode=ia.ALL\n",
        "\t\t\t\t\t# use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "\t\t\t\t)),\n",
        "\t\t\t\t# execute 0 to 5 of the following (less important) augmenters per image\n",
        "\t\t\t\t# don't execute all of them, as that would often be way too strong\n",
        "\t\t\t\tiaa.SomeOf((0, 5),\n",
        "\t\t\t\t           [sometimes(iaa.Superpixels(p_replace=(0, 1.0),\n",
        "\t\t\t\t\t\t                                     n_segments=(20, 200))),\n",
        "\t\t\t\t\t           # convert images into their superpixel representation\n",
        "\t\t\t\t\t           iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.GaussianBlur((0, 1.0)),\n",
        "\t\t\t\t\t\t\t           # blur images with a sigma between 0 and 3.0\n",
        "\t\t\t\t\t\t\t           iaa.AverageBlur(k=(3, 5)),\n",
        "\t\t\t\t\t\t\t           # blur image using local means with kernel sizes between 2 and 7\n",
        "\t\t\t\t\t\t\t           iaa.MedianBlur(k=(3, 5)),\n",
        "\t\t\t\t\t\t\t           # blur image using local medians with kernel sizes between 2 and 7\n",
        "\t\t\t\t\t           ]),\n",
        "\t\t\t\t\t           iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)),\n",
        "\t\t\t\t\t           # sharpen images\n",
        "\t\t\t\t\t           iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),\n",
        "\t\t\t\t\t           # emboss images\n",
        "\t\t\t\t\t           # search either for all edges or for directed edges,\n",
        "\t\t\t\t\t           # blend the result with the original image using a blobby mask\n",
        "\t\t\t\t\t           iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "\t\t\t\t\t\t\t           iaa.DirectedEdgeDetect(alpha=(0.5, 1.0),\n",
        "\t\t\t\t\t\t\t                                  direction=(0.0, 1.0)),\n",
        "\t\t\t\t\t           ])),\n",
        "\t\t\t\t\t           iaa.AdditiveGaussianNoise(loc=0,\n",
        "\t\t\t\t\t                                     scale=(0.0, 0.01 * 255),\n",
        "\t\t\t\t\t                                     per_channel=0.5),\n",
        "\t\t\t\t\t           # add gaussian noise to images\n",
        "\t\t\t\t\t           \n",
        "\t\t\t\t\t           \n",
        "\t\t\t\t\t           iaa.Add((-2, 2), per_channel=0.5),\n",
        "\t\t\t\t\t           # change brightness of images (by -10 to 10 of original value)\n",
        "\t\t\t\t\t           iaa.AddToHueAndSaturation((-1, 1)),\n",
        "\t\t\t\t\t           # change hue and saturation\n",
        "\t\t\t\t\t           # either change the brightness of the whole image (sometimes\n",
        "\t\t\t\t\t           # per channel) or change the brightness of subareas\n",
        "\t\t\t\t\t           iaa.OneOf([\n",
        "\t\t\t\t\t\t\t           iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "\t\t\t\t\t\t\t           iaa.FrequencyNoiseAlpha(\n",
        "\t\t\t\t\t\t\t\t\t           exponent=(-1, 0),\n",
        "\t\t\t\t\t\t\t\t\t           first=iaa.Multiply((0.9, 1.1),\n",
        "\t\t\t\t\t\t\t\t\t                              per_channel=True),\n",
        "\t\t\t\t\t\t\t\t\t           second=iaa.ContrastNormalization(\n",
        "\t\t\t\t\t\t\t\t\t\t\t           (0.9, 1.1))\n",
        "\t\t\t\t\t\t\t           )\n",
        "\t\t\t\t\t           ]),\n",
        "\t\t\t\t\t           sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5),\n",
        "\t\t\t\t\t                                               sigma=0.25)),\n",
        "\t\t\t\t\t           # move pixels locally around (with random strengths)\n",
        "\t\t\t\t\t           sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n",
        "\t\t\t\t\t           # sometimes move parts of the image around\n",
        "\t\t\t\t\t           sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "\t\t\t\t           ],\n",
        "\t\t\t\t           random_order=True\n",
        "\t\t\t\t           )\n",
        "\t\t\t\t],\n",
        "\t\t\t\trandom_order=True\n",
        "\t\t)\n",
        "\t\treturn seq.augment_images(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFOiv9olZdu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n",
        "    RandomBrightness, RandomContrast, RandomGamma,\n",
        "    ToFloat, ShiftScaleRotate, Normalize\n",
        ")\n",
        "AUGMENTATIONS_NORMALIZE = Compose([\n",
        "    ToFloat(max_value=255)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "ia.seed(1)\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        #image = np.stack([AUGMENTATIONS_NORMALIZE(image=img)[\"image\"] for img in image])\n",
        "        if self.batch_size ==32:\n",
        "          image = augmentor(image)\n",
        "          image = np.stack([get_random_eraser(img) for img in image])\n",
        "        image = np.stack([AUGMENTATIONS_NORMALIZE(image=img)[\"image\"] for img in image])\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "outputId": "10d74f96-6ec6-4c1b-8b57-74ccfd532329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 28), (2036, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "f24b6496-2618-43a4-dd23-dc5e3d6eaa1a"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>gender_female</th>\n",
              "      <th>gender_male</th>\n",
              "      <th>imagequality_Average</th>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <th>imagequality_Good</th>\n",
              "      <th>age_15-25</th>\n",
              "      <th>age_25-35</th>\n",
              "      <th>age_35-45</th>\n",
              "      <th>age_45-55</th>\n",
              "      <th>age_55+</th>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <th>weight_over-weight</th>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <th>weight_underweight</th>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <th>carryingbag_None</th>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <th>footwear_Normal</th>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <th>emotion_Happy</th>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <th>emotion_Sad</th>\n",
              "      <th>bodypose_Back</th>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <th>bodypose_Side</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>resized/1483.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10008</th>\n",
              "      <td>resized/10009.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3610</th>\n",
              "      <td>resized/3611.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6457</th>\n",
              "      <td>resized/6458.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13271</th>\n",
              "      <td>resized/13273.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              image_path  gender_female  ...  bodypose_Front-Frontish  bodypose_Side\n",
              "1482    resized/1483.jpg              0  ...                        1              0\n",
              "10008  resized/10009.jpg              0  ...                        1              0\n",
              "3610    resized/3611.jpg              1  ...                        1              0\n",
              "6457    resized/6458.jpg              0  ...                        1              0\n",
              "13271  resized/13273.jpg              1  ...                        0              1\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "outputId": "9a3f3375-f13c-4d02-8ce1-5fb4ca06bb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpStgLcg5NKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 0.001\n",
        "    if epoch > 95:\n",
        "        lr = 0.000001\n",
        "    if epoch > 80:\n",
        "        lr = 0.00005\n",
        "    elif epoch > 60:\n",
        "        lr = 0.0001\n",
        "    elif epoch > 40:\n",
        "        lr = 0.0005\n",
        "    elif epoch > 20:\n",
        "        lr = 0.001\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "outputId": "ae7386dd-f4fa-4cb7-e47d-886a73aa28a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "from keras.applications import InceptionV3, Xception, DenseNet121, DenseNet201, ResNet152V2\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "backbone = ResNet152V2(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "neck = GlobalAveragePooling2D()(neck)\n",
        "#neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "def build_dense_tower(in_layer):\n",
        "    neck = Dense(128, activation=\"relu\")(in_layer)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.1)(in_layer)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    neck = Dropout(0.1)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_dense_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_dense_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_dense_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_dense_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_dense_tower(neck))\n",
        "\n",
        "\n",
        "#model = Model(\n",
        "#    inputs=backbone.input, outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion])\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/person_attributes.hdf5')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snP65fRLqdhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "outputId": "768d9329-7380-4ecc-f5c5-574930c39230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# losses = {\n",
        "# \t\"gender_output\": \"binary_crossentropy\",\n",
        "# \t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "# \t\"age_output\": \"categorical_crossentropy\",\n",
        "# \t\"weight_output\": \"categorical_crossentropy\",\n",
        "\n",
        "# }\n",
        "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=lr_schedule(0))\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2ZRIQ7BW-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "outputId": "a461427e-d04e-41f7-fe2a-9c91a4308b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "#drive.mount('/content/gdrive')\n",
        "filepath = '/content/gdrive/My Drive/person_attributes1.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             verbose=1,save_weights_only=False,\n",
        "                             period =10)\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=100,\n",
        "    verbose=1,callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "360/360 [==============================] - 350s 971ms/step - loss: 4.7323 - gender_output_loss: 0.1612 - image_quality_output_loss: 0.7421 - age_output_loss: 1.0280 - weight_output_loss: 0.6863 - bag_output_loss: 0.5035 - footwear_output_loss: 0.5769 - pose_output_loss: 0.2361 - emotion_output_loss: 0.7981 - gender_output_acc: 0.9372 - image_quality_output_acc: 0.6686 - age_output_acc: 0.5611 - weight_output_acc: 0.7328 - bag_output_acc: 0.8056 - footwear_output_acc: 0.7605 - pose_output_acc: 0.9146 - emotion_output_acc: 0.7171 - val_loss: 3.5224 - val_gender_output_loss: 0.0499 - val_image_quality_output_loss: 0.5432 - val_age_output_loss: 0.8362 - val_weight_output_loss: 0.5483 - val_bag_output_loss: 0.3377 - val_footwear_output_loss: 0.3914 - val_pose_output_loss: 0.1051 - val_emotion_output_loss: 0.7105 - val_gender_output_acc: 0.9839 - val_image_quality_output_acc: 0.7853 - val_age_output_acc: 0.6799 - val_weight_output_acc: 0.7913 - val_bag_output_acc: 0.8800 - val_footwear_output_acc: 0.8553 - val_pose_output_acc: 0.9713 - val_emotion_output_acc: 0.7480\n",
            "Epoch 2/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.6679 - gender_output_loss: 0.1549 - image_quality_output_loss: 0.7320 - age_output_loss: 1.0269 - weight_output_loss: 0.6754 - bag_output_loss: 0.4892 - footwear_output_loss: 0.5765 - pose_output_loss: 0.2196 - emotion_output_loss: 0.7935 - gender_output_acc: 0.9387 - image_quality_output_acc: 0.6731 - age_output_acc: 0.5532 - weight_output_acc: 0.7360 - bag_output_acc: 0.8081 - footwear_output_acc: 0.7566 - pose_output_acc: 0.9207 - emotion_output_acc: 0.7197Epoch 2/100\n",
            "360/360 [==============================] - 283s 785ms/step - loss: 4.6682 - gender_output_loss: 0.1548 - image_quality_output_loss: 0.7322 - age_output_loss: 1.0273 - weight_output_loss: 0.6752 - bag_output_loss: 0.4889 - footwear_output_loss: 0.5768 - pose_output_loss: 0.2193 - emotion_output_loss: 0.7934 - gender_output_acc: 0.9386 - image_quality_output_acc: 0.6729 - age_output_acc: 0.5530 - weight_output_acc: 0.7361 - bag_output_acc: 0.8080 - footwear_output_acc: 0.7563 - pose_output_acc: 0.9207 - emotion_output_acc: 0.7197 - val_loss: 3.4848 - val_gender_output_loss: 0.0670 - val_image_quality_output_loss: 0.5571 - val_age_output_loss: 0.8718 - val_weight_output_loss: 0.5152 - val_bag_output_loss: 0.2817 - val_footwear_output_loss: 0.3830 - val_pose_output_loss: 0.0933 - val_emotion_output_loss: 0.7159 - val_gender_output_acc: 0.9798 - val_image_quality_output_acc: 0.7762 - val_age_output_acc: 0.6472 - val_weight_output_acc: 0.8185 - val_bag_output_acc: 0.9083 - val_footwear_output_acc: 0.8594 - val_pose_output_acc: 0.9748 - val_emotion_output_acc: 0.7540\n",
            "Epoch 3/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.5877 - gender_output_loss: 0.1489 - image_quality_output_loss: 0.7229 - age_output_loss: 1.0089 - weight_output_loss: 0.6662 - bag_output_loss: 0.4750 - footwear_output_loss: 0.5647 - pose_output_loss: 0.2133 - emotion_output_loss: 0.7878 - gender_output_acc: 0.9417 - image_quality_output_acc: 0.6766 - age_output_acc: 0.5675 - weight_output_acc: 0.7406 - bag_output_acc: 0.8112 - footwear_output_acc: 0.7641 - pose_output_acc: 0.9240 - emotion_output_acc: 0.7201Epoch 3/100\n",
            "360/360 [==============================] - 282s 783ms/step - loss: 4.5878 - gender_output_loss: 0.1495 - image_quality_output_loss: 0.7224 - age_output_loss: 1.0096 - weight_output_loss: 0.6661 - bag_output_loss: 0.4748 - footwear_output_loss: 0.5647 - pose_output_loss: 0.2135 - emotion_output_loss: 0.7873 - gender_output_acc: 0.9413 - image_quality_output_acc: 0.6768 - age_output_acc: 0.5673 - weight_output_acc: 0.7409 - bag_output_acc: 0.8112 - footwear_output_acc: 0.7643 - pose_output_acc: 0.9239 - emotion_output_acc: 0.7202 - val_loss: 3.5105 - val_gender_output_loss: 0.0717 - val_image_quality_output_loss: 0.5858 - val_age_output_loss: 0.8258 - val_weight_output_loss: 0.5351 - val_bag_output_loss: 0.3017 - val_footwear_output_loss: 0.3906 - val_pose_output_loss: 0.0938 - val_emotion_output_loss: 0.7060 - val_gender_output_acc: 0.9778 - val_image_quality_output_acc: 0.7510 - val_age_output_acc: 0.6613 - val_weight_output_acc: 0.8100 - val_bag_output_acc: 0.8987 - val_footwear_output_acc: 0.8483 - val_pose_output_acc: 0.9738 - val_emotion_output_acc: 0.7470\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - 282s 783ms/step - loss: 4.5307 - gender_output_loss: 0.1432 - image_quality_output_loss: 0.7075 - age_output_loss: 1.0100 - weight_output_loss: 0.6591 - bag_output_loss: 0.4668 - footwear_output_loss: 0.5506 - pose_output_loss: 0.2097 - emotion_output_loss: 0.7837 - gender_output_acc: 0.9442 - image_quality_output_acc: 0.6859 - age_output_acc: 0.5646 - weight_output_acc: 0.7378 - bag_output_acc: 0.8185 - footwear_output_acc: 0.7717 - pose_output_acc: 0.9230 - emotion_output_acc: 0.7197 - val_loss: 3.6282 - val_gender_output_loss: 0.0763 - val_image_quality_output_loss: 0.6882 - val_age_output_loss: 0.8254 - val_weight_output_loss: 0.5248 - val_bag_output_loss: 0.3227 - val_footwear_output_loss: 0.3808 - val_pose_output_loss: 0.0932 - val_emotion_output_loss: 0.7168 - val_gender_output_acc: 0.9738 - val_image_quality_output_acc: 0.6976 - val_age_output_acc: 0.6724 - val_weight_output_acc: 0.8049 - val_bag_output_acc: 0.8901 - val_footwear_output_acc: 0.8584 - val_pose_output_acc: 0.9748 - val_emotion_output_acc: 0.7485\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - 282s 782ms/step - loss: 4.5095 - gender_output_loss: 0.1422 - image_quality_output_loss: 0.7091 - age_output_loss: 0.9958 - weight_output_loss: 0.6531 - bag_output_loss: 0.4655 - footwear_output_loss: 0.5509 - pose_output_loss: 0.2125 - emotion_output_loss: 0.7803 - gender_output_acc: 0.9406 - image_quality_output_acc: 0.6816 - age_output_acc: 0.5746 - weight_output_acc: 0.7412 - bag_output_acc: 0.8166 - footwear_output_acc: 0.7719 - pose_output_acc: 0.9201 - emotion_output_acc: 0.7209 - val_loss: 3.6751 - val_gender_output_loss: 0.0686 - val_image_quality_output_loss: 0.6097 - val_age_output_loss: 0.8315 - val_weight_output_loss: 0.5538 - val_bag_output_loss: 0.3666 - val_footwear_output_loss: 0.4273 - val_pose_output_loss: 0.0898 - val_emotion_output_loss: 0.7279 - val_gender_output_acc: 0.9768 - val_image_quality_output_acc: 0.7460 - val_age_output_acc: 0.6547 - val_weight_output_acc: 0.7939 - val_bag_output_acc: 0.8775 - val_footwear_output_acc: 0.8327 - val_pose_output_acc: 0.9748 - val_emotion_output_acc: 0.7414\n",
            "Epoch 6/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.4624 - gender_output_loss: 0.1343 - image_quality_output_loss: 0.6960 - age_output_loss: 0.9986 - weight_output_loss: 0.6471 - bag_output_loss: 0.4537 - footwear_output_loss: 0.5483 - pose_output_loss: 0.2042 - emotion_output_loss: 0.7802 - gender_output_acc: 0.9446 - image_quality_output_acc: 0.6899 - age_output_acc: 0.5702 - weight_output_acc: 0.7436 - bag_output_acc: 0.8251 - footwear_output_acc: 0.7698 - pose_output_acc: 0.9246 - emotion_output_acc: 0.7194Epoch 6/100\n",
            "360/360 [==============================] - 282s 782ms/step - loss: 4.4650 - gender_output_loss: 0.1344 - image_quality_output_loss: 0.6963 - age_output_loss: 0.9988 - weight_output_loss: 0.6475 - bag_output_loss: 0.4540 - footwear_output_loss: 0.5488 - pose_output_loss: 0.2042 - emotion_output_loss: 0.7810 - gender_output_acc: 0.9447 - image_quality_output_acc: 0.6898 - age_output_acc: 0.5702 - weight_output_acc: 0.7435 - bag_output_acc: 0.8250 - footwear_output_acc: 0.7697 - pose_output_acc: 0.9246 - emotion_output_acc: 0.7192 - val_loss: 3.8336 - val_gender_output_loss: 0.0737 - val_image_quality_output_loss: 0.6188 - val_age_output_loss: 0.9151 - val_weight_output_loss: 0.5893 - val_bag_output_loss: 0.3546 - val_footwear_output_loss: 0.4415 - val_pose_output_loss: 0.1048 - val_emotion_output_loss: 0.7358 - val_gender_output_acc: 0.9773 - val_image_quality_output_acc: 0.7480 - val_age_output_acc: 0.6084 - val_weight_output_acc: 0.7712 - val_bag_output_acc: 0.8750 - val_footwear_output_acc: 0.8246 - val_pose_output_acc: 0.9693 - val_emotion_output_acc: 0.7424\n",
            "Epoch 7/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.4561 - gender_output_loss: 0.1409 - image_quality_output_loss: 0.6985 - age_output_loss: 0.9899 - weight_output_loss: 0.6502 - bag_output_loss: 0.4428 - footwear_output_loss: 0.5392 - pose_output_loss: 0.2101 - emotion_output_loss: 0.7845 - gender_output_acc: 0.9398 - image_quality_output_acc: 0.6942 - age_output_acc: 0.5749 - weight_output_acc: 0.7458 - bag_output_acc: 0.8262 - footwear_output_acc: 0.7794 - pose_output_acc: 0.9244 - emotion_output_acc: 0.7201Epoch 7/100\n",
            "360/360 [==============================] - 282s 783ms/step - loss: 4.4561 - gender_output_loss: 0.1414 - image_quality_output_loss: 0.6982 - age_output_loss: 0.9905 - weight_output_loss: 0.6497 - bag_output_loss: 0.4429 - footwear_output_loss: 0.5389 - pose_output_loss: 0.2103 - emotion_output_loss: 0.7843 - gender_output_acc: 0.9394 - image_quality_output_acc: 0.6944 - age_output_acc: 0.5747 - weight_output_acc: 0.7462 - bag_output_acc: 0.8261 - footwear_output_acc: 0.7795 - pose_output_acc: 0.9242 - emotion_output_acc: 0.7203 - val_loss: 3.7068 - val_gender_output_loss: 0.0527 - val_image_quality_output_loss: 0.6050 - val_age_output_loss: 0.8532 - val_weight_output_loss: 0.6196 - val_bag_output_loss: 0.3449 - val_footwear_output_loss: 0.4161 - val_pose_output_loss: 0.0959 - val_emotion_output_loss: 0.7193 - val_gender_output_acc: 0.9839 - val_image_quality_output_acc: 0.7586 - val_age_output_acc: 0.6603 - val_weight_output_acc: 0.7555 - val_bag_output_acc: 0.8831 - val_footwear_output_acc: 0.8473 - val_pose_output_acc: 0.9728 - val_emotion_output_acc: 0.7450\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - 286s 793ms/step - loss: 4.4133 - gender_output_loss: 0.1397 - image_quality_output_loss: 0.6907 - age_output_loss: 0.9790 - weight_output_loss: 0.6505 - bag_output_loss: 0.4431 - footwear_output_loss: 0.5350 - pose_output_loss: 0.2002 - emotion_output_loss: 0.7750 - gender_output_acc: 0.9433 - image_quality_output_acc: 0.6943 - age_output_acc: 0.5773 - weight_output_acc: 0.7435 - bag_output_acc: 0.8300 - footwear_output_acc: 0.7763 - pose_output_acc: 0.9272 - emotion_output_acc: 0.7209 - val_loss: 3.6656 - val_gender_output_loss: 0.0472 - val_image_quality_output_loss: 0.6207 - val_age_output_loss: 0.8247 - val_weight_output_loss: 0.5592 - val_bag_output_loss: 0.3421 - val_footwear_output_loss: 0.4451 - val_pose_output_loss: 0.0972 - val_emotion_output_loss: 0.7293 - val_gender_output_acc: 0.9859 - val_image_quality_output_acc: 0.7450 - val_age_output_acc: 0.6517 - val_weight_output_acc: 0.7712 - val_bag_output_acc: 0.8750 - val_footwear_output_acc: 0.8241 - val_pose_output_acc: 0.9723 - val_emotion_output_acc: 0.7419\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - 280s 777ms/step - loss: 4.3584 - gender_output_loss: 0.1364 - image_quality_output_loss: 0.6808 - age_output_loss: 0.9740 - weight_output_loss: 0.6400 - bag_output_loss: 0.4302 - footwear_output_loss: 0.5267 - pose_output_loss: 0.1956 - emotion_output_loss: 0.7746 - gender_output_acc: 0.9454 - image_quality_output_acc: 0.6980 - age_output_acc: 0.5775 - weight_output_acc: 0.7487 - bag_output_acc: 0.8335 - footwear_output_acc: 0.7840 - pose_output_acc: 0.9286 - emotion_output_acc: 0.7234 - val_loss: 3.7076 - val_gender_output_loss: 0.0628 - val_image_quality_output_loss: 0.6154 - val_age_output_loss: 0.8746 - val_weight_output_loss: 0.5349 - val_bag_output_loss: 0.3404 - val_footwear_output_loss: 0.4496 - val_pose_output_loss: 0.1089 - val_emotion_output_loss: 0.7210 - val_gender_output_acc: 0.9758 - val_image_quality_output_acc: 0.7440 - val_age_output_acc: 0.6391 - val_weight_output_acc: 0.8039 - val_bag_output_acc: 0.8780 - val_footwear_output_acc: 0.8281 - val_pose_output_acc: 0.9662 - val_emotion_output_acc: 0.7414\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - 284s 789ms/step - loss: 4.3182 - gender_output_loss: 0.1333 - image_quality_output_loss: 0.6715 - age_output_loss: 0.9599 - weight_output_loss: 0.6319 - bag_output_loss: 0.4353 - footwear_output_loss: 0.5165 - pose_output_loss: 0.1947 - emotion_output_loss: 0.7752 - gender_output_acc: 0.9464 - image_quality_output_acc: 0.7026 - age_output_acc: 0.5857 - weight_output_acc: 0.7538 - bag_output_acc: 0.8278 - footwear_output_acc: 0.7845 - pose_output_acc: 0.9295 - emotion_output_acc: 0.7194 - val_loss: 3.8096 - val_gender_output_loss: 0.0696 - val_image_quality_output_loss: 0.6735 - val_age_output_loss: 0.8842 - val_weight_output_loss: 0.5567 - val_bag_output_loss: 0.3506 - val_footwear_output_loss: 0.4324 - val_pose_output_loss: 0.1123 - val_emotion_output_loss: 0.7303 - val_gender_output_acc: 0.9803 - val_image_quality_output_acc: 0.7087 - val_age_output_acc: 0.6366 - val_weight_output_acc: 0.7939 - val_bag_output_acc: 0.8810 - val_footwear_output_acc: 0.8387 - val_pose_output_acc: 0.9652 - val_emotion_output_acc: 0.7414\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - 282s 782ms/step - loss: 4.3177 - gender_output_loss: 0.1358 - image_quality_output_loss: 0.6676 - age_output_loss: 0.9662 - weight_output_loss: 0.6343 - bag_output_loss: 0.4244 - footwear_output_loss: 0.5198 - pose_output_loss: 0.1965 - emotion_output_loss: 0.7733 - gender_output_acc: 0.9464 - image_quality_output_acc: 0.7037 - age_output_acc: 0.5806 - weight_output_acc: 0.7476 - bag_output_acc: 0.8393 - footwear_output_acc: 0.7878 - pose_output_acc: 0.9251 - emotion_output_acc: 0.7217 - val_loss: 3.7595 - val_gender_output_loss: 0.0580 - val_image_quality_output_loss: 0.6478 - val_age_output_loss: 0.8533 - val_weight_output_loss: 0.5933 - val_bag_output_loss: 0.3454 - val_footwear_output_loss: 0.4305 - val_pose_output_loss: 0.1107 - val_emotion_output_loss: 0.7204 - val_gender_output_acc: 0.9814 - val_image_quality_output_acc: 0.7248 - val_age_output_acc: 0.6421 - val_weight_output_acc: 0.7606 - val_bag_output_acc: 0.8750 - val_footwear_output_acc: 0.8261 - val_pose_output_acc: 0.9642 - val_emotion_output_acc: 0.7440\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - 281s 780ms/step - loss: 4.3967 - gender_output_loss: 0.1484 - image_quality_output_loss: 0.6807 - age_output_loss: 0.9746 - weight_output_loss: 0.6367 - bag_output_loss: 0.4414 - footwear_output_loss: 0.5348 - pose_output_loss: 0.2044 - emotion_output_loss: 0.7758 - gender_output_acc: 0.9385 - image_quality_output_acc: 0.6945 - age_output_acc: 0.5813 - weight_output_acc: 0.7484 - bag_output_acc: 0.8271 - footwear_output_acc: 0.7757 - pose_output_acc: 0.9238 - emotion_output_acc: 0.7207 - val_loss: 3.9321 - val_gender_output_loss: 0.0663 - val_image_quality_output_loss: 0.6451 - val_age_output_loss: 0.8693 - val_weight_output_loss: 0.6237 - val_bag_output_loss: 0.4443 - val_footwear_output_loss: 0.4523 - val_pose_output_loss: 0.1080 - val_emotion_output_loss: 0.7232 - val_gender_output_acc: 0.9803 - val_image_quality_output_acc: 0.7193 - val_age_output_acc: 0.6280 - val_weight_output_acc: 0.7329 - val_bag_output_acc: 0.8402 - val_footwear_output_acc: 0.8231 - val_pose_output_acc: 0.9703 - val_emotion_output_acc: 0.7429\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - 279s 776ms/step - loss: 4.2565 - gender_output_loss: 0.1374 - image_quality_output_loss: 0.6579 - age_output_loss: 0.9484 - weight_output_loss: 0.6201 - bag_output_loss: 0.4195 - footwear_output_loss: 0.5073 - pose_output_loss: 0.1941 - emotion_output_loss: 0.7718 - gender_output_acc: 0.9469 - image_quality_output_acc: 0.7023 - age_output_acc: 0.5835 - weight_output_acc: 0.7550 - bag_output_acc: 0.8344 - footwear_output_acc: 0.7905 - pose_output_acc: 0.9307 - emotion_output_acc: 0.7219 - val_loss: 3.8048 - val_gender_output_loss: 0.0764 - val_image_quality_output_loss: 0.6490 - val_age_output_loss: 0.8615 - val_weight_output_loss: 0.5434 - val_bag_output_loss: 0.3698 - val_footwear_output_loss: 0.4779 - val_pose_output_loss: 0.0964 - val_emotion_output_loss: 0.7304 - val_gender_output_acc: 0.9773 - val_image_quality_output_acc: 0.7263 - val_age_output_acc: 0.6361 - val_weight_output_acc: 0.7959 - val_bag_output_acc: 0.8745 - val_footwear_output_acc: 0.8160 - val_pose_output_acc: 0.9708 - val_emotion_output_acc: 0.7440\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - 287s 798ms/step - loss: 4.2156 - gender_output_loss: 0.1309 - image_quality_output_loss: 0.6538 - age_output_loss: 0.9484 - weight_output_loss: 0.6145 - bag_output_loss: 0.4064 - footwear_output_loss: 0.5086 - pose_output_loss: 0.1877 - emotion_output_loss: 0.7654 - gender_output_acc: 0.9464 - image_quality_output_acc: 0.7068 - age_output_acc: 0.5962 - weight_output_acc: 0.7583 - bag_output_acc: 0.8419 - footwear_output_acc: 0.7891 - pose_output_acc: 0.9323 - emotion_output_acc: 0.7232 - val_loss: 3.8276 - val_gender_output_loss: 0.0833 - val_image_quality_output_loss: 0.6524 - val_age_output_loss: 0.8669 - val_weight_output_loss: 0.5905 - val_bag_output_loss: 0.3685 - val_footwear_output_loss: 0.4314 - val_pose_output_loss: 0.0968 - val_emotion_output_loss: 0.7378 - val_gender_output_acc: 0.9698 - val_image_quality_output_acc: 0.7177 - val_age_output_acc: 0.6386 - val_weight_output_acc: 0.7737 - val_bag_output_acc: 0.8725 - val_footwear_output_acc: 0.8276 - val_pose_output_acc: 0.9723 - val_emotion_output_acc: 0.7445\n",
            "Epoch 15/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.2219 - gender_output_loss: 0.1384 - image_quality_output_loss: 0.6476 - age_output_loss: 0.9477 - weight_output_loss: 0.6081 - bag_output_loss: 0.4182 - footwear_output_loss: 0.5046 - pose_output_loss: 0.1944 - emotion_output_loss: 0.7629 - gender_output_acc: 0.9432 - image_quality_output_acc: 0.7147 - age_output_acc: 0.5925 - weight_output_acc: 0.7574 - bag_output_acc: 0.8377 - footwear_output_acc: 0.7883 - pose_output_acc: 0.9279 - emotion_output_acc: 0.7241Epoch 15/100\n",
            "360/360 [==============================] - 289s 802ms/step - loss: 4.2230 - gender_output_loss: 0.1385 - image_quality_output_loss: 0.6474 - age_output_loss: 0.9482 - weight_output_loss: 0.6082 - bag_output_loss: 0.4185 - footwear_output_loss: 0.5044 - pose_output_loss: 0.1950 - emotion_output_loss: 0.7628 - gender_output_acc: 0.9431 - image_quality_output_acc: 0.7149 - age_output_acc: 0.5922 - weight_output_acc: 0.7573 - bag_output_acc: 0.8375 - footwear_output_acc: 0.7884 - pose_output_acc: 0.9279 - emotion_output_acc: 0.7243 - val_loss: 3.9048 - val_gender_output_loss: 0.0664 - val_image_quality_output_loss: 0.6416 - val_age_output_loss: 0.9113 - val_weight_output_loss: 0.6360 - val_bag_output_loss: 0.3563 - val_footwear_output_loss: 0.4356 - val_pose_output_loss: 0.1251 - val_emotion_output_loss: 0.7325 - val_gender_output_acc: 0.9788 - val_image_quality_output_acc: 0.7384 - val_age_output_acc: 0.6129 - val_weight_output_acc: 0.7384 - val_bag_output_acc: 0.8765 - val_footwear_output_acc: 0.8301 - val_pose_output_acc: 0.9592 - val_emotion_output_acc: 0.7419\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - 283s 785ms/step - loss: 4.1765 - gender_output_loss: 0.1332 - image_quality_output_loss: 0.6371 - age_output_loss: 0.9418 - weight_output_loss: 0.6136 - bag_output_loss: 0.4011 - footwear_output_loss: 0.4890 - pose_output_loss: 0.1902 - emotion_output_loss: 0.7705 - gender_output_acc: 0.9425 - image_quality_output_acc: 0.7183 - age_output_acc: 0.5960 - weight_output_acc: 0.7508 - bag_output_acc: 0.8420 - footwear_output_acc: 0.7957 - pose_output_acc: 0.9280 - emotion_output_acc: 0.7244 - val_loss: 3.9950 - val_gender_output_loss: 0.0827 - val_image_quality_output_loss: 0.7032 - val_age_output_loss: 0.9126 - val_weight_output_loss: 0.5977 - val_bag_output_loss: 0.3921 - val_footwear_output_loss: 0.4449 - val_pose_output_loss: 0.1259 - val_emotion_output_loss: 0.7360 - val_gender_output_acc: 0.9808 - val_image_quality_output_acc: 0.7283 - val_age_output_acc: 0.5922 - val_weight_output_acc: 0.7702 - val_bag_output_acc: 0.8684 - val_footwear_output_acc: 0.8226 - val_pose_output_acc: 0.9617 - val_emotion_output_acc: 0.7374\n",
            "Epoch 17/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.1314 - gender_output_loss: 0.1332 - image_quality_output_loss: 0.6410 - age_output_loss: 0.9288 - weight_output_loss: 0.6011 - bag_output_loss: 0.3921 - footwear_output_loss: 0.4895 - pose_output_loss: 0.1832 - emotion_output_loss: 0.7626 - gender_output_acc: 0.9479 - image_quality_output_acc: 0.7174 - age_output_acc: 0.6009 - weight_output_acc: 0.7651 - bag_output_acc: 0.8505 - footwear_output_acc: 0.7981 - pose_output_acc: 0.9332 - emotion_output_acc: 0.7248Epoch 17/100\n",
            "360/360 [==============================] - 281s 781ms/step - loss: 4.1291 - gender_output_loss: 0.1330 - image_quality_output_loss: 0.6408 - age_output_loss: 0.9287 - weight_output_loss: 0.6005 - bag_output_loss: 0.3919 - footwear_output_loss: 0.4895 - pose_output_loss: 0.1828 - emotion_output_loss: 0.7619 - gender_output_acc: 0.9479 - image_quality_output_acc: 0.7177 - age_output_acc: 0.6010 - weight_output_acc: 0.7652 - bag_output_acc: 0.8506 - footwear_output_acc: 0.7979 - pose_output_acc: 0.9333 - emotion_output_acc: 0.7253 - val_loss: 4.0493 - val_gender_output_loss: 0.0882 - val_image_quality_output_loss: 0.7054 - val_age_output_loss: 0.9067 - val_weight_output_loss: 0.6112 - val_bag_output_loss: 0.4076 - val_footwear_output_loss: 0.4780 - val_pose_output_loss: 0.1125 - val_emotion_output_loss: 0.7397 - val_gender_output_acc: 0.9803 - val_image_quality_output_acc: 0.7077 - val_age_output_acc: 0.6230 - val_weight_output_acc: 0.7727 - val_bag_output_acc: 0.8599 - val_footwear_output_acc: 0.8201 - val_pose_output_acc: 0.9632 - val_emotion_output_acc: 0.7419\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - 281s 780ms/step - loss: 4.0905 - gender_output_loss: 0.1207 - image_quality_output_loss: 0.6215 - age_output_loss: 0.9369 - weight_output_loss: 0.6033 - bag_output_loss: 0.3859 - footwear_output_loss: 0.4781 - pose_output_loss: 0.1813 - emotion_output_loss: 0.7628 - gender_output_acc: 0.9525 - image_quality_output_acc: 0.7245 - age_output_acc: 0.6023 - weight_output_acc: 0.7632 - bag_output_acc: 0.8521 - footwear_output_acc: 0.8038 - pose_output_acc: 0.9320 - emotion_output_acc: 0.7247 - val_loss: 4.0936 - val_gender_output_loss: 0.0766 - val_image_quality_output_loss: 0.7696 - val_age_output_loss: 0.9012 - val_weight_output_loss: 0.6220 - val_bag_output_loss: 0.3839 - val_footwear_output_loss: 0.4891 - val_pose_output_loss: 0.1131 - val_emotion_output_loss: 0.7380 - val_gender_output_acc: 0.9713 - val_image_quality_output_acc: 0.6759 - val_age_output_acc: 0.6321 - val_weight_output_acc: 0.7434 - val_bag_output_acc: 0.8664 - val_footwear_output_acc: 0.8130 - val_pose_output_acc: 0.9667 - val_emotion_output_acc: 0.7389\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - 281s 781ms/step - loss: 4.0605 - gender_output_loss: 0.1264 - image_quality_output_loss: 0.6215 - age_output_loss: 0.9218 - weight_output_loss: 0.5954 - bag_output_loss: 0.3818 - footwear_output_loss: 0.4706 - pose_output_loss: 0.1850 - emotion_output_loss: 0.7581 - gender_output_acc: 0.9484 - image_quality_output_acc: 0.7283 - age_output_acc: 0.6061 - weight_output_acc: 0.7648 - bag_output_acc: 0.8489 - footwear_output_acc: 0.8056 - pose_output_acc: 0.9325 - emotion_output_acc: 0.7288 - val_loss: 4.0260 - val_gender_output_loss: 0.0808 - val_image_quality_output_loss: 0.6824 - val_age_output_loss: 0.9069 - val_weight_output_loss: 0.6020 - val_bag_output_loss: 0.4071 - val_footwear_output_loss: 0.4998 - val_pose_output_loss: 0.1031 - val_emotion_output_loss: 0.7439 - val_gender_output_acc: 0.9733 - val_image_quality_output_acc: 0.7253 - val_age_output_acc: 0.6134 - val_weight_output_acc: 0.7681 - val_bag_output_acc: 0.8690 - val_footwear_output_acc: 0.8120 - val_pose_output_acc: 0.9723 - val_emotion_output_acc: 0.7314\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - 280s 779ms/step - loss: 4.0184 - gender_output_loss: 0.1192 - image_quality_output_loss: 0.6111 - age_output_loss: 0.9147 - weight_output_loss: 0.5939 - bag_output_loss: 0.3819 - footwear_output_loss: 0.4626 - pose_output_loss: 0.1822 - emotion_output_loss: 0.7526 - gender_output_acc: 0.9530 - image_quality_output_acc: 0.7365 - age_output_acc: 0.6133 - weight_output_acc: 0.7661 - bag_output_acc: 0.8522 - footwear_output_acc: 0.8120 - pose_output_acc: 0.9341 - emotion_output_acc: 0.7264 - val_loss: 4.1643 - val_gender_output_loss: 0.0745 - val_image_quality_output_loss: 0.7206 - val_age_output_loss: 0.8952 - val_weight_output_loss: 0.6217 - val_bag_output_loss: 0.4285 - val_footwear_output_loss: 0.5285 - val_pose_output_loss: 0.1366 - val_emotion_output_loss: 0.7587 - val_gender_output_acc: 0.9753 - val_image_quality_output_acc: 0.7087 - val_age_output_acc: 0.6285 - val_weight_output_acc: 0.7646 - val_bag_output_acc: 0.8604 - val_footwear_output_acc: 0.8165 - val_pose_output_acc: 0.9607 - val_emotion_output_acc: 0.7349\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - 283s 785ms/step - loss: 4.0714 - gender_output_loss: 0.1291 - image_quality_output_loss: 0.6248 - age_output_loss: 0.9208 - weight_output_loss: 0.5962 - bag_output_loss: 0.3911 - footwear_output_loss: 0.4727 - pose_output_loss: 0.1819 - emotion_output_loss: 0.7549 - gender_output_acc: 0.9451 - image_quality_output_acc: 0.7218 - age_output_acc: 0.6030 - weight_output_acc: 0.7681 - bag_output_acc: 0.8466 - footwear_output_acc: 0.8049 - pose_output_acc: 0.9333 - emotion_output_acc: 0.7275 - val_loss: 4.1280 - val_gender_output_loss: 0.0801 - val_image_quality_output_loss: 0.7253 - val_age_output_loss: 0.9124 - val_weight_output_loss: 0.5830 - val_bag_output_loss: 0.4243 - val_footwear_output_loss: 0.5365 - val_pose_output_loss: 0.1236 - val_emotion_output_loss: 0.7429 - val_gender_output_acc: 0.9733 - val_image_quality_output_acc: 0.7021 - val_age_output_acc: 0.6225 - val_weight_output_acc: 0.7787 - val_bag_output_acc: 0.8579 - val_footwear_output_acc: 0.7939 - val_pose_output_acc: 0.9637 - val_emotion_output_acc: 0.7404\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - 282s 784ms/step - loss: 3.9732 - gender_output_loss: 0.1229 - image_quality_output_loss: 0.6111 - age_output_loss: 0.9017 - weight_output_loss: 0.5804 - bag_output_loss: 0.3691 - footwear_output_loss: 0.4639 - pose_output_loss: 0.1743 - emotion_output_loss: 0.7497 - gender_output_acc: 0.9489 - image_quality_output_acc: 0.7358 - age_output_acc: 0.6142 - weight_output_acc: 0.7693 - bag_output_acc: 0.8578 - footwear_output_acc: 0.8089 - pose_output_acc: 0.9358 - emotion_output_acc: 0.7289 - val_loss: 4.2570 - val_gender_output_loss: 0.0762 - val_image_quality_output_loss: 0.7518 - val_age_output_loss: 0.9011 - val_weight_output_loss: 0.5797 - val_bag_output_loss: 0.4369 - val_footwear_output_loss: 0.6118 - val_pose_output_loss: 0.1435 - val_emotion_output_loss: 0.7560 - val_gender_output_acc: 0.9788 - val_image_quality_output_acc: 0.7026 - val_age_output_acc: 0.6260 - val_weight_output_acc: 0.7792 - val_bag_output_acc: 0.8649 - val_footwear_output_acc: 0.7782 - val_pose_output_acc: 0.9612 - val_emotion_output_acc: 0.7349\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - 282s 783ms/step - loss: 3.9173 - gender_output_loss: 0.1137 - image_quality_output_loss: 0.5925 - age_output_loss: 0.8927 - weight_output_loss: 0.5776 - bag_output_loss: 0.3721 - footwear_output_loss: 0.4502 - pose_output_loss: 0.1685 - emotion_output_loss: 0.7499 - gender_output_acc: 0.9543 - image_quality_output_acc: 0.7395 - age_output_acc: 0.6156 - weight_output_acc: 0.7721 - bag_output_acc: 0.8530 - footwear_output_acc: 0.8160 - pose_output_acc: 0.9352 - emotion_output_acc: 0.7275 - val_loss: 4.3704 - val_gender_output_loss: 0.0938 - val_image_quality_output_loss: 0.7764 - val_age_output_loss: 0.8765 - val_weight_output_loss: 0.6907 - val_bag_output_loss: 0.4884 - val_footwear_output_loss: 0.5666 - val_pose_output_loss: 0.1291 - val_emotion_output_loss: 0.7489 - val_gender_output_acc: 0.9753 - val_image_quality_output_acc: 0.6961 - val_age_output_acc: 0.6346 - val_weight_output_acc: 0.7359 - val_bag_output_acc: 0.8387 - val_footwear_output_acc: 0.8014 - val_pose_output_acc: 0.9577 - val_emotion_output_acc: 0.7424\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - 282s 785ms/step - loss: 3.9337 - gender_output_loss: 0.1144 - image_quality_output_loss: 0.6090 - age_output_loss: 0.9014 - weight_output_loss: 0.5774 - bag_output_loss: 0.3623 - footwear_output_loss: 0.4500 - pose_output_loss: 0.1778 - emotion_output_loss: 0.7415 - gender_output_acc: 0.9537 - image_quality_output_acc: 0.7311 - age_output_acc: 0.6104 - weight_output_acc: 0.7729 - bag_output_acc: 0.8619 - footwear_output_acc: 0.8186 - pose_output_acc: 0.9351 - emotion_output_acc: 0.7305 - val_loss: 4.2815 - val_gender_output_loss: 0.0943 - val_image_quality_output_loss: 0.7500 - val_age_output_loss: 0.9128 - val_weight_output_loss: 0.6393 - val_bag_output_loss: 0.4513 - val_footwear_output_loss: 0.5344 - val_pose_output_loss: 0.1386 - val_emotion_output_loss: 0.7609 - val_gender_output_acc: 0.9753 - val_image_quality_output_acc: 0.6880 - val_age_output_acc: 0.6099 - val_weight_output_acc: 0.7581 - val_bag_output_acc: 0.8498 - val_footwear_output_acc: 0.8100 - val_pose_output_acc: 0.9572 - val_emotion_output_acc: 0.7379\n",
            "Epoch 25/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 3.8770 - gender_output_loss: 0.1157 - image_quality_output_loss: 0.5827 - age_output_loss: 0.8858 - weight_output_loss: 0.5726 - bag_output_loss: 0.3628 - footwear_output_loss: 0.4411 - pose_output_loss: 0.1709 - emotion_output_loss: 0.7454 - gender_output_acc: 0.9545 - image_quality_output_acc: 0.7498 - age_output_acc: 0.6258 - weight_output_acc: 0.7731 - bag_output_acc: 0.8592 - footwear_output_acc: 0.8245 - pose_output_acc: 0.9373 - emotion_output_acc: 0.7309Epoch 25/100\n",
            "360/360 [==============================] - 289s 804ms/step - loss: 3.8768 - gender_output_loss: 0.1156 - image_quality_output_loss: 0.5824 - age_output_loss: 0.8856 - weight_output_loss: 0.5733 - bag_output_loss: 0.3628 - footwear_output_loss: 0.4413 - pose_output_loss: 0.1707 - emotion_output_loss: 0.7452 - gender_output_acc: 0.9544 - image_quality_output_acc: 0.7499 - age_output_acc: 0.6260 - weight_output_acc: 0.7727 - bag_output_acc: 0.8591 - footwear_output_acc: 0.8242 - pose_output_acc: 0.9374 - emotion_output_acc: 0.7312 - val_loss: 4.2152 - val_gender_output_loss: 0.0936 - val_image_quality_output_loss: 0.7138 - val_age_output_loss: 0.9291 - val_weight_output_loss: 0.6281 - val_bag_output_loss: 0.3957 - val_footwear_output_loss: 0.5674 - val_pose_output_loss: 0.1357 - val_emotion_output_loss: 0.7518 - val_gender_output_acc: 0.9682 - val_image_quality_output_acc: 0.6941 - val_age_output_acc: 0.6190 - val_weight_output_acc: 0.7636 - val_bag_output_acc: 0.8629 - val_footwear_output_acc: 0.7848 - val_pose_output_acc: 0.9546 - val_emotion_output_acc: 0.7455\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - 284s 789ms/step - loss: 3.8778 - gender_output_loss: 0.1217 - image_quality_output_loss: 0.5754 - age_output_loss: 0.8931 - weight_output_loss: 0.5578 - bag_output_loss: 0.3614 - footwear_output_loss: 0.4485 - pose_output_loss: 0.1761 - emotion_output_loss: 0.7439 - gender_output_acc: 0.9514 - image_quality_output_acc: 0.7510 - age_output_acc: 0.6189 - weight_output_acc: 0.7797 - bag_output_acc: 0.8592 - footwear_output_acc: 0.8183 - pose_output_acc: 0.9345 - emotion_output_acc: 0.7296 - val_loss: 4.6541 - val_gender_output_loss: 0.1255 - val_image_quality_output_loss: 0.9368 - val_age_output_loss: 0.9622 - val_weight_output_loss: 0.6561 - val_bag_output_loss: 0.4912 - val_footwear_output_loss: 0.5724 - val_pose_output_loss: 0.1532 - val_emotion_output_loss: 0.7566 - val_gender_output_acc: 0.9551 - val_image_quality_output_acc: 0.6310 - val_age_output_acc: 0.6013 - val_weight_output_acc: 0.7525 - val_bag_output_acc: 0.8281 - val_footwear_output_acc: 0.7828 - val_pose_output_acc: 0.9541 - val_emotion_output_acc: 0.7389\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - 284s 789ms/step - loss: 3.8055 - gender_output_loss: 0.1147 - image_quality_output_loss: 0.5660 - age_output_loss: 0.8749 - weight_output_loss: 0.5627 - bag_output_loss: 0.3479 - footwear_output_loss: 0.4350 - pose_output_loss: 0.1647 - emotion_output_loss: 0.7397 - gender_output_acc: 0.9530 - image_quality_output_acc: 0.7500 - age_output_acc: 0.6261 - weight_output_acc: 0.7820 - bag_output_acc: 0.8631 - footwear_output_acc: 0.8216 - pose_output_acc: 0.9385 - emotion_output_acc: 0.7323 - val_loss: 4.7232 - val_gender_output_loss: 0.0854 - val_image_quality_output_loss: 0.8957 - val_age_output_loss: 1.0450 - val_weight_output_loss: 0.7416 - val_bag_output_loss: 0.4450 - val_footwear_output_loss: 0.5921 - val_pose_output_loss: 0.1485 - val_emotion_output_loss: 0.7700 - val_gender_output_acc: 0.9753 - val_image_quality_output_acc: 0.6724 - val_age_output_acc: 0.5771 - val_weight_output_acc: 0.7278 - val_bag_output_acc: 0.8589 - val_footwear_output_acc: 0.7873 - val_pose_output_acc: 0.9541 - val_emotion_output_acc: 0.7308\n",
            "Epoch 28/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 3.7754 - gender_output_loss: 0.1183 - image_quality_output_loss: 0.5629 - age_output_loss: 0.8728 - weight_output_loss: 0.5582 - bag_output_loss: 0.3366 - footwear_output_loss: 0.4196 - pose_output_loss: 0.1702 - emotion_output_loss: 0.7367 - gender_output_acc: 0.9525 - image_quality_output_acc: 0.7557 - age_output_acc: 0.6242 - weight_output_acc: 0.7765 - bag_output_acc: 0.8711 - footwear_output_acc: 0.8261 - pose_output_acc: 0.9338 - emotion_output_acc: 0.7349Epoch 28/100\n",
            "360/360 [==============================] - 287s 796ms/step - loss: 3.7770 - gender_output_loss: 0.1180 - image_quality_output_loss: 0.5629 - age_output_loss: 0.8730 - weight_output_loss: 0.5591 - bag_output_loss: 0.3366 - footwear_output_loss: 0.4195 - pose_output_loss: 0.1705 - emotion_output_loss: 0.7375 - gender_output_acc: 0.9526 - image_quality_output_acc: 0.7556 - age_output_acc: 0.6240 - weight_output_acc: 0.7763 - bag_output_acc: 0.8712 - footwear_output_acc: 0.8261 - pose_output_acc: 0.9335 - emotion_output_acc: 0.7347 - val_loss: 4.5234 - val_gender_output_loss: 0.0850 - val_image_quality_output_loss: 0.8064 - val_age_output_loss: 0.9627 - val_weight_output_loss: 0.7157 - val_bag_output_loss: 0.4720 - val_footwear_output_loss: 0.5480 - val_pose_output_loss: 0.1783 - val_emotion_output_loss: 0.7553 - val_gender_output_acc: 0.9743 - val_image_quality_output_acc: 0.6825 - val_age_output_acc: 0.6018 - val_weight_output_acc: 0.7268 - val_bag_output_acc: 0.8458 - val_footwear_output_acc: 0.8034 - val_pose_output_acc: 0.9461 - val_emotion_output_acc: 0.7354\n",
            "Epoch 29/100\n",
            "360/360 [==============================] - 287s 796ms/step - loss: 3.7855 - gender_output_loss: 0.1179 - image_quality_output_loss: 0.5702 - age_output_loss: 0.8628 - weight_output_loss: 0.5547 - bag_output_loss: 0.3428 - footwear_output_loss: 0.4323 - pose_output_loss: 0.1738 - emotion_output_loss: 0.7310 - gender_output_acc: 0.9507 - image_quality_output_acc: 0.7516 - age_output_acc: 0.6335 - weight_output_acc: 0.7815 - bag_output_acc: 0.8672 - footwear_output_acc: 0.8250 - pose_output_acc: 0.9346 - emotion_output_acc: 0.7339 - val_loss: 4.8229 - val_gender_output_loss: 0.0860 - val_image_quality_output_loss: 0.9759 - val_age_output_loss: 1.0371 - val_weight_output_loss: 0.6639 - val_bag_output_loss: 0.4859 - val_footwear_output_loss: 0.6396 - val_pose_output_loss: 0.1610 - val_emotion_output_loss: 0.7736 - val_gender_output_acc: 0.9723 - val_image_quality_output_acc: 0.6431 - val_age_output_acc: 0.5625 - val_weight_output_acc: 0.7414 - val_bag_output_acc: 0.8407 - val_footwear_output_acc: 0.7939 - val_pose_output_acc: 0.9511 - val_emotion_output_acc: 0.7364\n",
            "Epoch 30/100\n",
            "360/360 [==============================] - 286s 794ms/step - loss: 3.7652 - gender_output_loss: 0.1079 - image_quality_output_loss: 0.5627 - age_output_loss: 0.8678 - weight_output_loss: 0.5563 - bag_output_loss: 0.3433 - footwear_output_loss: 0.4303 - pose_output_loss: 0.1684 - emotion_output_loss: 0.7285 - gender_output_acc: 0.9518 - image_quality_output_acc: 0.7575 - age_output_acc: 0.6312 - weight_output_acc: 0.7788 - bag_output_acc: 0.8649 - footwear_output_acc: 0.8252 - pose_output_acc: 0.9374 - emotion_output_acc: 0.7348 - val_loss: 4.6155 - val_gender_output_loss: 0.1125 - val_image_quality_output_loss: 0.8423 - val_age_output_loss: 1.0136 - val_weight_output_loss: 0.6701 - val_bag_output_loss: 0.4812 - val_footwear_output_loss: 0.5911 - val_pose_output_loss: 0.1432 - val_emotion_output_loss: 0.7614 - val_gender_output_acc: 0.9672 - val_image_quality_output_acc: 0.6663 - val_age_output_acc: 0.5837 - val_weight_output_acc: 0.7364 - val_bag_output_acc: 0.8422 - val_footwear_output_acc: 0.7873 - val_pose_output_acc: 0.9602 - val_emotion_output_acc: 0.7324\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 31/100\n",
            "360/360 [==============================] - 285s 791ms/step - loss: 3.7397 - gender_output_loss: 0.1171 - image_quality_output_loss: 0.5674 - age_output_loss: 0.8589 - weight_output_loss: 0.5464 - bag_output_loss: 0.3312 - footwear_output_loss: 0.4167 - pose_output_loss: 0.1682 - emotion_output_loss: 0.7339 - gender_output_acc: 0.9509 - image_quality_output_acc: 0.7499 - age_output_acc: 0.6347 - weight_output_acc: 0.7853 - bag_output_acc: 0.8719 - footwear_output_acc: 0.8280 - pose_output_acc: 0.9353 - emotion_output_acc: 0.7346 - val_loss: 4.6226 - val_gender_output_loss: 0.0987 - val_image_quality_output_loss: 0.8830 - val_age_output_loss: 0.9771 - val_weight_output_loss: 0.6779 - val_bag_output_loss: 0.4976 - val_footwear_output_loss: 0.5641 - val_pose_output_loss: 0.1555 - val_emotion_output_loss: 0.7688 - val_gender_output_acc: 0.9733 - val_image_quality_output_acc: 0.6497 - val_age_output_acc: 0.5827 - val_weight_output_acc: 0.7465 - val_bag_output_acc: 0.8498 - val_footwear_output_acc: 0.7828 - val_pose_output_acc: 0.9531 - val_emotion_output_acc: 0.7364\n",
            "Epoch 32/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 3.7281 - gender_output_loss: 0.1158 - image_quality_output_loss: 0.5526 - age_output_loss: 0.8654 - weight_output_loss: 0.5530 - bag_output_loss: 0.3348 - footwear_output_loss: 0.4156 - pose_output_loss: 0.1612 - emotion_output_loss: 0.7297 - gender_output_acc: 0.9528 - image_quality_output_acc: 0.7660 - age_output_acc: 0.6360 - weight_output_acc: 0.7818 - bag_output_acc: 0.8708 - footwear_output_acc: 0.8343 - pose_output_acc: 0.9396 - emotion_output_acc: 0.7361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 32/100\n",
            "360/360 [==============================] - 285s 792ms/step - loss: 3.7325 - gender_output_loss: 0.1165 - image_quality_output_loss: 0.5527 - age_output_loss: 0.8659 - weight_output_loss: 0.5531 - bag_output_loss: 0.3359 - footwear_output_loss: 0.4161 - pose_output_loss: 0.1614 - emotion_output_loss: 0.7308 - gender_output_acc: 0.9527 - image_quality_output_acc: 0.7661 - age_output_acc: 0.6359 - weight_output_acc: 0.7817 - bag_output_acc: 0.8705 - footwear_output_acc: 0.8339 - pose_output_acc: 0.9395 - emotion_output_acc: 0.7359 - val_loss: 4.6105 - val_gender_output_loss: 0.1166 - val_image_quality_output_loss: 0.8397 - val_age_output_loss: 0.9745 - val_weight_output_loss: 0.6851 - val_bag_output_loss: 0.4929 - val_footwear_output_loss: 0.5895 - val_pose_output_loss: 0.1548 - val_emotion_output_loss: 0.7574 - val_gender_output_acc: 0.9652 - val_image_quality_output_acc: 0.6573 - val_age_output_acc: 0.5827 - val_weight_output_acc: 0.7374 - val_bag_output_acc: 0.8402 - val_footwear_output_acc: 0.7954 - val_pose_output_acc: 0.9476 - val_emotion_output_acc: 0.7404\n",
            "Epoch 33/100\n",
            "360/360 [==============================] - 287s 796ms/step - loss: 3.6940 - gender_output_loss: 0.1091 - image_quality_output_loss: 0.5481 - age_output_loss: 0.8553 - weight_output_loss: 0.5473 - bag_output_loss: 0.3312 - footwear_output_loss: 0.4084 - pose_output_loss: 0.1639 - emotion_output_loss: 0.7306 - gender_output_acc: 0.9561 - image_quality_output_acc: 0.7628 - age_output_acc: 0.6361 - weight_output_acc: 0.7857 - bag_output_acc: 0.8725 - footwear_output_acc: 0.8366 - pose_output_acc: 0.9389 - emotion_output_acc: 0.7339 - val_loss: 4.6921 - val_gender_output_loss: 0.1078 - val_image_quality_output_loss: 0.8642 - val_age_output_loss: 1.0150 - val_weight_output_loss: 0.6575 - val_bag_output_loss: 0.4911 - val_footwear_output_loss: 0.6138 - val_pose_output_loss: 0.1648 - val_emotion_output_loss: 0.7780 - val_gender_output_acc: 0.9718 - val_image_quality_output_acc: 0.6623 - val_age_output_acc: 0.5801 - val_weight_output_acc: 0.7490 - val_bag_output_acc: 0.8458 - val_footwear_output_acc: 0.7823 - val_pose_output_acc: 0.9481 - val_emotion_output_acc: 0.7394\n",
            "Epoch 34/100\n",
            "360/360 [==============================] - 287s 797ms/step - loss: 3.6585 - gender_output_loss: 0.1093 - image_quality_output_loss: 0.5415 - age_output_loss: 0.8468 - weight_output_loss: 0.5458 - bag_output_loss: 0.3218 - footwear_output_loss: 0.4062 - pose_output_loss: 0.1617 - emotion_output_loss: 0.7254 - gender_output_acc: 0.9536 - image_quality_output_acc: 0.7667 - age_output_acc: 0.6324 - weight_output_acc: 0.7826 - bag_output_acc: 0.8736 - footwear_output_acc: 0.8381 - pose_output_acc: 0.9397 - emotion_output_acc: 0.7339 - val_loss: 4.7724 - val_gender_output_loss: 0.1024 - val_image_quality_output_loss: 0.8777 - val_age_output_loss: 1.0204 - val_weight_output_loss: 0.6549 - val_bag_output_loss: 0.5185 - val_footwear_output_loss: 0.6513 - val_pose_output_loss: 0.1817 - val_emotion_output_loss: 0.7655 - val_gender_output_acc: 0.9667 - val_image_quality_output_acc: 0.6532 - val_age_output_acc: 0.5862 - val_weight_output_acc: 0.7485 - val_bag_output_acc: 0.8150 - val_footwear_output_acc: 0.7782 - val_pose_output_acc: 0.9471 - val_emotion_output_acc: 0.7354\n",
            "Epoch 35/100\n",
            "360/360 [==============================] - 285s 791ms/step - loss: 3.6268 - gender_output_loss: 0.1078 - image_quality_output_loss: 0.5358 - age_output_loss: 0.8427 - weight_output_loss: 0.5322 - bag_output_loss: 0.3231 - footwear_output_loss: 0.4053 - pose_output_loss: 0.1640 - emotion_output_loss: 0.7158 - gender_output_acc: 0.9543 - image_quality_output_acc: 0.7713 - age_output_acc: 0.6426 - weight_output_acc: 0.7898 - bag_output_acc: 0.8740 - footwear_output_acc: 0.8340 - pose_output_acc: 0.9375 - emotion_output_acc: 0.7409 - val_loss: 4.8868 - val_gender_output_loss: 0.0990 - val_image_quality_output_loss: 0.9268 - val_age_output_loss: 1.0374 - val_weight_output_loss: 0.6809 - val_bag_output_loss: 0.5279 - val_footwear_output_loss: 0.6415 - val_pose_output_loss: 0.1779 - val_emotion_output_loss: 0.7953 - val_gender_output_acc: 0.9708 - val_image_quality_output_acc: 0.6638 - val_age_output_acc: 0.5806 - val_weight_output_acc: 0.7349 - val_bag_output_acc: 0.8443 - val_footwear_output_acc: 0.7727 - val_pose_output_acc: 0.9476 - val_emotion_output_acc: 0.7324\n",
            "Epoch 36/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 3.5833 - gender_output_loss: 0.1144 - image_quality_output_loss: 0.5384 - age_output_loss: 0.8298 - weight_output_loss: 0.5206 - bag_output_loss: 0.3180 - footwear_output_loss: 0.3917 - pose_output_loss: 0.1526 - emotion_output_loss: 0.7178 - gender_output_acc: 0.9527 - image_quality_output_acc: 0.7686 - age_output_acc: 0.6484 - weight_output_acc: 0.7974 - bag_output_acc: 0.8756 - footwear_output_acc: 0.8405 - pose_output_acc: 0.9421 - emotion_output_acc: 0.7395Epoch 36/100\n",
            "360/360 [==============================] - 286s 794ms/step - loss: 3.5859 - gender_output_loss: 0.1146 - image_quality_output_loss: 0.5385 - age_output_loss: 0.8301 - weight_output_loss: 0.5205 - bag_output_loss: 0.3189 - footwear_output_loss: 0.3926 - pose_output_loss: 0.1528 - emotion_output_loss: 0.7179 - gender_output_acc: 0.9526 - image_quality_output_acc: 0.7686 - age_output_acc: 0.6481 - weight_output_acc: 0.7972 - bag_output_acc: 0.8752 - footwear_output_acc: 0.8400 - pose_output_acc: 0.9420 - emotion_output_acc: 0.7395 - val_loss: 4.8075 - val_gender_output_loss: 0.1050 - val_image_quality_output_loss: 0.8577 - val_age_output_loss: 1.0604 - val_weight_output_loss: 0.7123 - val_bag_output_loss: 0.5181 - val_footwear_output_loss: 0.5968 - val_pose_output_loss: 0.1658 - val_emotion_output_loss: 0.7915 - val_gender_output_acc: 0.9657 - val_image_quality_output_acc: 0.6668 - val_age_output_acc: 0.5706 - val_weight_output_acc: 0.7389 - val_bag_output_acc: 0.8488 - val_footwear_output_acc: 0.7752 - val_pose_output_acc: 0.9521 - val_emotion_output_acc: 0.7268\n",
            "Epoch 37/100\n",
            "360/360 [==============================] - 284s 790ms/step - loss: 3.6051 - gender_output_loss: 0.1117 - image_quality_output_loss: 0.5316 - age_output_loss: 0.8336 - weight_output_loss: 0.5330 - bag_output_loss: 0.3203 - footwear_output_loss: 0.4007 - pose_output_loss: 0.1594 - emotion_output_loss: 0.7148 - gender_output_acc: 0.9540 - image_quality_output_acc: 0.7694 - age_output_acc: 0.6400 - weight_output_acc: 0.7878 - bag_output_acc: 0.8745 - footwear_output_acc: 0.8384 - pose_output_acc: 0.9398 - emotion_output_acc: 0.7399 - val_loss: 4.9019 - val_gender_output_loss: 0.0888 - val_image_quality_output_loss: 1.0198 - val_age_output_loss: 1.0031 - val_weight_output_loss: 0.7025 - val_bag_output_loss: 0.4819 - val_footwear_output_loss: 0.6884 - val_pose_output_loss: 0.1436 - val_emotion_output_loss: 0.7739 - val_gender_output_acc: 0.9713 - val_image_quality_output_acc: 0.6406 - val_age_output_acc: 0.5791 - val_weight_output_acc: 0.7329 - val_bag_output_acc: 0.8458 - val_footwear_output_acc: 0.7732 - val_pose_output_acc: 0.9561 - val_emotion_output_acc: 0.7359\n",
            "Epoch 38/100\n",
            "360/360 [==============================] - 286s 794ms/step - loss: 3.5679 - gender_output_loss: 0.1112 - image_quality_output_loss: 0.5186 - age_output_loss: 0.8266 - weight_output_loss: 0.5188 - bag_output_loss: 0.3242 - footwear_output_loss: 0.4006 - pose_output_loss: 0.1511 - emotion_output_loss: 0.7168 - gender_output_acc: 0.9540 - image_quality_output_acc: 0.7804 - age_output_acc: 0.6507 - weight_output_acc: 0.7948 - bag_output_acc: 0.8756 - footwear_output_acc: 0.8387 - pose_output_acc: 0.9435 - emotion_output_acc: 0.7393 - val_loss: 4.7722 - val_gender_output_loss: 0.0816 - val_image_quality_output_loss: 0.8877 - val_age_output_loss: 1.0091 - val_weight_output_loss: 0.6887 - val_bag_output_loss: 0.5065 - val_footwear_output_loss: 0.6219 - val_pose_output_loss: 0.1967 - val_emotion_output_loss: 0.7800 - val_gender_output_acc: 0.9768 - val_image_quality_output_acc: 0.6497 - val_age_output_acc: 0.5781 - val_weight_output_acc: 0.7455 - val_bag_output_acc: 0.8453 - val_footwear_output_acc: 0.7797 - val_pose_output_acc: 0.9380 - val_emotion_output_acc: 0.7409\n",
            "Epoch 39/100\n",
            "360/360 [==============================] - 287s 797ms/step - loss: 3.5337 - gender_output_loss: 0.1070 - image_quality_output_loss: 0.5196 - age_output_loss: 0.8226 - weight_output_loss: 0.5153 - bag_output_loss: 0.3097 - footwear_output_loss: 0.3834 - pose_output_loss: 0.1598 - emotion_output_loss: 0.7163 - gender_output_acc: 0.9557 - image_quality_output_acc: 0.7777 - age_output_acc: 0.6541 - weight_output_acc: 0.7950 - bag_output_acc: 0.8819 - footwear_output_acc: 0.8496 - pose_output_acc: 0.9391 - emotion_output_acc: 0.7427 - val_loss: 5.0181 - val_gender_output_loss: 0.1040 - val_image_quality_output_loss: 0.8928 - val_age_output_loss: 1.0981 - val_weight_output_loss: 0.7449 - val_bag_output_loss: 0.5261 - val_footwear_output_loss: 0.7219 - val_pose_output_loss: 0.1543 - val_emotion_output_loss: 0.7760 - val_gender_output_acc: 0.9693 - val_image_quality_output_acc: 0.6588 - val_age_output_acc: 0.5575 - val_weight_output_acc: 0.7218 - val_bag_output_acc: 0.8317 - val_footwear_output_acc: 0.7772 - val_pose_output_acc: 0.9501 - val_emotion_output_acc: 0.7308\n",
            "Epoch 40/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 3.5280 - gender_output_loss: 0.1120 - image_quality_output_loss: 0.5097 - age_output_loss: 0.8259 - weight_output_loss: 0.5177 - bag_output_loss: 0.3060 - footwear_output_loss: 0.3868 - pose_output_loss: 0.1630 - emotion_output_loss: 0.7071 - gender_output_acc: 0.9539 - image_quality_output_acc: 0.7792 - age_output_acc: 0.6513 - weight_output_acc: 0.7960 - bag_output_acc: 0.8799 - footwear_output_acc: 0.8432 - pose_output_acc: 0.9380 - emotion_output_acc: 0.7420Epoch 40/100\n",
            "360/360 [==============================] - 289s 804ms/step - loss: 3.5283 - gender_output_loss: 0.1120 - image_quality_output_loss: 0.5102 - age_output_loss: 0.8258 - weight_output_loss: 0.5179 - bag_output_loss: 0.3063 - footwear_output_loss: 0.3869 - pose_output_loss: 0.1627 - emotion_output_loss: 0.7066 - gender_output_acc: 0.9539 - image_quality_output_acc: 0.7787 - age_output_acc: 0.6514 - weight_output_acc: 0.7957 - bag_output_acc: 0.8799 - footwear_output_acc: 0.8431 - pose_output_acc: 0.9382 - emotion_output_acc: 0.7421 - val_loss: 5.0546 - val_gender_output_loss: 0.1103 - val_image_quality_output_loss: 0.9439 - val_age_output_loss: 1.0307 - val_weight_output_loss: 0.7125 - val_bag_output_loss: 0.5448 - val_footwear_output_loss: 0.6877 - val_pose_output_loss: 0.2123 - val_emotion_output_loss: 0.8124 - val_gender_output_acc: 0.9632 - val_image_quality_output_acc: 0.6608 - val_age_output_acc: 0.5943 - val_weight_output_acc: 0.7450 - val_bag_output_acc: 0.8191 - val_footwear_output_acc: 0.7727 - val_pose_output_acc: 0.9441 - val_emotion_output_acc: 0.7308\n",
            "\n",
            "Epoch 00040: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 41/100\n",
            "360/360 [==============================] - 286s 794ms/step - loss: 3.4952 - gender_output_loss: 0.1078 - image_quality_output_loss: 0.5142 - age_output_loss: 0.8153 - weight_output_loss: 0.5080 - bag_output_loss: 0.3074 - footwear_output_loss: 0.3816 - pose_output_loss: 0.1596 - emotion_output_loss: 0.7013 - gender_output_acc: 0.9541 - image_quality_output_acc: 0.7817 - age_output_acc: 0.6530 - weight_output_acc: 0.8003 - bag_output_acc: 0.8841 - footwear_output_acc: 0.8456 - pose_output_acc: 0.9397 - emotion_output_acc: 0.7411 - val_loss: 5.1860 - val_gender_output_loss: 0.1135 - val_image_quality_output_loss: 0.9407 - val_age_output_loss: 1.0425 - val_weight_output_loss: 0.7827 - val_bag_output_loss: 0.5463 - val_footwear_output_loss: 0.7632 - val_pose_output_loss: 0.1796 - val_emotion_output_loss: 0.8174 - val_gender_output_acc: 0.9642 - val_image_quality_output_acc: 0.6593 - val_age_output_acc: 0.5857 - val_weight_output_acc: 0.7218 - val_bag_output_acc: 0.8322 - val_footwear_output_acc: 0.7611 - val_pose_output_acc: 0.9471 - val_emotion_output_acc: 0.7293\n",
            "Epoch 42/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 3.4721 - gender_output_loss: 0.1051 - image_quality_output_loss: 0.5122 - age_output_loss: 0.8001 - weight_output_loss: 0.5171 - bag_output_loss: 0.3031 - footwear_output_loss: 0.3736 - pose_output_loss: 0.1615 - emotion_output_loss: 0.6993 - gender_output_acc: 0.9567 - image_quality_output_acc: 0.7798 - age_output_acc: 0.6669 - weight_output_acc: 0.7949 - bag_output_acc: 0.8812 - footwear_output_acc: 0.8504 - pose_output_acc: 0.9379 - emotion_output_acc: 0.7434Epoch 42/100\n",
            "360/360 [==============================] - 286s 794ms/step - loss: 3.4708 - gender_output_loss: 0.1049 - image_quality_output_loss: 0.5124 - age_output_loss: 0.7998 - weight_output_loss: 0.5167 - bag_output_loss: 0.3030 - footwear_output_loss: 0.3735 - pose_output_loss: 0.1614 - emotion_output_loss: 0.6991 - gender_output_acc: 0.9568 - image_quality_output_acc: 0.7798 - age_output_acc: 0.6670 - weight_output_acc: 0.7951 - bag_output_acc: 0.8810 - footwear_output_acc: 0.8504 - pose_output_acc: 0.9380 - emotion_output_acc: 0.7435 - val_loss: 5.0800 - val_gender_output_loss: 0.0861 - val_image_quality_output_loss: 0.9767 - val_age_output_loss: 1.0496 - val_weight_output_loss: 0.7887 - val_bag_output_loss: 0.5459 - val_footwear_output_loss: 0.6593 - val_pose_output_loss: 0.1745 - val_emotion_output_loss: 0.7992 - val_gender_output_acc: 0.9753 - val_image_quality_output_acc: 0.6497 - val_age_output_acc: 0.5887 - val_weight_output_acc: 0.7067 - val_bag_output_acc: 0.8367 - val_footwear_output_acc: 0.7818 - val_pose_output_acc: 0.9425 - val_emotion_output_acc: 0.7329\n",
            "Epoch 43/100\n",
            "360/360 [==============================] - 282s 782ms/step - loss: 3.3939 - gender_output_loss: 0.1068 - image_quality_output_loss: 0.4934 - age_output_loss: 0.8008 - weight_output_loss: 0.4937 - bag_output_loss: 0.2948 - footwear_output_loss: 0.3631 - pose_output_loss: 0.1478 - emotion_output_loss: 0.6936 - gender_output_acc: 0.9558 - image_quality_output_acc: 0.7943 - age_output_acc: 0.6627 - weight_output_acc: 0.8087 - bag_output_acc: 0.8827 - footwear_output_acc: 0.8536 - pose_output_acc: 0.9454 - emotion_output_acc: 0.7488 - val_loss: 5.3494 - val_gender_output_loss: 0.1008 - val_image_quality_output_loss: 1.1041 - val_age_output_loss: 1.1225 - val_weight_output_loss: 0.8142 - val_bag_output_loss: 0.5381 - val_footwear_output_loss: 0.6707 - val_pose_output_loss: 0.1937 - val_emotion_output_loss: 0.8054 - val_gender_output_acc: 0.9637 - val_image_quality_output_acc: 0.6230 - val_age_output_acc: 0.5620 - val_weight_output_acc: 0.7198 - val_bag_output_acc: 0.8332 - val_footwear_output_acc: 0.7656 - val_pose_output_acc: 0.9435 - val_emotion_output_acc: 0.7172\n",
            "Epoch 44/100\n",
            "360/360 [==============================] - 282s 785ms/step - loss: 3.3866 - gender_output_loss: 0.1054 - image_quality_output_loss: 0.4950 - age_output_loss: 0.7874 - weight_output_loss: 0.4932 - bag_output_loss: 0.2908 - footwear_output_loss: 0.3641 - pose_output_loss: 0.1591 - emotion_output_loss: 0.6916 - gender_output_acc: 0.9567 - image_quality_output_acc: 0.7872 - age_output_acc: 0.6694 - weight_output_acc: 0.8072 - bag_output_acc: 0.8874 - footwear_output_acc: 0.8498 - pose_output_acc: 0.9404 - emotion_output_acc: 0.7477 - val_loss: 5.3705 - val_gender_output_loss: 0.1095 - val_image_quality_output_loss: 1.0038 - val_age_output_loss: 1.1348 - val_weight_output_loss: 0.8574 - val_bag_output_loss: 0.5954 - val_footwear_output_loss: 0.6818 - val_pose_output_loss: 0.1796 - val_emotion_output_loss: 0.8084 - val_gender_output_acc: 0.9713 - val_image_quality_output_acc: 0.6351 - val_age_output_acc: 0.5640 - val_weight_output_acc: 0.7087 - val_bag_output_acc: 0.8407 - val_footwear_output_acc: 0.7797 - val_pose_output_acc: 0.9501 - val_emotion_output_acc: 0.7324\n",
            "Epoch 45/100\n",
            "360/360 [==============================] - 282s 783ms/step - loss: 3.4140 - gender_output_loss: 0.1079 - image_quality_output_loss: 0.4896 - age_output_loss: 0.8069 - weight_output_loss: 0.5050 - bag_output_loss: 0.2938 - footwear_output_loss: 0.3772 - pose_output_loss: 0.1501 - emotion_output_loss: 0.6836 - gender_output_acc: 0.9565 - image_quality_output_acc: 0.7911 - age_output_acc: 0.6629 - weight_output_acc: 0.8044 - bag_output_acc: 0.8822 - footwear_output_acc: 0.8502 - pose_output_acc: 0.9446 - emotion_output_acc: 0.7473 - val_loss: 5.0228 - val_gender_output_loss: 0.1034 - val_image_quality_output_loss: 0.9842 - val_age_output_loss: 1.0491 - val_weight_output_loss: 0.7372 - val_bag_output_loss: 0.5263 - val_footwear_output_loss: 0.6363 - val_pose_output_loss: 0.1897 - val_emotion_output_loss: 0.7967 - val_gender_output_acc: 0.9682 - val_image_quality_output_acc: 0.6245 - val_age_output_acc: 0.5685 - val_weight_output_acc: 0.7243 - val_bag_output_acc: 0.8226 - val_footwear_output_acc: 0.7515 - val_pose_output_acc: 0.9435 - val_emotion_output_acc: 0.7238\n",
            "Epoch 46/100\n",
            "360/360 [==============================] - 283s 787ms/step - loss: 3.9885 - gender_output_loss: 0.1580 - image_quality_output_loss: 0.5908 - age_output_loss: 0.9020 - weight_output_loss: 0.5799 - bag_output_loss: 0.3786 - footwear_output_loss: 0.4502 - pose_output_loss: 0.2052 - emotion_output_loss: 0.7237 - gender_output_acc: 0.9348 - image_quality_output_acc: 0.7411 - age_output_acc: 0.6143 - weight_output_acc: 0.7726 - bag_output_acc: 0.8497 - footwear_output_acc: 0.8135 - pose_output_acc: 0.9200 - emotion_output_acc: 0.7405 - val_loss: 5.1293 - val_gender_output_loss: 0.1034 - val_image_quality_output_loss: 0.9610 - val_age_output_loss: 1.0500 - val_weight_output_loss: 0.7706 - val_bag_output_loss: 0.5600 - val_footwear_output_loss: 0.7108 - val_pose_output_loss: 0.1877 - val_emotion_output_loss: 0.7859 - val_gender_output_acc: 0.9622 - val_image_quality_output_acc: 0.6134 - val_age_output_acc: 0.5761 - val_weight_output_acc: 0.7228 - val_bag_output_acc: 0.8165 - val_footwear_output_acc: 0.7445 - val_pose_output_acc: 0.9405 - val_emotion_output_acc: 0.7228\n",
            "Epoch 47/100\n",
            "360/360 [==============================] - 281s 781ms/step - loss: 3.3958 - gender_output_loss: 0.1039 - image_quality_output_loss: 0.4948 - age_output_loss: 0.7916 - weight_output_loss: 0.4978 - bag_output_loss: 0.2970 - footwear_output_loss: 0.3702 - pose_output_loss: 0.1550 - emotion_output_loss: 0.6854 - gender_output_acc: 0.9573 - image_quality_output_acc: 0.7880 - age_output_acc: 0.6657 - weight_output_acc: 0.8040 - bag_output_acc: 0.8845 - footwear_output_acc: 0.8518 - pose_output_acc: 0.9435 - emotion_output_acc: 0.7432 - val_loss: 5.2677 - val_gender_output_loss: 0.0957 - val_image_quality_output_loss: 1.0695 - val_age_output_loss: 1.0705 - val_weight_output_loss: 0.7599 - val_bag_output_loss: 0.5939 - val_footwear_output_loss: 0.6888 - val_pose_output_loss: 0.1816 - val_emotion_output_loss: 0.8078 - val_gender_output_acc: 0.9688 - val_image_quality_output_acc: 0.6270 - val_age_output_acc: 0.5640 - val_weight_output_acc: 0.7273 - val_bag_output_acc: 0.8306 - val_footwear_output_acc: 0.7611 - val_pose_output_acc: 0.9481 - val_emotion_output_acc: 0.7137\n",
            "Epoch 48/100\n",
            "360/360 [==============================] - 285s 791ms/step - loss: 3.3288 - gender_output_loss: 0.1082 - image_quality_output_loss: 0.4732 - age_output_loss: 0.7899 - weight_output_loss: 0.4835 - bag_output_loss: 0.2776 - footwear_output_loss: 0.3641 - pose_output_loss: 0.1509 - emotion_output_loss: 0.6813 - gender_output_acc: 0.9545 - image_quality_output_acc: 0.7997 - age_output_acc: 0.6662 - weight_output_acc: 0.8091 - bag_output_acc: 0.8919 - footwear_output_acc: 0.8521 - pose_output_acc: 0.9421 - emotion_output_acc: 0.7484 - val_loss: 5.4225 - val_gender_output_loss: 0.1344 - val_image_quality_output_loss: 1.0200 - val_age_output_loss: 1.0969 - val_weight_output_loss: 0.7830 - val_bag_output_loss: 0.6403 - val_footwear_output_loss: 0.7289 - val_pose_output_loss: 0.1834 - val_emotion_output_loss: 0.8356 - val_gender_output_acc: 0.9572 - val_image_quality_output_acc: 0.6492 - val_age_output_acc: 0.5811 - val_weight_output_acc: 0.7228 - val_bag_output_acc: 0.8317 - val_footwear_output_acc: 0.7666 - val_pose_output_acc: 0.9486 - val_emotion_output_acc: 0.7238\n",
            "Epoch 49/100\n",
            "360/360 [==============================] - 281s 780ms/step - loss: 3.2927 - gender_output_loss: 0.1086 - image_quality_output_loss: 0.4766 - age_output_loss: 0.7643 - weight_output_loss: 0.4813 - bag_output_loss: 0.2751 - footwear_output_loss: 0.3553 - pose_output_loss: 0.1497 - emotion_output_loss: 0.6818 - gender_output_acc: 0.9560 - image_quality_output_acc: 0.7955 - age_output_acc: 0.6825 - weight_output_acc: 0.8116 - bag_output_acc: 0.8917 - footwear_output_acc: 0.8566 - pose_output_acc: 0.9433 - emotion_output_acc: 0.7488 - val_loss: 5.6264 - val_gender_output_loss: 0.0947 - val_image_quality_output_loss: 1.0552 - val_age_output_loss: 1.1397 - val_weight_output_loss: 0.7760 - val_bag_output_loss: 0.6895 - val_footwear_output_loss: 0.8372 - val_pose_output_loss: 0.1951 - val_emotion_output_loss: 0.8391 - val_gender_output_acc: 0.9693 - val_image_quality_output_acc: 0.6295 - val_age_output_acc: 0.5570 - val_weight_output_acc: 0.7238 - val_bag_output_acc: 0.8024 - val_footwear_output_acc: 0.7555 - val_pose_output_acc: 0.9456 - val_emotion_output_acc: 0.7293\n",
            "Epoch 50/100\n",
            "360/360 [==============================] - 282s 784ms/step - loss: 3.2520 - gender_output_loss: 0.1001 - image_quality_output_loss: 0.4727 - age_output_loss: 0.7684 - weight_output_loss: 0.4738 - bag_output_loss: 0.2707 - footwear_output_loss: 0.3440 - pose_output_loss: 0.1471 - emotion_output_loss: 0.6753 - gender_output_acc: 0.9583 - image_quality_output_acc: 0.7986 - age_output_acc: 0.6773 - weight_output_acc: 0.8134 - bag_output_acc: 0.8966 - footwear_output_acc: 0.8622 - pose_output_acc: 0.9416 - emotion_output_acc: 0.7491 - val_loss: 5.3998 - val_gender_output_loss: 0.1039 - val_image_quality_output_loss: 1.0496 - val_age_output_loss: 1.0760 - val_weight_output_loss: 0.7289 - val_bag_output_loss: 0.6664 - val_footwear_output_loss: 0.7667 - val_pose_output_loss: 0.1864 - val_emotion_output_loss: 0.8219 - val_gender_output_acc: 0.9652 - val_image_quality_output_acc: 0.6467 - val_age_output_acc: 0.5731 - val_weight_output_acc: 0.7364 - val_bag_output_acc: 0.8170 - val_footwear_output_acc: 0.7399 - val_pose_output_acc: 0.9491 - val_emotion_output_acc: 0.7374\n",
            "\n",
            "Epoch 00050: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 51/100\n",
            "360/360 [==============================] - 281s 780ms/step - loss: 3.2341 - gender_output_loss: 0.1051 - image_quality_output_loss: 0.4556 - age_output_loss: 0.7664 - weight_output_loss: 0.4804 - bag_output_loss: 0.2741 - footwear_output_loss: 0.3408 - pose_output_loss: 0.1468 - emotion_output_loss: 0.6649 - gender_output_acc: 0.9576 - image_quality_output_acc: 0.8082 - age_output_acc: 0.6785 - weight_output_acc: 0.8130 - bag_output_acc: 0.8954 - footwear_output_acc: 0.8621 - pose_output_acc: 0.9461 - emotion_output_acc: 0.7546 - val_loss: 5.6007 - val_gender_output_loss: 0.1052 - val_image_quality_output_loss: 1.0928 - val_age_output_loss: 1.1398 - val_weight_output_loss: 0.8499 - val_bag_output_loss: 0.5682 - val_footwear_output_loss: 0.8316 - val_pose_output_loss: 0.1872 - val_emotion_output_loss: 0.8260 - val_gender_output_acc: 0.9693 - val_image_quality_output_acc: 0.6245 - val_age_output_acc: 0.5625 - val_weight_output_acc: 0.7061 - val_bag_output_acc: 0.8216 - val_footwear_output_acc: 0.7611 - val_pose_output_acc: 0.9451 - val_emotion_output_acc: 0.7273\n",
            "\n",
            "Epoch 00050: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 52/100\n",
            "360/360 [==============================] - 288s 800ms/step - loss: 3.1928 - gender_output_loss: 0.0994 - image_quality_output_loss: 0.4617 - age_output_loss: 0.7620 - weight_output_loss: 0.4653 - bag_output_loss: 0.2664 - footwear_output_loss: 0.3340 - pose_output_loss: 0.1385 - emotion_output_loss: 0.6655 - gender_output_acc: 0.9609 - image_quality_output_acc: 0.8062 - age_output_acc: 0.6780 - weight_output_acc: 0.8142 - bag_output_acc: 0.8978 - footwear_output_acc: 0.8684 - pose_output_acc: 0.9499 - emotion_output_acc: 0.7534 - val_loss: 5.4633 - val_gender_output_loss: 0.1236 - val_image_quality_output_loss: 1.0026 - val_age_output_loss: 1.0757 - val_weight_output_loss: 0.8343 - val_bag_output_loss: 0.6352 - val_footwear_output_loss: 0.7774 - val_pose_output_loss: 0.1717 - val_emotion_output_loss: 0.8429 - val_gender_output_acc: 0.9602 - val_image_quality_output_acc: 0.6406 - val_age_output_acc: 0.5806 - val_weight_output_acc: 0.7218 - val_bag_output_acc: 0.8211 - val_footwear_output_acc: 0.7414 - val_pose_output_acc: 0.9446 - val_emotion_output_acc: 0.7203\n",
            "Epoch 53/100\n",
            "360/360 [==============================] - 286s 796ms/step - loss: 3.1496 - gender_output_loss: 0.1049 - image_quality_output_loss: 0.4455 - age_output_loss: 0.7393 - weight_output_loss: 0.4599 - bag_output_loss: 0.2690 - footwear_output_loss: 0.3309 - pose_output_loss: 0.1432 - emotion_output_loss: 0.6569 - gender_output_acc: 0.9549 - image_quality_output_acc: 0.8111 - age_output_acc: 0.6937 - weight_output_acc: 0.8212 - bag_output_acc: 0.8961 - footwear_output_acc: 0.8671 - pose_output_acc: 0.9456 - emotion_output_acc: 0.7572 - val_loss: 5.6417 - val_gender_output_loss: 0.1321 - val_image_quality_output_loss: 1.0894 - val_age_output_loss: 1.1259 - val_weight_output_loss: 0.8424 - val_bag_output_loss: 0.5975 - val_footwear_output_loss: 0.8512 - val_pose_output_loss: 0.1791 - val_emotion_output_loss: 0.8239 - val_gender_output_acc: 0.9602 - val_image_quality_output_acc: 0.6376 - val_age_output_acc: 0.5590 - val_weight_output_acc: 0.7198 - val_bag_output_acc: 0.8261 - val_footwear_output_acc: 0.7404 - val_pose_output_acc: 0.9471 - val_emotion_output_acc: 0.7324\n",
            "Epoch 54/100\n",
            "360/360 [==============================] - 285s 793ms/step - loss: 3.1468 - gender_output_loss: 0.0988 - image_quality_output_loss: 0.4450 - age_output_loss: 0.7455 - weight_output_loss: 0.4624 - bag_output_loss: 0.2670 - footwear_output_loss: 0.3319 - pose_output_loss: 0.1464 - emotion_output_loss: 0.6499 - gender_output_acc: 0.9591 - image_quality_output_acc: 0.8130 - age_output_acc: 0.6905 - weight_output_acc: 0.8171 - bag_output_acc: 0.8963 - footwear_output_acc: 0.8664 - pose_output_acc: 0.9452 - emotion_output_acc: 0.7617 - val_loss: 5.8914 - val_gender_output_loss: 0.1234 - val_image_quality_output_loss: 1.2960 - val_age_output_loss: 1.1237 - val_weight_output_loss: 0.8372 - val_bag_output_loss: 0.6325 - val_footwear_output_loss: 0.7931 - val_pose_output_loss: 0.2053 - val_emotion_output_loss: 0.8803 - val_gender_output_acc: 0.9667 - val_image_quality_output_acc: 0.5796 - val_age_output_acc: 0.5620 - val_weight_output_acc: 0.7182 - val_bag_output_acc: 0.8226 - val_footwear_output_acc: 0.7339 - val_pose_output_acc: 0.9400 - val_emotion_output_acc: 0.7233\n",
            "Epoch 55/100\n",
            "360/360 [==============================] - 282s 785ms/step - loss: 3.1547 - gender_output_loss: 0.0995 - image_quality_output_loss: 0.4418 - age_output_loss: 0.7419 - weight_output_loss: 0.4600 - bag_output_loss: 0.2757 - footwear_output_loss: 0.3334 - pose_output_loss: 0.1480 - emotion_output_loss: 0.6546 - gender_output_acc: 0.9595 - image_quality_output_acc: 0.8105 - age_output_acc: 0.6956 - weight_output_acc: 0.8216 - bag_output_acc: 0.8931 - footwear_output_acc: 0.8668 - pose_output_acc: 0.9427 - emotion_output_acc: 0.7588 - val_loss: 5.6540 - val_gender_output_loss: 0.1055 - val_image_quality_output_loss: 1.2520 - val_age_output_loss: 1.1499 - val_weight_output_loss: 0.7875 - val_bag_output_loss: 0.5902 - val_footwear_output_loss: 0.7562 - val_pose_output_loss: 0.1751 - val_emotion_output_loss: 0.8375 - val_gender_output_acc: 0.9672 - val_image_quality_output_acc: 0.5938 - val_age_output_acc: 0.5665 - val_weight_output_acc: 0.7223 - val_bag_output_acc: 0.8256 - val_footwear_output_acc: 0.7440 - val_pose_output_acc: 0.9420 - val_emotion_output_acc: 0.7298\n",
            "Epoch 56/100\n",
            "360/360 [==============================] - 284s 789ms/step - loss: 3.1024 - gender_output_loss: 0.1061 - image_quality_output_loss: 0.4317 - age_output_loss: 0.7322 - weight_output_loss: 0.4538 - bag_output_loss: 0.2661 - footwear_output_loss: 0.3271 - pose_output_loss: 0.1377 - emotion_output_loss: 0.6477 - gender_output_acc: 0.9559 - image_quality_output_acc: 0.8170 - age_output_acc: 0.6905 - weight_output_acc: 0.8221 - bag_output_acc: 0.8949 - footwear_output_acc: 0.8694 - pose_output_acc: 0.9494 - emotion_output_acc: 0.7636 - val_loss: 6.0369 - val_gender_output_loss: 0.1140 - val_image_quality_output_loss: 1.2709 - val_age_output_loss: 1.2211 - val_weight_output_loss: 0.8299 - val_bag_output_loss: 0.7027 - val_footwear_output_loss: 0.8130 - val_pose_output_loss: 0.1991 - val_emotion_output_loss: 0.8861 - val_gender_output_acc: 0.9647 - val_image_quality_output_acc: 0.6008 - val_age_output_acc: 0.5605 - val_weight_output_acc: 0.7223 - val_bag_output_acc: 0.8044 - val_footwear_output_acc: 0.7631 - val_pose_output_acc: 0.9410 - val_emotion_output_acc: 0.7329\n",
            "Epoch 57/100\n",
            "360/360 [==============================] - 283s 787ms/step - loss: 3.0754 - gender_output_loss: 0.1019 - image_quality_output_loss: 0.4308 - age_output_loss: 0.7241 - weight_output_loss: 0.4512 - bag_output_loss: 0.2585 - footwear_output_loss: 0.3219 - pose_output_loss: 0.1446 - emotion_output_loss: 0.6424 - gender_output_acc: 0.9575 - image_quality_output_acc: 0.8199 - age_output_acc: 0.6983 - weight_output_acc: 0.8234 - bag_output_acc: 0.8970 - footwear_output_acc: 0.8727 - pose_output_acc: 0.9444 - emotion_output_acc: 0.7614 - val_loss: 5.8627 - val_gender_output_loss: 0.1258 - val_image_quality_output_loss: 1.1729 - val_age_output_loss: 1.1952 - val_weight_output_loss: 0.8863 - val_bag_output_loss: 0.6546 - val_footwear_output_loss: 0.7907 - val_pose_output_loss: 0.2042 - val_emotion_output_loss: 0.8330 - val_gender_output_acc: 0.9677 - val_image_quality_output_acc: 0.6265 - val_age_output_acc: 0.5559 - val_weight_output_acc: 0.7021 - val_bag_output_acc: 0.8221 - val_footwear_output_acc: 0.7581 - val_pose_output_acc: 0.9395 - val_emotion_output_acc: 0.7208\n",
            "Epoch 58/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 3.0904 - gender_output_loss: 0.0999 - image_quality_output_loss: 0.4382 - age_output_loss: 0.7401 - weight_output_loss: 0.4507 - bag_output_loss: 0.2560 - footwear_output_loss: 0.3272 - pose_output_loss: 0.1371 - emotion_output_loss: 0.6412 - gender_output_acc: 0.9607 - image_quality_output_acc: 0.8155 - age_output_acc: 0.6922 - weight_output_acc: 0.8240 - bag_output_acc: 0.9000 - footwear_output_acc: 0.8698 - pose_output_acc: 0.9477 - emotion_output_acc: 0.7629Epoch 58/100\n",
            "360/360 [==============================] - 283s 786ms/step - loss: 3.0919 - gender_output_loss: 0.1003 - image_quality_output_loss: 0.4385 - age_output_loss: 0.7403 - weight_output_loss: 0.4504 - bag_output_loss: 0.2560 - footwear_output_loss: 0.3278 - pose_output_loss: 0.1375 - emotion_output_loss: 0.6412 - gender_output_acc: 0.9605 - image_quality_output_acc: 0.8153 - age_output_acc: 0.6923 - weight_output_acc: 0.8240 - bag_output_acc: 0.9000 - footwear_output_acc: 0.8693 - pose_output_acc: 0.9477 - emotion_output_acc: 0.7630 - val_loss: 5.7328 - val_gender_output_loss: 0.1455 - val_image_quality_output_loss: 1.0744 - val_age_output_loss: 1.1578 - val_weight_output_loss: 0.8734 - val_bag_output_loss: 0.6273 - val_footwear_output_loss: 0.7700 - val_pose_output_loss: 0.2010 - val_emotion_output_loss: 0.8836 - val_gender_output_acc: 0.9582 - val_image_quality_output_acc: 0.6305 - val_age_output_acc: 0.5665 - val_weight_output_acc: 0.7102 - val_bag_output_acc: 0.8170 - val_footwear_output_acc: 0.7490 - val_pose_output_acc: 0.9496 - val_emotion_output_acc: 0.7233\n",
            "Epoch 59/100\n",
            "360/360 [==============================] - 282s 782ms/step - loss: 3.1234 - gender_output_loss: 0.1048 - image_quality_output_loss: 0.4366 - age_output_loss: 0.7373 - weight_output_loss: 0.4603 - bag_output_loss: 0.2688 - footwear_output_loss: 0.3270 - pose_output_loss: 0.1471 - emotion_output_loss: 0.6415 - gender_output_acc: 0.9592 - image_quality_output_acc: 0.8146 - age_output_acc: 0.6904 - weight_output_acc: 0.8211 - bag_output_acc: 0.8920 - footwear_output_acc: 0.8699 - pose_output_acc: 0.9452 - emotion_output_acc: 0.7646 - val_loss: 5.5481 - val_gender_output_loss: 0.1150 - val_image_quality_output_loss: 1.0020 - val_age_output_loss: 1.1478 - val_weight_output_loss: 0.8122 - val_bag_output_loss: 0.5881 - val_footwear_output_loss: 0.8287 - val_pose_output_loss: 0.1787 - val_emotion_output_loss: 0.8756 - val_gender_output_acc: 0.9652 - val_image_quality_output_acc: 0.6300 - val_age_output_acc: 0.5610 - val_weight_output_acc: 0.7157 - val_bag_output_acc: 0.8080 - val_footwear_output_acc: 0.7500 - val_pose_output_acc: 0.9486 - val_emotion_output_acc: 0.7188\n",
            "Epoch 60/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 3.0498 - gender_output_loss: 0.0949 - image_quality_output_loss: 0.4345 - age_output_loss: 0.7256 - weight_output_loss: 0.4449 - bag_output_loss: 0.2623 - footwear_output_loss: 0.3155 - pose_output_loss: 0.1395 - emotion_output_loss: 0.6326 - gender_output_acc: 0.9615 - image_quality_output_acc: 0.8163 - age_output_acc: 0.6950 - weight_output_acc: 0.8222 - bag_output_acc: 0.8957 - footwear_output_acc: 0.8759 - pose_output_acc: 0.9474 - emotion_output_acc: 0.7673Epoch 60/100\n",
            "360/360 [==============================] - 286s 795ms/step - loss: 3.0486 - gender_output_loss: 0.0950 - image_quality_output_loss: 0.4340 - age_output_loss: 0.7253 - weight_output_loss: 0.4449 - bag_output_loss: 0.2619 - footwear_output_loss: 0.3156 - pose_output_loss: 0.1395 - emotion_output_loss: 0.6323 - gender_output_acc: 0.9615 - image_quality_output_acc: 0.8166 - age_output_acc: 0.6951 - weight_output_acc: 0.8224 - bag_output_acc: 0.8957 - footwear_output_acc: 0.8759 - pose_output_acc: 0.9475 - emotion_output_acc: 0.7674 - val_loss: 6.1029 - val_gender_output_loss: 0.1322 - val_image_quality_output_loss: 1.2231 - val_age_output_loss: 1.2419 - val_weight_output_loss: 0.8977 - val_bag_output_loss: 0.6467 - val_footwear_output_loss: 0.8916 - val_pose_output_loss: 0.2018 - val_emotion_output_loss: 0.8679 - val_gender_output_acc: 0.9607 - val_image_quality_output_acc: 0.6028 - val_age_output_acc: 0.5393 - val_weight_output_acc: 0.7082 - val_bag_output_acc: 0.8140 - val_footwear_output_acc: 0.7409 - val_pose_output_acc: 0.9441 - val_emotion_output_acc: 0.6920\n",
            "\n",
            "Epoch 00060: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 61/100\n",
            "360/360 [==============================] - 285s 791ms/step - loss: 3.0183 - gender_output_loss: 0.0966 - image_quality_output_loss: 0.4186 - age_output_loss: 0.7237 - weight_output_loss: 0.4501 - bag_output_loss: 0.2510 - footwear_output_loss: 0.3148 - pose_output_loss: 0.1339 - emotion_output_loss: 0.6295 - gender_output_acc: 0.9620 - image_quality_output_acc: 0.8215 - age_output_acc: 0.6954 - weight_output_acc: 0.8292 - bag_output_acc: 0.9021 - footwear_output_acc: 0.8743 - pose_output_acc: 0.9487 - emotion_output_acc: 0.7667 - val_loss: 5.9007 - val_gender_output_loss: 0.1331 - val_image_quality_output_loss: 1.1910 - val_age_output_loss: 1.2199 - val_weight_output_loss: 0.8292 - val_bag_output_loss: 0.6532 - val_footwear_output_loss: 0.8021 - val_pose_output_loss: 0.1991 - val_emotion_output_loss: 0.8731 - val_gender_output_acc: 0.9622 - val_image_quality_output_acc: 0.6285 - val_age_output_acc: 0.5479 - val_weight_output_acc: 0.7167 - val_bag_output_acc: 0.8049 - val_footwear_output_acc: 0.7480 - val_pose_output_acc: 0.9435 - val_emotion_output_acc: 0.7182\n",
            "Epoch 62/100\n",
            "360/360 [==============================] - 283s 787ms/step - loss: 3.0158 - gender_output_loss: 0.0996 - image_quality_output_loss: 0.4242 - age_output_loss: 0.7305 - weight_output_loss: 0.4387 - bag_output_loss: 0.2568 - footwear_output_loss: 0.3119 - pose_output_loss: 0.1317 - emotion_output_loss: 0.6223 - gender_output_acc: 0.9589 - image_quality_output_acc: 0.8207 - age_output_acc: 0.6921 - weight_output_acc: 0.8298 - bag_output_acc: 0.8983 - footwear_output_acc: 0.8745 - pose_output_acc: 0.9513 - emotion_output_acc: 0.7690 - val_loss: 5.8960 - val_gender_output_loss: 0.1430 - val_image_quality_output_loss: 1.1693 - val_age_output_loss: 1.1873 - val_weight_output_loss: 0.9154 - val_bag_output_loss: 0.6463 - val_footwear_output_loss: 0.7466 - val_pose_output_loss: 0.2262 - val_emotion_output_loss: 0.8620 - val_gender_output_acc: 0.9546 - val_image_quality_output_acc: 0.6149 - val_age_output_acc: 0.5292 - val_weight_output_acc: 0.6996 - val_bag_output_acc: 0.7863 - val_footwear_output_acc: 0.7571 - val_pose_output_acc: 0.9320 - val_emotion_output_acc: 0.7132\n",
            "Epoch 63/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.9905 - gender_output_loss: 0.0976 - image_quality_output_loss: 0.4254 - age_output_loss: 0.7114 - weight_output_loss: 0.4376 - bag_output_loss: 0.2587 - footwear_output_loss: 0.3033 - pose_output_loss: 0.1331 - emotion_output_loss: 0.6235 - gender_output_acc: 0.9616 - image_quality_output_acc: 0.8206 - age_output_acc: 0.7064 - weight_output_acc: 0.8296 - bag_output_acc: 0.9031 - footwear_output_acc: 0.8800 - pose_output_acc: 0.9492 - emotion_output_acc: 0.7702Epoch 63/100\n",
            "360/360 [==============================] - 285s 790ms/step - loss: 2.9927 - gender_output_loss: 0.0976 - image_quality_output_loss: 0.4255 - age_output_loss: 0.7123 - weight_output_loss: 0.4377 - bag_output_loss: 0.2590 - footwear_output_loss: 0.3037 - pose_output_loss: 0.1336 - emotion_output_loss: 0.6234 - gender_output_acc: 0.9616 - image_quality_output_acc: 0.8204 - age_output_acc: 0.7063 - weight_output_acc: 0.8296 - bag_output_acc: 0.9030 - footwear_output_acc: 0.8797 - pose_output_acc: 0.9490 - emotion_output_acc: 0.7703 - val_loss: 5.9602 - val_gender_output_loss: 0.1105 - val_image_quality_output_loss: 1.1223 - val_age_output_loss: 1.2474 - val_weight_output_loss: 0.8784 - val_bag_output_loss: 0.6702 - val_footwear_output_loss: 0.7976 - val_pose_output_loss: 0.2151 - val_emotion_output_loss: 0.9187 - val_gender_output_acc: 0.9713 - val_image_quality_output_acc: 0.6290 - val_age_output_acc: 0.5373 - val_weight_output_acc: 0.7112 - val_bag_output_acc: 0.7999 - val_footwear_output_acc: 0.7475 - val_pose_output_acc: 0.9345 - val_emotion_output_acc: 0.7046\n",
            "Epoch 64/100\n",
            "360/360 [==============================] - 287s 796ms/step - loss: 3.0162 - gender_output_loss: 0.0986 - image_quality_output_loss: 0.4287 - age_output_loss: 0.7153 - weight_output_loss: 0.4396 - bag_output_loss: 0.2501 - footwear_output_loss: 0.3173 - pose_output_loss: 0.1463 - emotion_output_loss: 0.6203 - gender_output_acc: 0.9583 - image_quality_output_acc: 0.8227 - age_output_acc: 0.6999 - weight_output_acc: 0.8313 - bag_output_acc: 0.9036 - footwear_output_acc: 0.8738 - pose_output_acc: 0.9453 - emotion_output_acc: 0.7747 - val_loss: 5.9922 - val_gender_output_loss: 0.1670 - val_image_quality_output_loss: 1.1554 - val_age_output_loss: 1.2295 - val_weight_output_loss: 0.9236 - val_bag_output_loss: 0.6359 - val_footwear_output_loss: 0.7930 - val_pose_output_loss: 0.1941 - val_emotion_output_loss: 0.8937 - val_gender_output_acc: 0.9496 - val_image_quality_output_acc: 0.6013 - val_age_output_acc: 0.5544 - val_weight_output_acc: 0.7142 - val_bag_output_acc: 0.8145 - val_footwear_output_acc: 0.7369 - val_pose_output_acc: 0.9390 - val_emotion_output_acc: 0.7177\n",
            "Epoch 65/100\n",
            "360/360 [==============================] - 283s 787ms/step - loss: 2.9411 - gender_output_loss: 0.0916 - image_quality_output_loss: 0.4080 - age_output_loss: 0.7034 - weight_output_loss: 0.4333 - bag_output_loss: 0.2520 - footwear_output_loss: 0.3061 - pose_output_loss: 0.1345 - emotion_output_loss: 0.6123 - gender_output_acc: 0.9633 - image_quality_output_acc: 0.8250 - age_output_acc: 0.7044 - weight_output_acc: 0.8313 - bag_output_acc: 0.9036 - footwear_output_acc: 0.8789 - pose_output_acc: 0.9497 - emotion_output_acc: 0.7725 - val_loss: 6.3874 - val_gender_output_loss: 0.1679 - val_image_quality_output_loss: 1.2854 - val_age_output_loss: 1.2489 - val_weight_output_loss: 0.8934 - val_bag_output_loss: 0.6876 - val_footwear_output_loss: 0.9173 - val_pose_output_loss: 0.2268 - val_emotion_output_loss: 0.9601 - val_gender_output_acc: 0.9602 - val_image_quality_output_acc: 0.6210 - val_age_output_acc: 0.5615 - val_weight_output_acc: 0.7056 - val_bag_output_acc: 0.7999 - val_footwear_output_acc: 0.7419 - val_pose_output_acc: 0.9345 - val_emotion_output_acc: 0.7041\n",
            "Epoch 66/100\n",
            "360/360 [==============================] - 283s 785ms/step - loss: 2.9618 - gender_output_loss: 0.0973 - image_quality_output_loss: 0.4170 - age_output_loss: 0.7031 - weight_output_loss: 0.4400 - bag_output_loss: 0.2448 - footwear_output_loss: 0.3134 - pose_output_loss: 0.1362 - emotion_output_loss: 0.6100 - gender_output_acc: 0.9609 - image_quality_output_acc: 0.8261 - age_output_acc: 0.7030 - weight_output_acc: 0.8225 - bag_output_acc: 0.9027 - footwear_output_acc: 0.8745 - pose_output_acc: 0.9477 - emotion_output_acc: 0.7706 - val_loss: 6.4018 - val_gender_output_loss: 0.1717 - val_image_quality_output_loss: 1.2474 - val_age_output_loss: 1.2945 - val_weight_output_loss: 0.9084 - val_bag_output_loss: 0.7100 - val_footwear_output_loss: 0.9132 - val_pose_output_loss: 0.2275 - val_emotion_output_loss: 0.9290 - val_gender_output_acc: 0.9612 - val_image_quality_output_acc: 0.6250 - val_age_output_acc: 0.5509 - val_weight_output_acc: 0.7036 - val_bag_output_acc: 0.8170 - val_footwear_output_acc: 0.7404 - val_pose_output_acc: 0.9395 - val_emotion_output_acc: 0.7177\n",
            "Epoch 67/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.9623 - gender_output_loss: 0.1045 - image_quality_output_loss: 0.4196 - age_output_loss: 0.7064 - weight_output_loss: 0.4343 - bag_output_loss: 0.2487 - footwear_output_loss: 0.3103 - pose_output_loss: 0.1336 - emotion_output_loss: 0.6050 - gender_output_acc: 0.9574 - image_quality_output_acc: 0.8214 - age_output_acc: 0.7027 - weight_output_acc: 0.8300 - bag_output_acc: 0.9010 - footwear_output_acc: 0.8743 - pose_output_acc: 0.9500 - emotion_output_acc: 0.7779Epoch 67/100\n",
            "360/360 [==============================] - 283s 786ms/step - loss: 2.9643 - gender_output_loss: 0.1045 - image_quality_output_loss: 0.4202 - age_output_loss: 0.7076 - weight_output_loss: 0.4342 - bag_output_loss: 0.2485 - footwear_output_loss: 0.3103 - pose_output_loss: 0.1335 - emotion_output_loss: 0.6055 - gender_output_acc: 0.9574 - image_quality_output_acc: 0.8214 - age_output_acc: 0.7024 - weight_output_acc: 0.8301 - bag_output_acc: 0.9011 - footwear_output_acc: 0.8743 - pose_output_acc: 0.9502 - emotion_output_acc: 0.7778 - val_loss: 6.2409 - val_gender_output_loss: 0.1360 - val_image_quality_output_loss: 1.1954 - val_age_output_loss: 1.2628 - val_weight_output_loss: 0.8899 - val_bag_output_loss: 0.6500 - val_footwear_output_loss: 0.9357 - val_pose_output_loss: 0.2767 - val_emotion_output_loss: 0.8944 - val_gender_output_acc: 0.9546 - val_image_quality_output_acc: 0.6053 - val_age_output_acc: 0.5227 - val_weight_output_acc: 0.7142 - val_bag_output_acc: 0.8014 - val_footwear_output_acc: 0.7354 - val_pose_output_acc: 0.9194 - val_emotion_output_acc: 0.7056\n",
            "Epoch 68/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.8949 - gender_output_loss: 0.0915 - image_quality_output_loss: 0.4119 - age_output_loss: 0.6953 - weight_output_loss: 0.4383 - bag_output_loss: 0.2371 - footwear_output_loss: 0.2971 - pose_output_loss: 0.1307 - emotion_output_loss: 0.5930 - gender_output_acc: 0.9634 - image_quality_output_acc: 0.8278 - age_output_acc: 0.7153 - weight_output_acc: 0.8294 - bag_output_acc: 0.9081 - footwear_output_acc: 0.8841 - pose_output_acc: 0.9526 - emotion_output_acc: 0.7806Epoch 68/100\n",
            "360/360 [==============================] - 283s 786ms/step - loss: 2.8976 - gender_output_loss: 0.0915 - image_quality_output_loss: 0.4122 - age_output_loss: 0.6959 - weight_output_loss: 0.4383 - bag_output_loss: 0.2369 - footwear_output_loss: 0.2983 - pose_output_loss: 0.1309 - emotion_output_loss: 0.5935 - gender_output_acc: 0.9634 - image_quality_output_acc: 0.8274 - age_output_acc: 0.7149 - weight_output_acc: 0.8294 - bag_output_acc: 0.9082 - footwear_output_acc: 0.8833 - pose_output_acc: 0.9524 - emotion_output_acc: 0.7805 - val_loss: 6.6557 - val_gender_output_loss: 0.1494 - val_image_quality_output_loss: 1.4532 - val_age_output_loss: 1.2780 - val_weight_output_loss: 0.9498 - val_bag_output_loss: 0.6907 - val_footwear_output_loss: 0.9614 - val_pose_output_loss: 0.2520 - val_emotion_output_loss: 0.9211 - val_gender_output_acc: 0.9556 - val_image_quality_output_acc: 0.5706 - val_age_output_acc: 0.5484 - val_weight_output_acc: 0.7067 - val_bag_output_acc: 0.8039 - val_footwear_output_acc: 0.7414 - val_pose_output_acc: 0.9345 - val_emotion_output_acc: 0.6794\n",
            "Epoch 69/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.8640 - gender_output_loss: 0.0978 - image_quality_output_loss: 0.4047 - age_output_loss: 0.6770 - weight_output_loss: 0.4267 - bag_output_loss: 0.2433 - footwear_output_loss: 0.2999 - pose_output_loss: 0.1278 - emotion_output_loss: 0.5866 - gender_output_acc: 0.9605 - image_quality_output_acc: 0.8317 - age_output_acc: 0.7189 - weight_output_acc: 0.8343 - bag_output_acc: 0.9080 - footwear_output_acc: 0.8806 - pose_output_acc: 0.9520 - emotion_output_acc: 0.7809Epoch 69/100\n",
            "360/360 [==============================] - 283s 786ms/step - loss: 2.8647 - gender_output_loss: 0.0977 - image_quality_output_loss: 0.4050 - age_output_loss: 0.6772 - weight_output_loss: 0.4270 - bag_output_loss: 0.2435 - footwear_output_loss: 0.2997 - pose_output_loss: 0.1280 - emotion_output_loss: 0.5868 - gender_output_acc: 0.9605 - image_quality_output_acc: 0.8318 - age_output_acc: 0.7188 - weight_output_acc: 0.8342 - bag_output_acc: 0.9079 - footwear_output_acc: 0.8807 - pose_output_acc: 0.9520 - emotion_output_acc: 0.7807 - val_loss: 6.1608 - val_gender_output_loss: 0.1503 - val_image_quality_output_loss: 1.1609 - val_age_output_loss: 1.2593 - val_weight_output_loss: 0.9249 - val_bag_output_loss: 0.6710 - val_footwear_output_loss: 0.8521 - val_pose_output_loss: 0.2141 - val_emotion_output_loss: 0.9282 - val_gender_output_acc: 0.9556 - val_image_quality_output_acc: 0.6235 - val_age_output_acc: 0.5454 - val_weight_output_acc: 0.7001 - val_bag_output_acc: 0.8049 - val_footwear_output_acc: 0.7555 - val_pose_output_acc: 0.9425 - val_emotion_output_acc: 0.6905\n",
            "Epoch 70/100\n",
            "360/360 [==============================] - 283s 785ms/step - loss: 2.8517 - gender_output_loss: 0.0966 - image_quality_output_loss: 0.3933 - age_output_loss: 0.6875 - weight_output_loss: 0.4209 - bag_output_loss: 0.2381 - footwear_output_loss: 0.2977 - pose_output_loss: 0.1327 - emotion_output_loss: 0.5849 - gender_output_acc: 0.9609 - image_quality_output_acc: 0.8345 - age_output_acc: 0.7144 - weight_output_acc: 0.8339 - bag_output_acc: 0.9076 - footwear_output_acc: 0.8821 - pose_output_acc: 0.9489 - emotion_output_acc: 0.7844 - val_loss: 6.6401 - val_gender_output_loss: 0.1701 - val_image_quality_output_loss: 1.3236 - val_age_output_loss: 1.3075 - val_weight_output_loss: 1.0363 - val_bag_output_loss: 0.7399 - val_footwear_output_loss: 0.8352 - val_pose_output_loss: 0.2353 - val_emotion_output_loss: 0.9922 - val_gender_output_acc: 0.9567 - val_image_quality_output_acc: 0.6074 - val_age_output_acc: 0.5474 - val_weight_output_acc: 0.6865 - val_bag_output_acc: 0.8075 - val_footwear_output_acc: 0.7550 - val_pose_output_acc: 0.9309 - val_emotion_output_acc: 0.7157\n",
            "\n",
            "Epoch 00070: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 71/100\n",
            "360/360 [==============================] - 282s 784ms/step - loss: 2.8697 - gender_output_loss: 0.0944 - image_quality_output_loss: 0.4035 - age_output_loss: 0.6747 - weight_output_loss: 0.4359 - bag_output_loss: 0.2544 - footwear_output_loss: 0.2971 - pose_output_loss: 0.1282 - emotion_output_loss: 0.5814 - gender_output_acc: 0.9605 - image_quality_output_acc: 0.8331 - age_output_acc: 0.7197 - weight_output_acc: 0.8299 - bag_output_acc: 0.8992 - footwear_output_acc: 0.8828 - pose_output_acc: 0.9529 - emotion_output_acc: 0.7855 - val_loss: 6.9629 - val_gender_output_loss: 0.1460 - val_image_quality_output_loss: 1.3139 - val_age_output_loss: 1.2953 - val_weight_output_loss: 1.0009 - val_bag_output_loss: 0.8937 - val_footwear_output_loss: 1.0829 - val_pose_output_loss: 0.2627 - val_emotion_output_loss: 0.9674 - val_gender_output_acc: 0.9592 - val_image_quality_output_acc: 0.6184 - val_age_output_acc: 0.5444 - val_weight_output_acc: 0.6956 - val_bag_output_acc: 0.7828 - val_footwear_output_acc: 0.7122 - val_pose_output_acc: 0.9289 - val_emotion_output_acc: 0.6885\n",
            "Epoch 72/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.7920 - gender_output_loss: 0.0967 - image_quality_output_loss: 0.3946 - age_output_loss: 0.6602 - weight_output_loss: 0.4063 - bag_output_loss: 0.2445 - footwear_output_loss: 0.2896 - pose_output_loss: 0.1212 - emotion_output_loss: 0.5789 - gender_output_acc: 0.9594 - image_quality_output_acc: 0.8345 - age_output_acc: 0.7290 - weight_output_acc: 0.8404 - bag_output_acc: 0.9054 - footwear_output_acc: 0.8841 - pose_output_acc: 0.9538 - emotion_output_acc: 0.7869\n",
            "360/360 [==============================] - 283s 787ms/step - loss: 2.7940 - gender_output_loss: 0.0967 - image_quality_output_loss: 0.3948 - age_output_loss: 0.6611 - weight_output_loss: 0.4066 - bag_output_loss: 0.2450 - footwear_output_loss: 0.2906 - pose_output_loss: 0.1210 - emotion_output_loss: 0.5782 - gender_output_acc: 0.9595 - image_quality_output_acc: 0.8344 - age_output_acc: 0.7286 - weight_output_acc: 0.8403 - bag_output_acc: 0.9052 - footwear_output_acc: 0.8840 - pose_output_acc: 0.9539 - emotion_output_acc: 0.7872 - val_loss: 6.6287 - val_gender_output_loss: 0.1668 - val_image_quality_output_loss: 1.2487 - val_age_output_loss: 1.3565 - val_weight_output_loss: 0.9272 - val_bag_output_loss: 0.6991 - val_footwear_output_loss: 1.0017 - val_pose_output_loss: 0.2416 - val_emotion_output_loss: 0.9871 - val_gender_output_acc: 0.9561 - val_image_quality_output_acc: 0.6064 - val_age_output_acc: 0.5348 - val_weight_output_acc: 0.7016 - val_bag_output_acc: 0.8155 - val_footwear_output_acc: 0.7208 - val_pose_output_acc: 0.9304 - val_emotion_output_acc: 0.6835\n",
            "Epoch 73/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.7683 - gender_output_loss: 0.0952 - image_quality_output_loss: 0.3855 - age_output_loss: 0.6607 - weight_output_loss: 0.4115 - bag_output_loss: 0.2310 - footwear_output_loss: 0.2830 - pose_output_loss: 0.1297 - emotion_output_loss: 0.5718 - gender_output_acc: 0.9632 - image_quality_output_acc: 0.8344 - age_output_acc: 0.7259 - weight_output_acc: 0.8422 - bag_output_acc: 0.9099 - footwear_output_acc: 0.8879 - pose_output_acc: 0.9506 - emotion_output_acc: 0.7899\n",
            "360/360 [==============================] - 284s 789ms/step - loss: 2.7701 - gender_output_loss: 0.0952 - image_quality_output_loss: 0.3855 - age_output_loss: 0.6608 - weight_output_loss: 0.4118 - bag_output_loss: 0.2312 - footwear_output_loss: 0.2833 - pose_output_loss: 0.1299 - emotion_output_loss: 0.5725 - gender_output_acc: 0.9631 - image_quality_output_acc: 0.8345 - age_output_acc: 0.7257 - weight_output_acc: 0.8420 - bag_output_acc: 0.9097 - footwear_output_acc: 0.8877 - pose_output_acc: 0.9503 - emotion_output_acc: 0.7896 - val_loss: 6.3615 - val_gender_output_loss: 0.1455 - val_image_quality_output_loss: 1.2618 - val_age_output_loss: 1.3104 - val_weight_output_loss: 0.8838 - val_bag_output_loss: 0.6899 - val_footwear_output_loss: 0.9130 - val_pose_output_loss: 0.2285 - val_emotion_output_loss: 0.9286 - val_gender_output_acc: 0.9597 - val_image_quality_output_acc: 0.6265 - val_age_output_acc: 0.5323 - val_weight_output_acc: 0.7097 - val_bag_output_acc: 0.7913 - val_footwear_output_acc: 0.7409 - val_pose_output_acc: 0.9360 - val_emotion_output_acc: 0.7117\n",
            "Epoch 74/100\n",
            "360/360 [==============================] - 283s 787ms/step - loss: 2.7818 - gender_output_loss: 0.0949 - image_quality_output_loss: 0.3757 - age_output_loss: 0.6648 - weight_output_loss: 0.4115 - bag_output_loss: 0.2410 - footwear_output_loss: 0.2897 - pose_output_loss: 0.1334 - emotion_output_loss: 0.5707 - gender_output_acc: 0.9601 - image_quality_output_acc: 0.8390 - age_output_acc: 0.7257 - weight_output_acc: 0.8389 - bag_output_acc: 0.9075 - footwear_output_acc: 0.8842 - pose_output_acc: 0.9516 - emotion_output_acc: 0.7891 - val_loss: 6.5693 - val_gender_output_loss: 0.1480 - val_image_quality_output_loss: 1.3530 - val_age_output_loss: 1.3392 - val_weight_output_loss: 0.9045 - val_bag_output_loss: 0.7545 - val_footwear_output_loss: 0.8896 - val_pose_output_loss: 0.2392 - val_emotion_output_loss: 0.9413 - val_gender_output_acc: 0.9622 - val_image_quality_output_acc: 0.6169 - val_age_output_acc: 0.5408 - val_weight_output_acc: 0.7157 - val_bag_output_acc: 0.7994 - val_footwear_output_acc: 0.7434 - val_pose_output_acc: 0.9385 - val_emotion_output_acc: 0.7041\n",
            "Epoch 75/100\n",
            "360/360 [==============================] - 285s 792ms/step - loss: 2.7461 - gender_output_loss: 0.0896 - image_quality_output_loss: 0.3791 - age_output_loss: 0.6540 - weight_output_loss: 0.4178 - bag_output_loss: 0.2306 - footwear_output_loss: 0.2793 - pose_output_loss: 0.1335 - emotion_output_loss: 0.5621 - gender_output_acc: 0.9648 - image_quality_output_acc: 0.8395 - age_output_acc: 0.7307 - weight_output_acc: 0.8375 - bag_output_acc: 0.9102 - footwear_output_acc: 0.8897 - pose_output_acc: 0.9497 - emotion_output_acc: 0.7893 - val_loss: 6.9094 - val_gender_output_loss: 0.1418 - val_image_quality_output_loss: 1.4773 - val_age_output_loss: 1.3298 - val_weight_output_loss: 0.9743 - val_bag_output_loss: 0.7382 - val_footwear_output_loss: 1.0056 - val_pose_output_loss: 0.2537 - val_emotion_output_loss: 0.9888 - val_gender_output_acc: 0.9622 - val_image_quality_output_acc: 0.5988 - val_age_output_acc: 0.5403 - val_weight_output_acc: 0.6905 - val_bag_output_acc: 0.7954 - val_footwear_output_acc: 0.7263 - val_pose_output_acc: 0.9340 - val_emotion_output_acc: 0.7167\n",
            "Epoch 76/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.8117 - gender_output_loss: 0.0929 - image_quality_output_loss: 0.4068 - age_output_loss: 0.6738 - weight_output_loss: 0.4161 - bag_output_loss: 0.2420 - footwear_output_loss: 0.2852 - pose_output_loss: 0.1312 - emotion_output_loss: 0.5637 - gender_output_acc: 0.9614 - image_quality_output_acc: 0.8277 - age_output_acc: 0.7196 - weight_output_acc: 0.8377 - bag_output_acc: 0.9065 - footwear_output_acc: 0.8868 - pose_output_acc: 0.9506 - emotion_output_acc: 0.7934Epoch 76/100\n",
            "360/360 [==============================] - 285s 793ms/step - loss: 2.8150 - gender_output_loss: 0.0929 - image_quality_output_loss: 0.4076 - age_output_loss: 0.6756 - weight_output_loss: 0.4163 - bag_output_loss: 0.2420 - footwear_output_loss: 0.2860 - pose_output_loss: 0.1313 - emotion_output_loss: 0.5633 - gender_output_acc: 0.9613 - image_quality_output_acc: 0.8274 - age_output_acc: 0.7190 - weight_output_acc: 0.8375 - bag_output_acc: 0.9066 - footwear_output_acc: 0.8864 - pose_output_acc: 0.9504 - emotion_output_acc: 0.7937 - val_loss: 6.9070 - val_gender_output_loss: 0.1688 - val_image_quality_output_loss: 1.3392 - val_age_output_loss: 1.3417 - val_weight_output_loss: 1.1274 - val_bag_output_loss: 0.7270 - val_footwear_output_loss: 1.0126 - val_pose_output_loss: 0.2426 - val_emotion_output_loss: 0.9477 - val_gender_output_acc: 0.9567 - val_image_quality_output_acc: 0.6013 - val_age_output_acc: 0.5444 - val_weight_output_acc: 0.6658 - val_bag_output_acc: 0.7984 - val_footwear_output_acc: 0.7248 - val_pose_output_acc: 0.9330 - val_emotion_output_acc: 0.6890\n",
            "Epoch 77/100\n",
            "360/360 [==============================] - 285s 791ms/step - loss: 2.7567 - gender_output_loss: 0.0908 - image_quality_output_loss: 0.3895 - age_output_loss: 0.6598 - weight_output_loss: 0.4099 - bag_output_loss: 0.2298 - footwear_output_loss: 0.2792 - pose_output_loss: 0.1344 - emotion_output_loss: 0.5633 - gender_output_acc: 0.9609 - image_quality_output_acc: 0.8369 - age_output_acc: 0.7248 - weight_output_acc: 0.8370 - bag_output_acc: 0.9108 - footwear_output_acc: 0.8874 - pose_output_acc: 0.9490 - emotion_output_acc: 0.7880 - val_loss: 6.6261 - val_gender_output_loss: 0.1584 - val_image_quality_output_loss: 1.2445 - val_age_output_loss: 1.3726 - val_weight_output_loss: 0.9504 - val_bag_output_loss: 0.7274 - val_footwear_output_loss: 0.9409 - val_pose_output_loss: 0.2455 - val_emotion_output_loss: 0.9865 - val_gender_output_acc: 0.9617 - val_image_quality_output_acc: 0.6043 - val_age_output_acc: 0.5449 - val_weight_output_acc: 0.7056 - val_bag_output_acc: 0.8054 - val_footwear_output_acc: 0.7278 - val_pose_output_acc: 0.9350 - val_emotion_output_acc: 0.6996\n",
            "Epoch 78/100\n",
            "360/360 [==============================] - 284s 789ms/step - loss: 2.6972 - gender_output_loss: 0.0900 - image_quality_output_loss: 0.3819 - age_output_loss: 0.6474 - weight_output_loss: 0.4003 - bag_output_loss: 0.2277 - footwear_output_loss: 0.2823 - pose_output_loss: 0.1240 - emotion_output_loss: 0.5436 - gender_output_acc: 0.9613 - image_quality_output_acc: 0.8374 - age_output_acc: 0.7344 - weight_output_acc: 0.8429 - bag_output_acc: 0.9096 - footwear_output_acc: 0.8901 - pose_output_acc: 0.9518 - emotion_output_acc: 0.7995 - val_loss: 7.4338 - val_gender_output_loss: 0.1444 - val_image_quality_output_loss: 1.4736 - val_age_output_loss: 1.4341 - val_weight_output_loss: 1.2159 - val_bag_output_loss: 0.7732 - val_footwear_output_loss: 1.0823 - val_pose_output_loss: 0.2722 - val_emotion_output_loss: 1.0381 - val_gender_output_acc: 0.9592 - val_image_quality_output_acc: 0.6099 - val_age_output_acc: 0.5212 - val_weight_output_acc: 0.6689 - val_bag_output_acc: 0.8065 - val_footwear_output_acc: 0.7334 - val_pose_output_acc: 0.9264 - val_emotion_output_acc: 0.6996\n",
            "Epoch 79/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.6882 - gender_output_loss: 0.0923 - image_quality_output_loss: 0.3751 - age_output_loss: 0.6396 - weight_output_loss: 0.3999 - bag_output_loss: 0.2254 - footwear_output_loss: 0.2698 - pose_output_loss: 0.1329 - emotion_output_loss: 0.5531 - gender_output_acc: 0.9620 - image_quality_output_acc: 0.8412 - age_output_acc: 0.7348 - weight_output_acc: 0.8444 - bag_output_acc: 0.9112 - footwear_output_acc: 0.8938 - pose_output_acc: 0.9496 - emotion_output_acc: 0.7904Epoch 79/100\n",
            "360/360 [==============================] - 284s 790ms/step - loss: 2.6871 - gender_output_loss: 0.0921 - image_quality_output_loss: 0.3746 - age_output_loss: 0.6393 - weight_output_loss: 0.4004 - bag_output_loss: 0.2253 - footwear_output_loss: 0.2701 - pose_output_loss: 0.1326 - emotion_output_loss: 0.5528 - gender_output_acc: 0.9621 - image_quality_output_acc: 0.8415 - age_output_acc: 0.7346 - weight_output_acc: 0.8442 - bag_output_acc: 0.9112 - footwear_output_acc: 0.8938 - pose_output_acc: 0.9497 - emotion_output_acc: 0.7906 - val_loss: 7.2707 - val_gender_output_loss: 0.1561 - val_image_quality_output_loss: 1.4429 - val_age_output_loss: 1.4838 - val_weight_output_loss: 1.0973 - val_bag_output_loss: 0.8235 - val_footwear_output_loss: 1.0154 - val_pose_output_loss: 0.2593 - val_emotion_output_loss: 0.9923 - val_gender_output_acc: 0.9536 - val_image_quality_output_acc: 0.6033 - val_age_output_acc: 0.5343 - val_weight_output_acc: 0.6961 - val_bag_output_acc: 0.7833 - val_footwear_output_acc: 0.7344 - val_pose_output_acc: 0.9365 - val_emotion_output_acc: 0.6875\n",
            "Epoch 80/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.6328 - gender_output_loss: 0.0912 - image_quality_output_loss: 0.3643 - age_output_loss: 0.6281 - weight_output_loss: 0.3905 - bag_output_loss: 0.2240 - footwear_output_loss: 0.2701 - pose_output_loss: 0.1202 - emotion_output_loss: 0.5445 - gender_output_acc: 0.9635 - image_quality_output_acc: 0.8461 - age_output_acc: 0.7472 - weight_output_acc: 0.8478 - bag_output_acc: 0.9126 - footwear_output_acc: 0.8928 - pose_output_acc: 0.9547 - emotion_output_acc: 0.8001\n",
            "360/360 [==============================] - 283s 786ms/step - loss: 2.6349 - gender_output_loss: 0.0912 - image_quality_output_loss: 0.3642 - age_output_loss: 0.6286 - weight_output_loss: 0.3908 - bag_output_loss: 0.2243 - footwear_output_loss: 0.2705 - pose_output_loss: 0.1203 - emotion_output_loss: 0.5451 - gender_output_acc: 0.9635 - image_quality_output_acc: 0.8462 - age_output_acc: 0.7467 - weight_output_acc: 0.8477 - bag_output_acc: 0.9125 - footwear_output_acc: 0.8927 - pose_output_acc: 0.9547 - emotion_output_acc: 0.7999 - val_loss: 7.2598 - val_gender_output_loss: 0.1320 - val_image_quality_output_loss: 1.5736 - val_age_output_loss: 1.4273 - val_weight_output_loss: 1.1353 - val_bag_output_loss: 0.7524 - val_footwear_output_loss: 1.0270 - val_pose_output_loss: 0.2357 - val_emotion_output_loss: 0.9764 - val_gender_output_acc: 0.9617 - val_image_quality_output_acc: 0.5544 - val_age_output_acc: 0.5413 - val_weight_output_acc: 0.6739 - val_bag_output_acc: 0.8080 - val_footwear_output_acc: 0.7182 - val_pose_output_acc: 0.9380 - val_emotion_output_acc: 0.6578\n",
            "\n",
            "Epoch 00080: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 81/100\n",
            "360/360 [==============================] - 283s 786ms/step - loss: 2.6163 - gender_output_loss: 0.0924 - image_quality_output_loss: 0.3691 - age_output_loss: 0.6237 - weight_output_loss: 0.3836 - bag_output_loss: 0.2187 - footwear_output_loss: 0.2685 - pose_output_loss: 0.1231 - emotion_output_loss: 0.5373 - gender_output_acc: 0.9630 - image_quality_output_acc: 0.8458 - age_output_acc: 0.7419 - weight_output_acc: 0.8520 - bag_output_acc: 0.9118 - footwear_output_acc: 0.8951 - pose_output_acc: 0.9543 - emotion_output_acc: 0.8002 - val_loss: 7.2817 - val_gender_output_loss: 0.2041 - val_image_quality_output_loss: 1.3741 - val_age_output_loss: 1.4654 - val_weight_output_loss: 1.0752 - val_bag_output_loss: 0.8028 - val_footwear_output_loss: 1.0875 - val_pose_output_loss: 0.2533 - val_emotion_output_loss: 1.0193 - val_gender_output_acc: 0.9471 - val_image_quality_output_acc: 0.6043 - val_age_output_acc: 0.5242 - val_weight_output_acc: 0.6860 - val_bag_output_acc: 0.7923 - val_footwear_output_acc: 0.7213 - val_pose_output_acc: 0.9365 - val_emotion_output_acc: 0.6935\n",
            "Epoch 82/100\n",
            "360/360 [==============================] - 284s 789ms/step - loss: 2.6268 - gender_output_loss: 0.0920 - image_quality_output_loss: 0.3620 - age_output_loss: 0.6352 - weight_output_loss: 0.3897 - bag_output_loss: 0.2255 - footwear_output_loss: 0.2654 - pose_output_loss: 0.1171 - emotion_output_loss: 0.5400 - gender_output_acc: 0.9625 - image_quality_output_acc: 0.8527 - age_output_acc: 0.7391 - weight_output_acc: 0.8477 - bag_output_acc: 0.9140 - footwear_output_acc: 0.8949 - pose_output_acc: 0.9559 - emotion_output_acc: 0.7993 - val_loss: 6.9236 - val_gender_output_loss: 0.1766 - val_image_quality_output_loss: 1.3482 - val_age_output_loss: 1.4165 - val_weight_output_loss: 1.0127 - val_bag_output_loss: 0.7574 - val_footwear_output_loss: 0.9654 - val_pose_output_loss: 0.2497 - val_emotion_output_loss: 0.9971 - val_gender_output_acc: 0.9556 - val_image_quality_output_acc: 0.5993 - val_age_output_acc: 0.5282 - val_weight_output_acc: 0.6895 - val_bag_output_acc: 0.7828 - val_footwear_output_acc: 0.7208 - val_pose_output_acc: 0.9294 - val_emotion_output_acc: 0.7021\n",
            "Epoch 83/100\n",
            "Epoch 82/100\n",
            "360/360 [==============================] - 285s 791ms/step - loss: 2.6034 - gender_output_loss: 0.0929 - image_quality_output_loss: 0.3561 - age_output_loss: 0.6302 - weight_output_loss: 0.3867 - bag_output_loss: 0.2216 - footwear_output_loss: 0.2685 - pose_output_loss: 0.1224 - emotion_output_loss: 0.5251 - gender_output_acc: 0.9617 - image_quality_output_acc: 0.8493 - age_output_acc: 0.7405 - weight_output_acc: 0.8494 - bag_output_acc: 0.9154 - footwear_output_acc: 0.8930 - pose_output_acc: 0.9536 - emotion_output_acc: 0.8049 - val_loss: 7.3732 - val_gender_output_loss: 0.1647 - val_image_quality_output_loss: 1.4851 - val_age_output_loss: 1.4010 - val_weight_output_loss: 1.0221 - val_bag_output_loss: 0.8740 - val_footwear_output_loss: 1.1434 - val_pose_output_loss: 0.2755 - val_emotion_output_loss: 1.0074 - val_gender_output_acc: 0.9607 - val_image_quality_output_acc: 0.5953 - val_age_output_acc: 0.5383 - val_weight_output_acc: 0.6981 - val_bag_output_acc: 0.8029 - val_footwear_output_acc: 0.7117 - val_pose_output_acc: 0.9330 - val_emotion_output_acc: 0.6562\n",
            "Epoch 84/100\n",
            "360/360 [==============================] - 286s 795ms/step - loss: 2.5952 - gender_output_loss: 0.0848 - image_quality_output_loss: 0.3568 - age_output_loss: 0.6320 - weight_output_loss: 0.3897 - bag_output_loss: 0.2237 - footwear_output_loss: 0.2688 - pose_output_loss: 0.1223 - emotion_output_loss: 0.5171 - gender_output_acc: 0.9650 - image_quality_output_acc: 0.8514 - age_output_acc: 0.7377 - weight_output_acc: 0.8471 - bag_output_acc: 0.9134 - footwear_output_acc: 0.8923 - pose_output_acc: 0.9537 - emotion_output_acc: 0.8094 - val_loss: 7.3393 - val_gender_output_loss: 0.1851 - val_image_quality_output_loss: 1.6108 - val_age_output_loss: 1.4359 - val_weight_output_loss: 1.0234 - val_bag_output_loss: 0.7643 - val_footwear_output_loss: 1.0366 - val_pose_output_loss: 0.2513 - val_emotion_output_loss: 1.0320 - val_gender_output_acc: 0.9577 - val_image_quality_output_acc: 0.5736 - val_age_output_acc: 0.5207 - val_weight_output_acc: 0.6935 - val_bag_output_acc: 0.7797 - val_footwear_output_acc: 0.7450 - val_pose_output_acc: 0.9355 - val_emotion_output_acc: 0.6850\n",
            "Epoch 85/100\n",
            "360/360 [==============================] - 288s 801ms/step - loss: 2.5798 - gender_output_loss: 0.0857 - image_quality_output_loss: 0.3637 - age_output_loss: 0.6167 - weight_output_loss: 0.3836 - bag_output_loss: 0.2244 - footwear_output_loss: 0.2627 - pose_output_loss: 0.1251 - emotion_output_loss: 0.5179 - gender_output_acc: 0.9635 - image_quality_output_acc: 0.8520 - age_output_acc: 0.7486 - weight_output_acc: 0.8524 - bag_output_acc: 0.9121 - footwear_output_acc: 0.8936 - pose_output_acc: 0.9518 - emotion_output_acc: 0.8084 - val_loss: 7.1112 - val_gender_output_loss: 0.1490 - val_image_quality_output_loss: 1.3295 - val_age_output_loss: 1.4375 - val_weight_output_loss: 1.0844 - val_bag_output_loss: 0.7620 - val_footwear_output_loss: 1.0720 - val_pose_output_loss: 0.2461 - val_emotion_output_loss: 1.0307 - val_gender_output_acc: 0.9607 - val_image_quality_output_acc: 0.6124 - val_age_output_acc: 0.5106 - val_weight_output_acc: 0.6850 - val_bag_output_acc: 0.8029 - val_footwear_output_acc: 0.7354 - val_pose_output_acc: 0.9320 - val_emotion_output_acc: 0.6719\n",
            "Epoch 86/100\n",
            "360/360 [==============================] - 288s 800ms/step - loss: 2.5733 - gender_output_loss: 0.0902 - image_quality_output_loss: 0.3573 - age_output_loss: 0.6212 - weight_output_loss: 0.3855 - bag_output_loss: 0.2114 - footwear_output_loss: 0.2713 - pose_output_loss: 0.1228 - emotion_output_loss: 0.5137 - gender_output_acc: 0.9637 - image_quality_output_acc: 0.8514 - age_output_acc: 0.7429 - weight_output_acc: 0.8493 - bag_output_acc: 0.9175 - footwear_output_acc: 0.8891 - pose_output_acc: 0.9543 - emotion_output_acc: 0.8142 - val_loss: 7.0765 - val_gender_output_loss: 0.1610 - val_image_quality_output_loss: 1.2680 - val_age_output_loss: 1.4579 - val_weight_output_loss: 1.0299 - val_bag_output_loss: 0.7826 - val_footwear_output_loss: 1.0652 - val_pose_output_loss: 0.2730 - val_emotion_output_loss: 1.0391 - val_gender_output_acc: 0.9516 - val_image_quality_output_acc: 0.6079 - val_age_output_acc: 0.5222 - val_weight_output_acc: 0.6850 - val_bag_output_acc: 0.7903 - val_footwear_output_acc: 0.7223 - val_pose_output_acc: 0.9254 - val_emotion_output_acc: 0.6996\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "360/360 [==============================] - 289s 802ms/step - loss: 2.5198 - gender_output_loss: 0.0869 - image_quality_output_loss: 0.3657 - age_output_loss: 0.6028 - weight_output_loss: 0.3737 - bag_output_loss: 0.2220 - footwear_output_loss: 0.2527 - pose_output_loss: 0.1165 - emotion_output_loss: 0.4995 - gender_output_acc: 0.9642 - image_quality_output_acc: 0.8494 - age_output_acc: 0.7472 - weight_output_acc: 0.8576 - bag_output_acc: 0.9134 - footwear_output_acc: 0.9000 - pose_output_acc: 0.9567 - emotion_output_acc: 0.8161 - val_loss: 7.0996 - val_gender_output_loss: 0.1495 - val_image_quality_output_loss: 1.2924 - val_age_output_loss: 1.4799 - val_weight_output_loss: 1.0910 - val_bag_output_loss: 0.7472 - val_footwear_output_loss: 1.0169 - val_pose_output_loss: 0.2693 - val_emotion_output_loss: 1.0534 - val_gender_output_acc: 0.9592 - val_image_quality_output_acc: 0.5953 - val_age_output_acc: 0.5146 - val_weight_output_acc: 0.6925 - val_bag_output_acc: 0.8100 - val_footwear_output_acc: 0.7193 - val_pose_output_acc: 0.9340 - val_emotion_output_acc: 0.6789\n",
            "Epoch 88/100\n",
            "360/360 [==============================] - 289s 803ms/step - loss: 2.5014 - gender_output_loss: 0.0867 - image_quality_output_loss: 0.3490 - age_output_loss: 0.5981 - weight_output_loss: 0.3805 - bag_output_loss: 0.2120 - footwear_output_loss: 0.2579 - pose_output_loss: 0.1227 - emotion_output_loss: 0.4945 - gender_output_acc: 0.9649 - image_quality_output_acc: 0.8539 - age_output_acc: 0.7569 - weight_output_acc: 0.8501 - bag_output_acc: 0.9181 - footwear_output_acc: 0.8993 - pose_output_acc: 0.9546 - emotion_output_acc: 0.8200 - val_loss: 6.9269 - val_gender_output_loss: 0.1900 - val_image_quality_output_loss: 1.2929 - val_age_output_loss: 1.4115 - val_weight_output_loss: 1.0971 - val_bag_output_loss: 0.7677 - val_footwear_output_loss: 0.9210 - val_pose_output_loss: 0.2280 - val_emotion_output_loss: 1.0189 - val_gender_output_acc: 0.9350 - val_image_quality_output_acc: 0.5963 - val_age_output_acc: 0.5267 - val_weight_output_acc: 0.6875 - val_bag_output_acc: 0.7818 - val_footwear_output_acc: 0.7434 - val_pose_output_acc: 0.9345 - val_emotion_output_acc: 0.6885\n",
            "Epoch 89/100\n",
            "360/360 [==============================] - 292s 811ms/step - loss: 2.5036 - gender_output_loss: 0.0896 - image_quality_output_loss: 0.3498 - age_output_loss: 0.6151 - weight_output_loss: 0.3728 - bag_output_loss: 0.2088 - footwear_output_loss: 0.2484 - pose_output_loss: 0.1191 - emotion_output_loss: 0.5001 - gender_output_acc: 0.9623 - image_quality_output_acc: 0.8552 - age_output_acc: 0.7510 - weight_output_acc: 0.8565 - bag_output_acc: 0.9185 - footwear_output_acc: 0.9021 - pose_output_acc: 0.9558 - emotion_output_acc: 0.8151 - val_loss: 7.5163 - val_gender_output_loss: 0.1521 - val_image_quality_output_loss: 1.5631 - val_age_output_loss: 1.4771 - val_weight_output_loss: 1.0257 - val_bag_output_loss: 0.7932 - val_footwear_output_loss: 1.1394 - val_pose_output_loss: 0.2536 - val_emotion_output_loss: 1.1121 - val_gender_output_acc: 0.9602 - val_image_quality_output_acc: 0.5902 - val_age_output_acc: 0.5066 - val_weight_output_acc: 0.6830 - val_bag_output_acc: 0.7888 - val_footwear_output_acc: 0.7238 - val_pose_output_acc: 0.9274 - val_emotion_output_acc: 0.6905\n",
            "Epoch 90/100\n",
            "360/360 [==============================] - 291s 809ms/step - loss: 2.4839 - gender_output_loss: 0.0812 - image_quality_output_loss: 0.3518 - age_output_loss: 0.6021 - weight_output_loss: 0.3671 - bag_output_loss: 0.2060 - footwear_output_loss: 0.2547 - pose_output_loss: 0.1214 - emotion_output_loss: 0.4996 - gender_output_acc: 0.9672 - image_quality_output_acc: 0.8557 - age_output_acc: 0.7535 - weight_output_acc: 0.8572 - bag_output_acc: 0.9195 - footwear_output_acc: 0.9001 - pose_output_acc: 0.9543 - emotion_output_acc: 0.8179 - val_loss: 7.4257 - val_gender_output_loss: 0.1632 - val_image_quality_output_loss: 1.5946 - val_age_output_loss: 1.4652 - val_weight_output_loss: 1.0093 - val_bag_output_loss: 0.8346 - val_footwear_output_loss: 1.0546 - val_pose_output_loss: 0.2824 - val_emotion_output_loss: 1.0217 - val_gender_output_acc: 0.9536 - val_image_quality_output_acc: 0.5837 - val_age_output_acc: 0.5131 - val_weight_output_acc: 0.7026 - val_bag_output_acc: 0.7878 - val_footwear_output_acc: 0.7253 - val_pose_output_acc: 0.9309 - val_emotion_output_acc: 0.6941\n",
            "\n",
            "Epoch 00090: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "Epoch 91/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.4281 - gender_output_loss: 0.0866 - image_quality_output_loss: 0.3450 - age_output_loss: 0.5791 - weight_output_loss: 0.3611 - bag_output_loss: 0.2090 - footwear_output_loss: 0.2487 - pose_output_loss: 0.1180 - emotion_output_loss: 0.4806 - gender_output_acc: 0.9648 - image_quality_output_acc: 0.8584 - age_output_acc: 0.7591 - weight_output_acc: 0.8575 - bag_output_acc: 0.9212 - footwear_output_acc: 0.9049 - pose_output_acc: 0.9540 - emotion_output_acc: 0.8253\n",
            "Epoch 00090: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n",
            "360/360 [==============================] - 291s 808ms/step - loss: 2.4297 - gender_output_loss: 0.0870 - image_quality_output_loss: 0.3452 - age_output_loss: 0.5792 - weight_output_loss: 0.3612 - bag_output_loss: 0.2087 - footwear_output_loss: 0.2492 - pose_output_loss: 0.1180 - emotion_output_loss: 0.4811 - gender_output_acc: 0.9648 - image_quality_output_acc: 0.8583 - age_output_acc: 0.7590 - weight_output_acc: 0.8574 - bag_output_acc: 0.9214 - footwear_output_acc: 0.9047 - pose_output_acc: 0.9540 - emotion_output_acc: 0.8253 - val_loss: 7.5498 - val_gender_output_loss: 0.1637 - val_image_quality_output_loss: 1.4594 - val_age_output_loss: 1.5771 - val_weight_output_loss: 1.0672 - val_bag_output_loss: 0.8450 - val_footwear_output_loss: 1.0862 - val_pose_output_loss: 0.2708 - val_emotion_output_loss: 1.0804 - val_gender_output_acc: 0.9516 - val_image_quality_output_acc: 0.5927 - val_age_output_acc: 0.4940 - val_weight_output_acc: 0.6915 - val_bag_output_acc: 0.7928 - val_footwear_output_acc: 0.6976 - val_pose_output_acc: 0.9219 - val_emotion_output_acc: 0.6769\n",
            "Epoch 92/100\n",
            "360/360 [==============================] - 294s 816ms/step - loss: 2.4641 - gender_output_loss: 0.0859 - image_quality_output_loss: 0.3457 - age_output_loss: 0.5989 - weight_output_loss: 0.3691 - bag_output_loss: 0.2076 - footwear_output_loss: 0.2542 - pose_output_loss: 0.1255 - emotion_output_loss: 0.4772 - gender_output_acc: 0.9655 - image_quality_output_acc: 0.8538 - age_output_acc: 0.7563 - weight_output_acc: 0.8538 - bag_output_acc: 0.9193 - footwear_output_acc: 0.9001 - pose_output_acc: 0.9539 - emotion_output_acc: 0.8226 - val_loss: 7.5819 - val_gender_output_loss: 0.1617 - val_image_quality_output_loss: 1.4364 - val_age_output_loss: 1.6712 - val_weight_output_loss: 1.0883 - val_bag_output_loss: 0.7651 - val_footwear_output_loss: 1.1352 - val_pose_output_loss: 0.2393 - val_emotion_output_loss: 1.0846 - val_gender_output_acc: 0.9546 - val_image_quality_output_acc: 0.5902 - val_age_output_acc: 0.5126 - val_weight_output_acc: 0.6920 - val_bag_output_acc: 0.7964 - val_footwear_output_acc: 0.7082 - val_pose_output_acc: 0.9335 - val_emotion_output_acc: 0.6815\n",
            "Epoch 93/100\n",
            "360/360 [==============================] - 294s 817ms/step - loss: 2.4371 - gender_output_loss: 0.0887 - image_quality_output_loss: 0.3381 - age_output_loss: 0.5897 - weight_output_loss: 0.3689 - bag_output_loss: 0.2018 - footwear_output_loss: 0.2488 - pose_output_loss: 0.1221 - emotion_output_loss: 0.4790 - gender_output_acc: 0.9649 - image_quality_output_acc: 0.8628 - age_output_acc: 0.7604 - weight_output_acc: 0.8578 - bag_output_acc: 0.9216 - footwear_output_acc: 0.9033 - pose_output_acc: 0.9536 - emotion_output_acc: 0.8244 - val_loss: 7.2604 - val_gender_output_loss: 0.1610 - val_image_quality_output_loss: 1.3767 - val_age_output_loss: 1.5067 - val_weight_output_loss: 1.0680 - val_bag_output_loss: 0.7836 - val_footwear_output_loss: 1.0482 - val_pose_output_loss: 0.2449 - val_emotion_output_loss: 1.0714 - val_gender_output_acc: 0.9556 - val_image_quality_output_acc: 0.6008 - val_age_output_acc: 0.5091 - val_weight_output_acc: 0.6870 - val_bag_output_acc: 0.7984 - val_footwear_output_acc: 0.7137 - val_pose_output_acc: 0.9304 - val_emotion_output_acc: 0.6769\n",
            "Epoch 94/100\n",
            "360/360 [==============================] - 295s 819ms/step - loss: 2.4382 - gender_output_loss: 0.0889 - image_quality_output_loss: 0.3497 - age_output_loss: 0.5802 - weight_output_loss: 0.3587 - bag_output_loss: 0.2129 - footwear_output_loss: 0.2500 - pose_output_loss: 0.1243 - emotion_output_loss: 0.4735 - gender_output_acc: 0.9646 - image_quality_output_acc: 0.8523 - age_output_acc: 0.7641 - weight_output_acc: 0.8607 - bag_output_acc: 0.9194 - footwear_output_acc: 0.8986 - pose_output_acc: 0.9516 - emotion_output_acc: 0.8252 - val_loss: 7.3477 - val_gender_output_loss: 0.1684 - val_image_quality_output_loss: 1.4656 - val_age_output_loss: 1.4652 - val_weight_output_loss: 1.0334 - val_bag_output_loss: 0.7786 - val_footwear_output_loss: 1.0346 - val_pose_output_loss: 0.2500 - val_emotion_output_loss: 1.1519 - val_gender_output_acc: 0.9451 - val_image_quality_output_acc: 0.5827 - val_age_output_acc: 0.5106 - val_weight_output_acc: 0.6981 - val_bag_output_acc: 0.7933 - val_footwear_output_acc: 0.7218 - val_pose_output_acc: 0.9380 - val_emotion_output_acc: 0.7243\n",
            "Epoch 95/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.3957 - gender_output_loss: 0.0853 - image_quality_output_loss: 0.3300 - age_output_loss: 0.5827 - weight_output_loss: 0.3566 - bag_output_loss: 0.2089 - footwear_output_loss: 0.2455 - pose_output_loss: 0.1222 - emotion_output_loss: 0.4645 - gender_output_acc: 0.9647 - image_quality_output_acc: 0.8608 - age_output_acc: 0.7635 - weight_output_acc: 0.8582 - bag_output_acc: 0.9186 - footwear_output_acc: 0.9053 - pose_output_acc: 0.9533 - emotion_output_acc: 0.8263Epoch 95/100\n",
            "360/360 [==============================] - 296s 822ms/step - loss: 2.3977 - gender_output_loss: 0.0855 - image_quality_output_loss: 0.3302 - age_output_loss: 0.5832 - weight_output_loss: 0.3566 - bag_output_loss: 0.2095 - footwear_output_loss: 0.2454 - pose_output_loss: 0.1224 - emotion_output_loss: 0.4649 - gender_output_acc: 0.9646 - image_quality_output_acc: 0.8607 - age_output_acc: 0.7634 - weight_output_acc: 0.8582 - bag_output_acc: 0.9185 - footwear_output_acc: 0.9055 - pose_output_acc: 0.9531 - emotion_output_acc: 0.8261 - val_loss: 7.6597 - val_gender_output_loss: 0.2179 - val_image_quality_output_loss: 1.5142 - val_age_output_loss: 1.6521 - val_weight_output_loss: 1.0952 - val_bag_output_loss: 0.7488 - val_footwear_output_loss: 1.0123 - val_pose_output_loss: 0.2957 - val_emotion_output_loss: 1.1235 - val_gender_output_acc: 0.9441 - val_image_quality_output_acc: 0.5922 - val_age_output_acc: 0.5101 - val_weight_output_acc: 0.6946 - val_bag_output_acc: 0.7893 - val_footwear_output_acc: 0.7308 - val_pose_output_acc: 0.9284 - val_emotion_output_acc: 0.6653\n",
            "Epoch 96/100\n",
            "359/360 [============================>.] - ETA: 0s - loss: 2.3505 - gender_output_loss: 0.0859 - image_quality_output_loss: 0.3222 - age_output_loss: 0.5860 - weight_output_loss: 0.3472 - bag_output_loss: 0.1937 - footwear_output_loss: 0.2423 - pose_output_loss: 0.1161 - emotion_output_loss: 0.4571 - gender_output_acc: 0.9655 - image_quality_output_acc: 0.8661 - age_output_acc: 0.7628 - weight_output_acc: 0.8663 - bag_output_acc: 0.9230 - footwear_output_acc: 0.9053 - pose_output_acc: 0.9584 - emotion_output_acc: 0.8243Epoch 96/100\n",
            "360/360 [==============================] - 295s 819ms/step - loss: 2.3515 - gender_output_loss: 0.0868 - image_quality_output_loss: 0.3224 - age_output_loss: 0.5856 - weight_output_loss: 0.3471 - bag_output_loss: 0.1938 - footwear_output_loss: 0.2422 - pose_output_loss: 0.1161 - emotion_output_loss: 0.4574 - gender_output_acc: 0.9652 - image_quality_output_acc: 0.8660 - age_output_acc: 0.7629 - weight_output_acc: 0.8663 - bag_output_acc: 0.9228 - footwear_output_acc: 0.9053 - pose_output_acc: 0.9583 - emotion_output_acc: 0.8240 - val_loss: 8.1805 - val_gender_output_loss: 0.1856 - val_image_quality_output_loss: 1.5591 - val_age_output_loss: 1.6247 - val_weight_output_loss: 1.1999 - val_bag_output_loss: 0.9518 - val_footwear_output_loss: 1.1124 - val_pose_output_loss: 0.3466 - val_emotion_output_loss: 1.2002 - val_gender_output_acc: 0.9461 - val_image_quality_output_acc: 0.5751 - val_age_output_acc: 0.5025 - val_weight_output_acc: 0.6855 - val_bag_output_acc: 0.7828 - val_footwear_output_acc: 0.7142 - val_pose_output_acc: 0.9183 - val_emotion_output_acc: 0.6638\n",
            "Epoch 97/100\n",
            "360/360 [==============================] - 294s 815ms/step - loss: 2.3933 - gender_output_loss: 0.0846 - image_quality_output_loss: 0.3346 - age_output_loss: 0.5864 - weight_output_loss: 0.3533 - bag_output_loss: 0.2073 - footwear_output_loss: 0.2540 - pose_output_loss: 0.1145 - emotion_output_loss: 0.4587 - gender_output_acc: 0.9647 - image_quality_output_acc: 0.8580 - age_output_acc: 0.7630 - weight_output_acc: 0.8673 - bag_output_acc: 0.9178 - footwear_output_acc: 0.9010 - pose_output_acc: 0.9576 - emotion_output_acc: 0.8287 - val_loss: 7.8566 - val_gender_output_loss: 0.1713 - val_image_quality_output_loss: 1.6032 - val_age_output_loss: 1.5946 - val_weight_output_loss: 1.0950 - val_bag_output_loss: 0.8835 - val_footwear_output_loss: 1.0694 - val_pose_output_loss: 0.2970 - val_emotion_output_loss: 1.1424 - val_gender_output_acc: 0.9541 - val_image_quality_output_acc: 0.5806 - val_age_output_acc: 0.5101 - val_weight_output_acc: 0.6754 - val_bag_output_acc: 0.7823 - val_footwear_output_acc: 0.7238 - val_pose_output_acc: 0.9294 - val_emotion_output_acc: 0.6381\n",
            "Epoch 98/100\n",
            "360/360 [==============================] - 297s 825ms/step - loss: 2.3607 - gender_output_loss: 0.0763 - image_quality_output_loss: 0.3283 - age_output_loss: 0.5729 - weight_output_loss: 0.3587 - bag_output_loss: 0.2073 - footwear_output_loss: 0.2428 - pose_output_loss: 0.1207 - emotion_output_loss: 0.4537 - gender_output_acc: 0.9689 - image_quality_output_acc: 0.8644 - age_output_acc: 0.7671 - weight_output_acc: 0.8631 - bag_output_acc: 0.9201 - footwear_output_acc: 0.9022 - pose_output_acc: 0.9540 - emotion_output_acc: 0.8309 - val_loss: 7.8271 - val_gender_output_loss: 0.2278 - val_image_quality_output_loss: 1.6084 - val_age_output_loss: 1.5691 - val_weight_output_loss: 1.0888 - val_bag_output_loss: 0.8443 - val_footwear_output_loss: 1.0805 - val_pose_output_loss: 0.2579 - val_emotion_output_loss: 1.1503 - val_gender_output_acc: 0.9526 - val_image_quality_output_acc: 0.5751 - val_age_output_acc: 0.5020 - val_weight_output_acc: 0.6860 - val_bag_output_acc: 0.7697 - val_footwear_output_acc: 0.7263 - val_pose_output_acc: 0.9259 - val_emotion_output_acc: 0.6588\n",
            "Epoch 99/100\n",
            "360/360 [==============================] - 296s 822ms/step - loss: 2.3690 - gender_output_loss: 0.0877 - image_quality_output_loss: 0.3274 - age_output_loss: 0.5796 - weight_output_loss: 0.3497 - bag_output_loss: 0.2114 - footwear_output_loss: 0.2490 - pose_output_loss: 0.1158 - emotion_output_loss: 0.4485 - gender_output_acc: 0.9639 - image_quality_output_acc: 0.8636 - age_output_acc: 0.7602 - weight_output_acc: 0.8678 - bag_output_acc: 0.9201 - footwear_output_acc: 0.9030 - pose_output_acc: 0.9577 - emotion_output_acc: 0.8334 - val_loss: 8.4580 - val_gender_output_loss: 0.2191 - val_image_quality_output_loss: 1.7415 - val_age_output_loss: 1.7405 - val_weight_output_loss: 1.1716 - val_bag_output_loss: 0.8716 - val_footwear_output_loss: 1.1373 - val_pose_output_loss: 0.3037 - val_emotion_output_loss: 1.2727 - val_gender_output_acc: 0.9451 - val_image_quality_output_acc: 0.5645 - val_age_output_acc: 0.5010 - val_weight_output_acc: 0.6865 - val_bag_output_acc: 0.7752 - val_footwear_output_acc: 0.7177 - val_pose_output_acc: 0.9234 - val_emotion_output_acc: 0.6835\n",
            "Epoch 100/100\n",
            "360/360 [==============================] - 296s 822ms/step - loss: 2.3439 - gender_output_loss: 0.0846 - image_quality_output_loss: 0.3369 - age_output_loss: 0.5611 - weight_output_loss: 0.3427 - bag_output_loss: 0.2049 - footwear_output_loss: 0.2475 - pose_output_loss: 0.1128 - emotion_output_loss: 0.4535 - gender_output_acc: 0.9671 - image_quality_output_acc: 0.8597 - age_output_acc: 0.7755 - weight_output_acc: 0.8704 - bag_output_acc: 0.9178 - footwear_output_acc: 0.9025 - pose_output_acc: 0.9567 - emotion_output_acc: 0.8329 - val_loss: 7.7954 - val_gender_output_loss: 0.2159 - val_image_quality_output_loss: 1.5471 - val_age_output_loss: 1.6174 - val_weight_output_loss: 1.1419 - val_bag_output_loss: 0.8218 - val_footwear_output_loss: 1.0502 - val_pose_output_loss: 0.2730 - val_emotion_output_loss: 1.1281 - val_gender_output_acc: 0.9425 - val_image_quality_output_acc: 0.5766 - val_age_output_acc: 0.5066 - val_weight_output_acc: 0.6835 - val_bag_output_acc: 0.7878 - val_footwear_output_acc: 0.7137 - val_pose_output_acc: 0.9254 - val_emotion_output_acc: 0.6744\n",
            "\n",
            "Epoch 00100: saving model to /content/gdrive/My Drive/person_attributes1.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fca2a51ee48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP5OIiduotdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3OCW3iag5k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}